{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import related package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import tensorflow package for modeling\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Min-max normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Initializing module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "## Copy module\n",
    "import copy\n",
    "\n",
    "## Used to calculate the training time\n",
    "import time\n",
    "\n",
    "## Set the GUP environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the display\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control memory usage space for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前設備： 0\n",
      "目前設備名： GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "## 查詢有無可用 GPU\n",
    "torch.cuda.is_available()\n",
    "## 查詢可用 GPU 的數量\n",
    "torch.cuda.device_count()\n",
    "##目前設備\n",
    "print(\"目前設備：\",torch.cuda.current_device())\n",
    "## 目前設備名\n",
    "print(\"目前設備名：\",torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out some info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cacl(pred_value, actual_value):\n",
    "    \n",
    "#     yo, loss, tape = network.forward()\n",
    "    performance = []\n",
    "    performance.append(torch.mean(torch.abs(pred_value - actual_value)))\n",
    "    performance.append(torch.mean(torch.abs((pred_value - actual_value) / actual_value))) \n",
    "    performance.append(torch.sqrt(torch.mean((pred_value - actual_value)**2)))\n",
    "    \n",
    "    for i in range(2000,3001,1000):\n",
    "        correct_times = torch.nonzero(torch.abs(pred_value - actual_value) <= i)\n",
    "        accuracy = correct_times.shape[0]/pred_value.shape[0]\n",
    "        performance.append(accuracy)\n",
    "                       \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(name, pred_value, actual_value,block_index):\n",
    "    \n",
    "#     fig, ax = plt.subplots(2,2,figsize=(20,10), sharex=True, sharey=True)\n",
    "    fig, ax = plt.subplots(1,figsize=(20,10), sharex=True, sharey=True)\n",
    "#     ax.set_xlim(0,pred_value.shape[0])  \n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.plot(pred_value, label=\"LLAAT\")\n",
    "    ax.plot(actual_value, label=\"Actual\")\n",
    "    ax.set_title(\"Forecasted performance for l=%d\" %(1))\n",
    "    ax.legend()\n",
    "        \n",
    "    #fig.text(0.5, 0, \"Stage of training\", ha='center', fontsize=20)\n",
    "    #fig.text(0, 0.5, \"Copper price value\", va='center', rotation='vertical')\n",
    "\n",
    "    fig.suptitle(\"In the %s process in the M=%d window\"%(name, block_index))\n",
    "    fig.tight_layout()\n",
    "#     fig.savefig(\"In the %s process in the M=%d window.png\"%(name, block_index),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adopted_node(network,block_index):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "#     ax.set_xticklabels([i for i in range(network.nb_node_acceptable.shape[0]+5)])\n",
    "    \n",
    "    ax.set_title(\"Total amount of adopted hidden nodes in the training process in the M=%d window\"%(block_index))\n",
    "    ax.plot(network.nb_node_acceptable,\"-o\")\n",
    "\n",
    "    ax.set_xlabel(\"Stage of training\")\n",
    "    ax.set_ylabel(\"Hidden nodes\")\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "#     fig.savefig(\"hidden nodes in the training process in the M=%d window\"%(block_index),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_table(evaluation_results, block_index, name, performance, nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node):\n",
    "\n",
    "    print(performance[3])\n",
    "    print(type(performance[3]))\n",
    "    \n",
    "    new_result = pd.DataFrame({\n",
    "\n",
    "        \"Window_index\":block_index,\n",
    "        \"Stage\":name,\n",
    "        \"MAE\" : performance[0].item(),\n",
    "        \"MAPE\" : \"%.2f\"%(performance[1]*100).item(),\n",
    "        \"RMSE\" : performance[2].item(),\n",
    "        \"Accuracy(2000)\" : [round(performance[3]*100,2)],\n",
    "        \"Accuracy(3000)\" : [round(performance[4]*100,2)],\n",
    "        \"Step4\":nb_step4,\n",
    "        \"Step6.1\":nb_step6_1,\n",
    "        \"Step6.2\":nb_step6_2,\n",
    "        \"Time\":time,\n",
    "        \"Adopted_hidden_node\":adopted_hidden_node\n",
    "    })\n",
    "\n",
    "    evaluation_results = evaluation_results.append(new_result, ignore_index=True)\n",
    "    \n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(network, nb_step4, nb_step6_1, nb_step6_2, x_train_scaled, y_train_scaled, x_test, y_test, start, end, block_index, evaluation_results_train, evaluation_results_outlier, evaluation_results_test):\n",
    "\n",
    "    ## Training_Step\n",
    "    print(\"<<Training step>>\")\n",
    "    print(\"The training time(s):\",end - start)\n",
    "    time = end - start\n",
    "    yo, loss= network.forward()\n",
    "    \n",
    "    ## N - outlier\n",
    "    pre_train = yo.data.cpu()\n",
    "    true_train = network.y.data.cpu()\n",
    "    \n",
    "    pred_value_train = torch.FloatTensor(sc.inverse_transform(pre_train))\n",
    "    actual_value_train = torch.FloatTensor(sc.inverse_transform(true_train))\n",
    "    accuracy_train = accuracy_cacl(pred_value_train,actual_value_train)\n",
    "\n",
    "    ## Outlier\n",
    "    pre_outlier = torch.FloatTensor(sc.inverse_transform(network.forecast(x_train_scaled).data.cpu()))\n",
    "    actual_outlier = torch.FloatTensor(sc.inverse_transform(y_train_scaled))\n",
    "    accuracy_outlier = accuracy_cacl(pre_outlier,actual_outlier)\n",
    "    \n",
    "    ## B\n",
    "    pred_value_test = torch.FloatTensor(sc.inverse_transform(network.forecast(x_test).data.cpu()))\n",
    "    accuracy_test = accuracy_cacl(pred_value_test, y_test)\n",
    "    \n",
    "    total_time = nb_step4 + nb_step6_1 + nb_step6_2\n",
    "    print(\"<<The percentage of each step>>\")\n",
    "    print(\"Step 4: %.2f%%\"%((nb_step4/total_time)*100))\n",
    "    print(\"Step 6.1: %.2f%%\"%((nb_step6_1/total_time)*100))\n",
    "    print(\"Step 6.2: %.2f%%\"%((nb_step6_2/total_time)*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"Total frequency of cramming occurrences:\",nb_step6_2)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"The amount of hidden node that be pruned:\",network.nb_node_pruned)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    adopted_hidden_node = network.nb_node_acceptable[-1].item()\n",
    "    print(\"The amount of adopted hidden nodes:\",network.nb_node_acceptable[-1].item())\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in training step>>\")\n",
    "    print(\"The MAE for l = 1: %.2f\" %(accuracy_train[0]))\n",
    "    print(\"The MAPE for l = 1: %.2f%%\" %(accuracy_train[1]))\n",
    "    print(\"The RMSE for l = 1: %.2f\" %(accuracy_train[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.2f%%\" %(accuracy_train[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.2f%%\" %(accuracy_train[4]*100))\n",
    "#     print(\"The accuracy for l = 2: %.1f%%\" %(accuracy_train[1]*100))\n",
    "#     print(\"The accuracy for l = 3: %.1f%%\" %(accuracy_train[2]*100))\n",
    "#     print(\"The accuracy for l = 4: %.1f%%\" %(accuracy_train[3]*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in toutlier>>\")\n",
    "    print(\"The MAE for l = 1: %.2f\" %(accuracy_outlier[0]))\n",
    "    print(\"The MAPE for l = 1: %.2f%%\" %(accuracy_outlier[1]))\n",
    "    print(\"The RMSE for l = 1: %.2f\" %(accuracy_outlier[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.2f%%\" %(accuracy_outlier[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.2f%%\" %(accuracy_outlier[4]*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in inferencing step>>\")\n",
    "    print(\"The MAE for l = 1: %.1f\" %(accuracy_test[0]))\n",
    "    print(\"The MAPE for l = 1: %.1f%%\" %(accuracy_test[1]))\n",
    "    print(\"The RMSE for l = 1: %.1f\" %(accuracy_test[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.1f%%\" %(accuracy_test[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.1f%%\" %(accuracy_test[4]*100))\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    \n",
    "    evaluation_table_train = evaluation_table(evaluation_results_train, block_index, \"Training\", accuracy_train,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    evaluation_table_outlier = evaluation_table(evaluation_results_outlier, block_index, \"Outlier\", accuracy_outlier,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    evaluation_table_test = evaluation_table(evaluation_results_test, block_index, \"Inferencing\", accuracy_test,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    pre_LDSS = sc.inverse_transform(network.forecast(x_test).data.cpu())\n",
    "    pd.DataFrame(pre_LDSS).to_csv(\"pre_LDSS_%d.csv\"%(block_index), index=False)\n",
    "    \n",
    "#     if block_index%5==0:\n",
    "    plot_result(\"training\",pred_value_train, actual_value_train,block_index)\n",
    "    plot_result(\"inferencing\",pred_value_test, y_test,block_index)\n",
    "    plot_adopted_node(network,block_index)\n",
    "    \n",
    "    return(evaluation_table_train,evaluation_table_outlier, evaluation_table_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastWeek=4, futureWeek=4, defaultWeek=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureWeek-pastWeek):\n",
    "        X = np.array(train.iloc[i:i+defaultWeek])\n",
    "        X = np.append(X,train[\"CCSP\"].iloc[i+defaultWeek:i+pastWeek])\n",
    "        X_train.append(X.reshape(X.size))\n",
    "        Y_train.append(np.array(train.iloc[i+pastWeek:i+pastWeek+futureWeek][\"CCSP\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use min-max normalization to scale the data to the range from 1 to 0\n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design get_data() to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(futureWeek):\n",
    "    \n",
    "    ## Read weekly copper price data\n",
    "    path = \"WeeklyFinalData.csv\"\n",
    "    data = read(path)\n",
    "    \n",
    "    date = data[\"Date\"]\n",
    "    data.drop(\"Date\", axis=1, inplace=True)\n",
    "    \n",
    "    ## Add time lag (pastWeek=4, futureWeek=1)\n",
    "    x_data, y_data = buildTrain(data, futureWeek=futureWeek)\n",
    "\n",
    "\n",
    "    return (x_data, y_data)\n",
    "\n",
    "#     return (x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_neuro, x_train_scaled, y_train_scaled):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(x_train_scaled.shape[1], nb_neuro).cuda()\n",
    "        self.linear2 = torch.nn.Linear(nb_neuro, 1).cuda()\n",
    "        \n",
    "        \n",
    "        # Stop criteria - threshold\n",
    "        self.threshold_for_error = 0.12\n",
    "        self.threshold_for_lr = 1e-4\n",
    "        \n",
    "        # Input data \n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "        \n",
    "        # Learning rate\n",
    "        self.learning_rate = 1e-3\n",
    "        \n",
    "        # Whether the network is acceptable, default as False\n",
    "        self.acceptable = False\n",
    "        \n",
    "        # Some record for experiment\n",
    "        self.nb_node_pruned = 0\n",
    "        self.nb_node_acceptable=torch.IntTensor([nb_neuro])\n",
    "        \n",
    "        self.limit = nb_neuro\n",
    "        \n",
    "    ## Forecast the test data\n",
    "    def forecast(self, x_test):\n",
    "    \n",
    "        x_test = torch.FloatTensor(x_test).cuda()\n",
    "        activation_value = self.linear1(x_test).clamp(min=0)\n",
    "        forecast_value = self.linear2(activation_value)\n",
    "       \n",
    "        return forecast_value\n",
    "\n",
    "    ## Reset the x and y data\n",
    "    def setData(self, x_train_scaled, y_train_scaled):\n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "    \n",
    "    ## Add the new data to the x and y data\n",
    "    def addData(self, new_x_train, new_y_train):\n",
    "\n",
    "        self.x = torch.cat([self.x, new_x_train.reshape(1,-1).cuda()],0)\n",
    "        self.y = torch.cat([self.y, new_y_train.reshape(-1,1).cuda()],0)\n",
    "    \n",
    "    ## forward operation\n",
    "    def forward(self, reg_strength=0):\n",
    "       \n",
    "        y1 = self.linear1(self.x).clamp(min=0)\n",
    "        yo = self.linear2(y1)\n",
    "\n",
    "        # performance measure\n",
    "        param_val= torch.sum(torch.pow(self.linear2.bias.data,2))+torch.sum(torch.pow(self.linear2.weight.data,2))+torch.sum(torch.pow(self.linear1.bias.data,2))+torch.sum(torch.pow(self.linear1.weight.data,2))\n",
    "        reg_term= reg_strength/((self.linear2.bias.data.shape[0]*(self.linear2.weight.data.shape[1]+1)) +(self.linear1.bias.data.shape[0]*(self.linear1.weight.data.shape[1]+1)))*param_val\n",
    "        loss = torch.nn.functional.mse_loss(yo,self.y)+reg_term\n",
    "        loss = loss.cuda()\n",
    "        return(yo, loss)\n",
    "\n",
    "    # backward operation\n",
    "    def backward_Adadelta(self,loss):    \n",
    "\n",
    "        optimizer = optim.Adadelta(self.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializing(network, initial_x, initial_y):\n",
    "    print(\"Initializing module\")\n",
    "    ## Find each minimum output value y\n",
    "    min_y = torch.min(initial_y, axis=0)\n",
    "    ## Subtract min_y from each y\n",
    "    res_y = initial_y-min_y.values\n",
    "    \n",
    "    ## Use linear regression to find the initial W1,b1,Wo,bo\n",
    "    reg = LinearRegression().fit(initial_x, res_y)\n",
    "    \n",
    "    ## Set up the initial parameter of the network\n",
    "    network.linear1.weight = torch.nn.Parameter(torch.FloatTensor(reg.coef_).cuda())\n",
    "    network.linear1.bias = torch.nn.Parameter(torch.FloatTensor(reg.intercept_).cuda())\n",
    "    network.linear2.weight=torch.nn.Parameter(torch.FloatTensor([[1]]).cuda())\n",
    "    network.linear2.bias = torch.nn.Parameter(torch.FloatTensor(min_y.values).cuda())\n",
    "    \n",
    "#     print(reg.coef_)\n",
    "#     print(reg.intercept_)\n",
    "\n",
    "    ## Set up the acceptable of the initial network as True\n",
    "    network.acceptable =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting(network, x_train_scaled, y_train_scaled):\n",
    "    \n",
    "    print(\"<<Selecting module>>\")\n",
    "    loss = []\n",
    "    temp_network = copy.deepcopy(network)\n",
    "    \n",
    "    ## Put each data into network to calculate the loss value\n",
    "    for i in range(x_train_scaled.shape[0]):\n",
    "        temp_network.setData(x_train_scaled[i].reshape(1,-1), y_train_scaled[i].reshape(-1,1))\n",
    "        loss.append((temp_network.forward()[1].item(),i))\n",
    "#         print(network.state_dict())\n",
    "#         print(temp_network.y)\n",
    "#         print(\"-\"*20)\n",
    "#         print(temp_network.forward()[1])\n",
    "#         print(\"-\"*20)\n",
    "#     ## Sort the data according to the loss value from smallest to largest, and save the data index in sorted_index\n",
    "    sorted_index = [sorted_data[1] for sorted_data in sorted(loss, key = lambda x:x[0])]\n",
    "    \n",
    "    \n",
    "    ## Print out some info for debug\n",
    "    print(\"The loss value of k:\",loss[sorted_index[0]])\n",
    "    print(\"The second_loss value of k:\",loss[sorted_index[1]])\n",
    "    print(\"Selecting module finish!\")\n",
    "#     print(\"Loss\",loss)\n",
    "#     print(network.state_dict())\n",
    "    \n",
    "    return sorted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def matching(network):\n",
    "\n",
    "#     times_enlarge=0\n",
    "#     times_shrink=0\n",
    "    \n",
    "#     print(\"<<Matching module>>\")\n",
    "#     print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "#     ## Set up the learning rate of the network\n",
    "#     network.learning_rate = 1e-3\n",
    "#     network.acceptable = False\n",
    "#     initial_network = copy.deepcopy(network)\n",
    "\n",
    "#     yo, loss = network.forward()\n",
    "    \n",
    "#     if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "#         print(\"Matching finished (firstly) - the network is acceptable\")\n",
    "#         network.acceptable = True\n",
    "# #         print(\"Matching firstly finished - the network is acceptable\")\n",
    "#         print(\"Number of enlarge:\",times_enlarge)\n",
    "#         print(\"Number of shrink:\",times_shrink)\n",
    "#         return(network)\n",
    "    \n",
    "#     else:\n",
    "    \n",
    "#         while True:\n",
    "\n",
    "#             yo, loss = network.forward()\n",
    "#             network_pre = copy.deepcopy(network)\n",
    "#             loss_pre = loss\n",
    "            \n",
    "#             # Backward and check the loss performance of the network with new learning rate\n",
    "#             network.backward_Adadelta(loss)\n",
    "#             yo, loss = network.forward()\n",
    "\n",
    "#             # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "#             if loss <= loss_pre and torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "       \n",
    "#                 network.acceptable = True\n",
    "#                 print(\"Matching finished - the network is acceptable\")\n",
    "#                 print(\"Number of enlarge:\",times_enlarge)\n",
    "#                 print(\"Number of shrink:\",times_shrink)\n",
    "#                 return(network)\n",
    "\n",
    "#             elif loss <= loss_pre:\n",
    "                \n",
    "#                 times_enlarge+=1\n",
    "#                 network.learning_rate *= 1.2\n",
    "\n",
    "#             else:         \n",
    "\n",
    "#                 # Identify whether the current learning rate is less than the threshold\n",
    "#                 if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "#                     # If true, set the acceptable of the network as false and return it\n",
    "#                     network.acceptable = False\n",
    "#                     print(\"Matching finished - the network is Unacceptable\")\n",
    "#                     print(\"Number of enlarge:\",times_enlarge)\n",
    "#                     print(\"Number of shrink:\",times_shrink)\n",
    "#                     return(initial_network)\n",
    "\n",
    "#                 # On the contrary, restore w and adjust the learning rate\n",
    "#                 else:\n",
    "                    \n",
    "#                     # Restore the papameter of the network\n",
    "#                     network = copy.deepcopy(network_pre)\n",
    "#                     times_shrink+=1\n",
    "#                     network.learning_rate *= 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    \n",
    "    print(\"<<Matching module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "    yo, loss = network.forward()\n",
    "    \n",
    "    if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "        network.acceptable = True\n",
    "        print(\"Matching(o) first finished - the network is acceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(10000):\n",
    "            \n",
    "            yo, loss = network.forward()\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "#             print(\"<前Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "            network.backward_Adadelta(loss)\n",
    "            yo, loss = network.forward()\n",
    "#             print(\"<後Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "            if loss <= loss_pre and torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "                # If true, multiply the learning rate by 1.2\n",
    "                network.acceptable = True\n",
    "                print(\"Matching finished - the network is acceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "            elif loss <= loss_pre:\n",
    "                \n",
    "#                 print(\"*1.2\")\n",
    "                times_enlarge+=1\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "\n",
    "            else:         \n",
    "\n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                    # If true, set the acceptable of the network as false and return it\n",
    "                    network.acceptable = False\n",
    "                    print(\"Matching finished - the network is Unacceptable\")\n",
    "                    print(\"Number of enlarge:\",times_enlarge)\n",
    "                    print(\"Number of shrink:\",times_shrink)\n",
    "                    return(initial_network)\n",
    "\n",
    "                # On the contrary, restore w and adjust the learning rate\n",
    "                else:\n",
    "#                     print(\"*0.7\")\n",
    "                    # Restore the papameter of the network\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    times_shrink+=1\n",
    "                    network.learning_rate *= 0.7\n",
    "                \n",
    "        network.acceptable = False\n",
    "        print(\"Matching的第%d回合\"%(i+1))\n",
    "        print(\"Matching finished - the network is Unacceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(initial_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching for reorganizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_for_reorganizing(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    \n",
    "    print(\"<<Matching module for reorganizing>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "    yo, loss = network.forward()\n",
    "    \n",
    "    if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "        network.acceptable = True\n",
    "        print(\"Matching(o) first finished - the network is acceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(500):\n",
    "            \n",
    "            yo, loss = network.forward()\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "#             print(\"<前Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "            network.backward_Adadelta(loss)\n",
    "            yo, loss = network.forward()\n",
    "#             print(\"<後Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "            if loss <= loss_pre and torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "                # If true, multiply the learning rate by 1.2\n",
    "                network.acceptable = True\n",
    "                print(\"Matching finished(o) - the network is acceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "            elif loss <= loss_pre:\n",
    "                \n",
    "#                 print(\"*1.2\")\n",
    "                times_enlarge+=1\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "\n",
    "            else:         \n",
    "\n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                    # If true, set the acceptable of the network as false and return it\n",
    "                    network.acceptable = False\n",
    "                    print(\"Matching finished(o) - the network is Unacceptable\")\n",
    "                    print(\"Number of enlarge:\",times_enlarge)\n",
    "                    print(\"Number of shrink:\",times_shrink)\n",
    "                    return(initial_network)\n",
    "\n",
    "                # On the contrary, restore w and adjust the learning rate\n",
    "                else:\n",
    "#                     print(\"*0.7\")\n",
    "                    # Restore the papameter of the network\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    times_shrink+=1\n",
    "                    network.learning_rate *= 0.7\n",
    "                \n",
    "        network.acceptable = False\n",
    "        print(\"Matching的第%d回合\"%(i+1))\n",
    "        print(\"Matching finished - the network is Unacceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(initial_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramming module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramming(network):\n",
    "    \n",
    "    torch.random.manual_seed(0)\n",
    "    print(\"<<Cramming module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Find unsatisfied data:K\n",
    "    yo, loss = network.forward()\n",
    "    undesired_index = torch.nonzero(torch.abs(yo-network.y) > network.threshold_for_error+0.001, as_tuple =False)\n",
    "\n",
    "    ## Print out the undesired_index for debug\n",
    "    print(\"不滿足個數：\",undesired_index.shape[0])\n",
    "    print(\"The index of the undesired data:\",undesired_index)\n",
    "\n",
    "    \n",
    "    if undesired_index.shape[0] == 1:\n",
    "        \n",
    "        # Unsatisfied situation\n",
    "        ## Find the index of the unsatisfied data\n",
    "        k_data_num = undesired_index[0][0]\n",
    "\n",
    "        undesired_data = torch.reshape(network.x[k_data_num,:], [1,-1])\n",
    "\n",
    "        ## Remove the data that does not meet the error term\n",
    "        left_data = network.x[:k_data_num,:]\n",
    "        right_data = network.x[k_data_num+1:,:]\n",
    "        remain_tensor = torch.cat([left_data, right_data], 0)\n",
    "\n",
    "\n",
    "        ## Use the random method to find out the gamma and zeta\n",
    "        while True:\n",
    "\n",
    "            ## Find m-vector gamma: r\n",
    "            ## Use the random method to generate the gamma that can make the conditions met\n",
    "            gamma = torch.rand(size=[1,network.x.shape[1]]).cuda()\n",
    "            subtract_undesired_data = torch.sub(remain_tensor, undesired_data)\n",
    "            matmul_value = torch.mm(gamma,torch.t(subtract_undesired_data))\n",
    "\n",
    "            if torch.all(matmul_value != 0):\n",
    "                break\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## Find the tiny value: zeta\n",
    "            ## Use the random method to generate the zeta that can make the conditions met\n",
    "            zeta = torch.rand(size=[1]).cuda()\n",
    "\n",
    "            if torch.all(torch.mul(torch.add(zeta,matmul_value),torch.sub(zeta,matmul_value))<0):\n",
    "                break\n",
    "\n",
    "       \n",
    "\n",
    "        k_l = undesired_index[0][1]\n",
    "        \n",
    "        ## The weight of input layer to hidden layer I\n",
    "        w10 = gamma\n",
    "        w11 = gamma\n",
    "        w12 = gamma\n",
    "\n",
    "        W1_new = torch.cat([w10,w11,w12],0)\n",
    "        \n",
    "\n",
    "        ## The bias of input layer to hidden layer I\n",
    "        matual_value = torch.mm(gamma,torch.t(undesired_data))\n",
    "       \n",
    "        \n",
    "        b10 = torch.sub(zeta,matual_value)\n",
    "        b11 = -1*matual_value\n",
    "        b12 = torch.sub(-1*zeta,matual_value)\n",
    "\n",
    "        b1_new = torch.reshape(torch.cat([b10,b11,b12],0),[3])\n",
    "        \n",
    "#         print(\"b1_new\",b1_new)\n",
    "\n",
    "\n",
    "        ## The weight of hidden layer I to output layer\n",
    "        gap = network.y[k_data_num, k_l]-yo[k_data_num, k_l]\n",
    "#         print(\"gap:\",gap)\n",
    "\n",
    "        wo0_value = gap/zeta\n",
    "        wo1_value = (-2*gap)/zeta\n",
    "        wo2_value = gap/zeta\n",
    "\n",
    "        Wo_new = torch.reshape(torch.cat([wo0_value,wo1_value,wo2_value],0),[1,-1])\n",
    "\n",
    "        ## Add new neuroes to the network\n",
    "        network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight.data, W1_new]))\n",
    "        network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias.data, b1_new]))\n",
    "        network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight.data, Wo_new],1))\n",
    "\n",
    "\n",
    "        yo, loss = network.forward()\n",
    "        \n",
    "        ## Determine if cramming is successful and print out the corresponding information\n",
    "        if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "            network.acceptable = True \n",
    "            print(\"Cramming success!\")\n",
    "\n",
    "        else:\n",
    "            print(\"Cramming failed!\")\n",
    "    \n",
    "    else:\n",
    "        print(\"條件不合，不能Cramming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizing(network):\n",
    "\n",
    "    print(\"<<Regularizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    ## Record the number of executions\n",
    "    times_enlarge = 0\n",
    "    times_shrink = 0\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "\n",
    "    ## Set epoch to 100\n",
    "    for i in range(100):\n",
    "\n",
    "        ## Store the parameter of the network\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "        loss_pre = loss\n",
    "\n",
    "#         print(\"調整前的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "        \n",
    "        ## Backward operation to obtain w'\n",
    "        network.backward_Adadelta(loss)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "#         print(\"調整後的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "         # Confirm whether the adjusted loss value is smaller than the current one\n",
    "        if loss <= loss_pre:\n",
    "            \n",
    "            ## Identify that all forecast value has met the error term\n",
    "            if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "                \n",
    "                ## If true, multiply the learning rate by 1.2\n",
    "#                 print(\"*1.2\")\n",
    "                network.learning_rate *= 1.2\n",
    "                times_enlarge += 1\n",
    "#                 print(\"Regularizing %d process - Enlarge\"%i)\n",
    "#                 print(\"第\\\"%d\\\"回合是成功執行regularizing\"%(i+1))\n",
    "#                 print(\"差異\")\n",
    "#                 print(torch.abs(yo-network.y))\n",
    "\n",
    "            else:\n",
    "\n",
    "                ## Else, restore w and end the process\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                print(\"Regularizing結束-因為沒有顧好預測誤差\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Unable to meet the error term\")\n",
    "                return(network)\n",
    "\n",
    "        # If the adjusted loss value is not smaller than the current one\n",
    "        else:\n",
    "\n",
    "            ## If the learning rate is greater than the threshold for learning rate\n",
    "            if network.learning_rate > network.threshold_for_lr:\n",
    "                \n",
    "                ## Restore the w and multiply the learning rate by 0.7\n",
    "                network = copy.deepcopy(network_pre)\n",
    "#                 print(\"*0.7\")\n",
    "                network.learning_rate *= 0.7\n",
    "                times_shrink += 1\n",
    "#                 print(\"把Learning rate變小\")\n",
    "#                 print(\"Regularizing %d process - Shrink\"%i)\n",
    "             ## If the learning rate is smaller than the threshold for learning rate\n",
    "            else:\n",
    "                \n",
    "                ## Restore the w\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                print(\"Regularizing結束-Learning不能這麼小\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Less than the epsilon for the learning rate\")\n",
    "                return(network)\n",
    "\n",
    "    print(\"第\\\"%d\\\"回合Regularizing module完畢\"%(i+1))\n",
    "    print(\"Number of enlarge:\",times_enlarge)\n",
    "    print(\"Number of shrink:\",times_shrink)\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganizing(network):\n",
    "    print(\"<<Reorganizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    limit = 4\n",
    "    if network.linear1.bias.shape[0] <= limit:\n",
    "        network = regularizing(network)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        ## Set up the k = 1, and p = the number of hidden node\n",
    "        k = 1\n",
    "    #     p = network.W1.shape[1]\n",
    "        p = network.linear1.weight.data.shape[0]\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## If k > p, end of Process\n",
    "            if k > p or p<=limit:\n",
    "\n",
    "                print(\"Reorganizing result: The final number of neuro is \",p)\n",
    "                return(network)\n",
    "\n",
    "            ## Else, Process is ongoing\n",
    "            else:\n",
    "\n",
    "                ## Using the regularizing module to adjust the network\n",
    "                network = regularizing(network)\n",
    "\n",
    "                ## Store the network and w\n",
    "                network_pre = copy.deepcopy(network)\n",
    "\n",
    "                ## Set up the acceptable of the network as false\n",
    "                network.acceptable = False\n",
    "                \n",
    "            \n",
    "                ## Ignore the K hidden node\n",
    "                network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight[:k-1],network.linear1.weight[k:]],0))\n",
    "                network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias[:k-1],network.linear1.bias[k:]]))\n",
    "                network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight[:,:k-1],network.linear2.weight[:,k:]],1))\n",
    "\n",
    "                \n",
    "                ## Using the matching module to adjust the network\n",
    "                network = matching_for_reorganizing(network)\n",
    "\n",
    "                print(\"是不是可以不要這個hidden node:\",network.acceptable)\n",
    "\n",
    "                ## If the resulting network is acceptable, this means that the k hidden node can be removed\n",
    "                if network.acceptable:\n",
    "\n",
    "                    print(\"Drop out the nero number: %d / %d\" %(k, p))\n",
    "                    network.nb_node_pruned += 1\n",
    "                    ## p--\n",
    "                    p-=1\n",
    "\n",
    "                ## Else, it means that the k hidden node cannot be removed\n",
    "                else:\n",
    "\n",
    "                    ## Restore the network and w\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    print(\"Cannot drop out the nero number: %d / %d\" %(k, p))\n",
    "\n",
    "                    ## k++\n",
    "                    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The <<1>> Block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing module\n",
      "<<Initializing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "現在訓練到第幾筆資料: 20\n",
      "剩餘X 資料 torch.Size([87, 18])\n",
      "剩餘Y 資料 torch.Size([87, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (1.808647311918321e-06, 3)\n",
      "The second_loss value of k: (0.00010389705130364746, 21)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.9767])\n",
      "目前模型的Data狀態 torch.Size([20, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8982],\n",
      "        [0.9283],\n",
      "        [0.8435],\n",
      "        [0.8040],\n",
      "        [0.8136],\n",
      "        [0.8421],\n",
      "        [0.8447],\n",
      "        [0.9290],\n",
      "        [0.8890],\n",
      "        [0.9141],\n",
      "        [0.9367],\n",
      "        [0.9159],\n",
      "        [0.8533],\n",
      "        [0.8548],\n",
      "        [0.8454],\n",
      "        [0.7929],\n",
      "        [0.8065],\n",
      "        [0.8315],\n",
      "        [0.8036],\n",
      "        [0.9753]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0013]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 23\n",
      "Number of shrink: 19\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0013]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.4332258701324463\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 21\n",
      "剩餘X 資料 torch.Size([86, 18])\n",
      "剩餘Y 資料 torch.Size([86, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00010269638005411252, 20)\n",
      "The second_loss value of k: (0.00012979797611478716, 14)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引20，y= tensor([0.8635])\n",
      "目前模型的Data狀態 torch.Size([21, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8982],\n",
      "        [0.9284],\n",
      "        [0.8436],\n",
      "        [0.8040],\n",
      "        [0.8136],\n",
      "        [0.8422],\n",
      "        [0.8448],\n",
      "        [0.9290],\n",
      "        [0.8890],\n",
      "        [0.9142],\n",
      "        [0.9367],\n",
      "        [0.9160],\n",
      "        [0.8534],\n",
      "        [0.8548],\n",
      "        [0.8455],\n",
      "        [0.7929],\n",
      "        [0.8066],\n",
      "        [0.8316],\n",
      "        [0.8037],\n",
      "        [0.9754],\n",
      "        [0.8534]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0013],\n",
      "        [    0.0101]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0001],\n",
      "        [0.0002],\n",
      "        [0.0003],\n",
      "        [0.0003],\n",
      "        [0.0003],\n",
      "        [0.0003],\n",
      "        [0.0004],\n",
      "        [0.0004],\n",
      "        [0.0007],\n",
      "        [0.0007],\n",
      "        [0.0008],\n",
      "        [0.0008],\n",
      "        [0.0008],\n",
      "        [0.0007],\n",
      "        [0.0008],\n",
      "        [0.0009],\n",
      "        [0.0009],\n",
      "        [0.0009],\n",
      "        [0.0010],\n",
      "        [0.0009],\n",
      "        [0.0089]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.6790494918823242\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 22\n",
      "剩餘X 資料 torch.Size([85, 18])\n",
      "剩餘Y 資料 torch.Size([85, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00011631329834926873, 14)\n",
      "The second_loss value of k: (0.00013560507795773447, 19)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引14，y= tensor([0.8043])\n",
      "目前模型的Data狀態 torch.Size([22, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8983],\n",
      "        [0.9285],\n",
      "        [0.8438],\n",
      "        [0.8043],\n",
      "        [0.8138],\n",
      "        [0.8424],\n",
      "        [0.8451],\n",
      "        [0.9294],\n",
      "        [0.8896],\n",
      "        [0.9148],\n",
      "        [0.9374],\n",
      "        [0.9167],\n",
      "        [0.8541],\n",
      "        [0.8555],\n",
      "        [0.8463],\n",
      "        [0.7938],\n",
      "        [0.8074],\n",
      "        [0.8324],\n",
      "        [0.8046],\n",
      "        [0.9758],\n",
      "        [0.8546],\n",
      "        [0.7935]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0001],\n",
      "        [0.0002],\n",
      "        [0.0003],\n",
      "        [0.0003],\n",
      "        [0.0003],\n",
      "        [0.0003],\n",
      "        [0.0004],\n",
      "        [0.0004],\n",
      "        [0.0007],\n",
      "        [0.0007],\n",
      "        [0.0008],\n",
      "        [0.0008],\n",
      "        [0.0008],\n",
      "        [0.0007],\n",
      "        [0.0008],\n",
      "        [0.0009],\n",
      "        [0.0009],\n",
      "        [0.0009],\n",
      "        [0.0010],\n",
      "        [0.0009],\n",
      "        [0.0089],\n",
      "        [0.0108]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0006],\n",
      "        [    0.0004],\n",
      "        [    0.0002],\n",
      "        [    0.0000],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0003],\n",
      "        [    0.0003],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0005],\n",
      "        [    0.0006],\n",
      "        [    0.0007],\n",
      "        [    0.0006],\n",
      "        [    0.0007],\n",
      "        [    0.0043],\n",
      "        [    0.0012],\n",
      "        [    0.0013],\n",
      "        [    0.0015],\n",
      "        [    0.0014],\n",
      "        [    0.0081],\n",
      "        [    0.0071]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 1.9248058795928955\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 23\n",
      "剩餘X 資料 torch.Size([84, 18])\n",
      "剩餘Y 資料 torch.Size([84, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00011543557047843933, 18)\n",
      "The second_loss value of k: (0.0005457014194689691, 37)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引18，y= tensor([0.8425])\n",
      "目前模型的Data狀態 torch.Size([23, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8976],\n",
      "        [0.9280],\n",
      "        [0.8433],\n",
      "        [0.8040],\n",
      "        [0.8134],\n",
      "        [0.8420],\n",
      "        [0.8450],\n",
      "        [0.9293],\n",
      "        [0.8891],\n",
      "        [0.9143],\n",
      "        [0.9371],\n",
      "        [0.9165],\n",
      "        [0.8540],\n",
      "        [0.8553],\n",
      "        [0.8462],\n",
      "        [0.7972],\n",
      "        [0.8078],\n",
      "        [0.8328],\n",
      "        [0.8051],\n",
      "        [0.9753],\n",
      "        [0.8554],\n",
      "        [0.7972],\n",
      "        [0.8318]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0006],\n",
      "        [    0.0004],\n",
      "        [    0.0002],\n",
      "        [    0.0000],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0003],\n",
      "        [    0.0003],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0005],\n",
      "        [    0.0006],\n",
      "        [    0.0007],\n",
      "        [    0.0006],\n",
      "        [    0.0007],\n",
      "        [    0.0043],\n",
      "        [    0.0012],\n",
      "        [    0.0013],\n",
      "        [    0.0015],\n",
      "        [    0.0014],\n",
      "        [    0.0081],\n",
      "        [    0.0071],\n",
      "        [    0.0107]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0005],\n",
      "        [    0.0002],\n",
      "        [    0.0000],\n",
      "        [    0.0003],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0008],\n",
      "        [    0.0012],\n",
      "        [    0.0014],\n",
      "        [    0.0015],\n",
      "        [    0.0013],\n",
      "        [    0.0016],\n",
      "        [    0.0058],\n",
      "        [    0.0023],\n",
      "        [    0.0023],\n",
      "        [    0.0027],\n",
      "        [    0.0010],\n",
      "        [    0.0064],\n",
      "        [    0.0056],\n",
      "        [    0.0090]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.1710236072540283\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 24\n",
      "剩餘X 資料 torch.Size([83, 18])\n",
      "剩餘Y 資料 torch.Size([83, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0004985324339941144, 36)\n",
      "The second_loss value of k: (0.0007962135132402182, 14)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引36，y= tensor([0.9059])\n",
      "目前模型的Data狀態 torch.Size([24, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8976],\n",
      "        [0.9281],\n",
      "        [0.8435],\n",
      "        [0.8043],\n",
      "        [0.8137],\n",
      "        [0.8422],\n",
      "        [0.8454],\n",
      "        [0.9297],\n",
      "        [0.8897],\n",
      "        [0.9149],\n",
      "        [0.9379],\n",
      "        [0.9173],\n",
      "        [0.8549],\n",
      "        [0.8561],\n",
      "        [0.8470],\n",
      "        [0.7986],\n",
      "        [0.8088],\n",
      "        [0.8338],\n",
      "        [0.8063],\n",
      "        [0.9757],\n",
      "        [0.8571],\n",
      "        [0.7986],\n",
      "        [0.8336],\n",
      "        [0.8836]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0005],\n",
      "        [    0.0002],\n",
      "        [    0.0000],\n",
      "        [    0.0003],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0008],\n",
      "        [    0.0012],\n",
      "        [    0.0014],\n",
      "        [    0.0015],\n",
      "        [    0.0013],\n",
      "        [    0.0016],\n",
      "        [    0.0058],\n",
      "        [    0.0023],\n",
      "        [    0.0023],\n",
      "        [    0.0027],\n",
      "        [    0.0010],\n",
      "        [    0.0064],\n",
      "        [    0.0056],\n",
      "        [    0.0090],\n",
      "        [    0.0223]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0006],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0003],\n",
      "        [    0.0001],\n",
      "        [    0.0002],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0013],\n",
      "        [    0.0014],\n",
      "        [    0.0021],\n",
      "        [    0.0024],\n",
      "        [    0.0025],\n",
      "        [    0.0021],\n",
      "        [    0.0028],\n",
      "        [    0.0063],\n",
      "        [    0.0033],\n",
      "        [    0.0033],\n",
      "        [    0.0037],\n",
      "        [    0.0007],\n",
      "        [    0.0046],\n",
      "        [    0.0051],\n",
      "        [    0.0071],\n",
      "        [    0.0202]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.4160566329956055\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 25\n",
      "剩餘X 資料 torch.Size([82, 18])\n",
      "剩餘Y 資料 torch.Size([82, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0009117954759858549, 14)\n",
      "The second_loss value of k: (0.000921109807677567, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引14，y= tensor([0.8094])\n",
      "目前模型的Data狀態 torch.Size([25, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8976],\n",
      "        [0.9282],\n",
      "        [0.8436],\n",
      "        [0.8042],\n",
      "        [0.8136],\n",
      "        [0.8423],\n",
      "        [0.8453],\n",
      "        [0.9297],\n",
      "        [0.8903],\n",
      "        [0.9155],\n",
      "        [0.9387],\n",
      "        [0.9183],\n",
      "        [0.8558],\n",
      "        [0.8569],\n",
      "        [0.8483],\n",
      "        [0.7992],\n",
      "        [0.8098],\n",
      "        [0.8348],\n",
      "        [0.8074],\n",
      "        [0.9759],\n",
      "        [0.8589],\n",
      "        [0.7992],\n",
      "        [0.8354],\n",
      "        [0.8857],\n",
      "        [0.8396]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0006],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0003],\n",
      "        [    0.0001],\n",
      "        [    0.0002],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0013],\n",
      "        [    0.0014],\n",
      "        [    0.0021],\n",
      "        [    0.0024],\n",
      "        [    0.0025],\n",
      "        [    0.0021],\n",
      "        [    0.0028],\n",
      "        [    0.0063],\n",
      "        [    0.0033],\n",
      "        [    0.0033],\n",
      "        [    0.0037],\n",
      "        [    0.0007],\n",
      "        [    0.0046],\n",
      "        [    0.0051],\n",
      "        [    0.0071],\n",
      "        [    0.0202],\n",
      "        [    0.0302]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(    0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0003],\n",
      "        [    0.0003],\n",
      "        [    0.0004],\n",
      "        [    0.0003],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0003],\n",
      "        [    0.0003],\n",
      "        [    0.0004],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0014],\n",
      "        [    0.0015],\n",
      "        [    0.0011],\n",
      "        [    0.0017],\n",
      "        [    0.0054],\n",
      "        [    0.0017],\n",
      "        [    0.0018],\n",
      "        [    0.0021],\n",
      "        [    0.0012],\n",
      "        [    0.0061],\n",
      "        [    0.0060],\n",
      "        [    0.0087],\n",
      "        [    0.0209],\n",
      "        [    0.0285]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.660353899002075\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 26\n",
      "剩餘X 資料 torch.Size([81, 18])\n",
      "剩餘Y 資料 torch.Size([81, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0009756909566931427, 12)\n",
      "The second_loss value of k: (0.0009830477647483349, 26)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([0.8295])\n",
      "目前模型的Data狀態 torch.Size([26, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8978],\n",
      "        [0.9286],\n",
      "        [0.8439],\n",
      "        [0.8042],\n",
      "        [0.8136],\n",
      "        [0.8422],\n",
      "        [0.8450],\n",
      "        [0.9293],\n",
      "        [0.8894],\n",
      "        [0.9146],\n",
      "        [0.9377],\n",
      "        [0.9174],\n",
      "        [0.8549],\n",
      "        [0.8558],\n",
      "        [0.8471],\n",
      "        [0.7983],\n",
      "        [0.8082],\n",
      "        [0.8333],\n",
      "        [0.8058],\n",
      "        [0.9755],\n",
      "        [0.8574],\n",
      "        [0.7983],\n",
      "        [0.8338],\n",
      "        [0.8851],\n",
      "        [0.8379],\n",
      "        [0.7983]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0003],\n",
      "        [    0.0003],\n",
      "        [    0.0004],\n",
      "        [    0.0003],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0003],\n",
      "        [    0.0003],\n",
      "        [    0.0004],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0014],\n",
      "        [    0.0015],\n",
      "        [    0.0011],\n",
      "        [    0.0017],\n",
      "        [    0.0054],\n",
      "        [    0.0017],\n",
      "        [    0.0018],\n",
      "        [    0.0021],\n",
      "        [    0.0012],\n",
      "        [    0.0061],\n",
      "        [    0.0060],\n",
      "        [    0.0087],\n",
      "        [    0.0209],\n",
      "        [    0.0285],\n",
      "        [    0.0312]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(    0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0008],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0003],\n",
      "        [    0.0002],\n",
      "        [    0.0003],\n",
      "        [    0.0003],\n",
      "        [    0.0007],\n",
      "        [    0.0005],\n",
      "        [    0.0001],\n",
      "        [    0.0007],\n",
      "        [    0.0008],\n",
      "        [    0.0003],\n",
      "        [    0.0010],\n",
      "        [    0.0128],\n",
      "        [    0.0013],\n",
      "        [    0.0014],\n",
      "        [    0.0020],\n",
      "        [    0.0021],\n",
      "        [    0.0062],\n",
      "        [    0.0014],\n",
      "        [    0.0087],\n",
      "        [    0.0208],\n",
      "        [    0.0283],\n",
      "        [    0.0238]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.906806230545044\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 27\n",
      "剩餘X 資料 torch.Size([80, 18])\n",
      "剩餘Y 資料 torch.Size([80, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.000574244128074497, 25)\n",
      "The second_loss value of k: (0.0014133373042568564, 24)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引25，y= tensor([0.8297])\n",
      "目前模型的Data狀態 torch.Size([27, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8974],\n",
      "        [0.9284],\n",
      "        [0.8436],\n",
      "        [0.8057],\n",
      "        [0.8133],\n",
      "        [0.8419],\n",
      "        [0.8450],\n",
      "        [0.9292],\n",
      "        [0.8882],\n",
      "        [0.9136],\n",
      "        [0.9368],\n",
      "        [0.9166],\n",
      "        [0.8542],\n",
      "        [0.8551],\n",
      "        [0.8465],\n",
      "        [0.8057],\n",
      "        [0.8078],\n",
      "        [0.8329],\n",
      "        [0.8057],\n",
      "        [0.9746],\n",
      "        [0.8574],\n",
      "        [0.8057],\n",
      "        [0.8338],\n",
      "        [0.8851],\n",
      "        [0.8377],\n",
      "        [0.8057],\n",
      "        [0.8057]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0008],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0003],\n",
      "        [    0.0002],\n",
      "        [    0.0003],\n",
      "        [    0.0003],\n",
      "        [    0.0007],\n",
      "        [    0.0005],\n",
      "        [    0.0001],\n",
      "        [    0.0007],\n",
      "        [    0.0008],\n",
      "        [    0.0003],\n",
      "        [    0.0010],\n",
      "        [    0.0128],\n",
      "        [    0.0013],\n",
      "        [    0.0014],\n",
      "        [    0.0020],\n",
      "        [    0.0021],\n",
      "        [    0.0062],\n",
      "        [    0.0014],\n",
      "        [    0.0087],\n",
      "        [    0.0208],\n",
      "        [    0.0283],\n",
      "        [    0.0238],\n",
      "        [    0.0240]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(    0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0011],\n",
      "        [    0.0011],\n",
      "        [    0.0059],\n",
      "        [    0.0005],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0010],\n",
      "        [    0.0003],\n",
      "        [    0.0001],\n",
      "        [    0.0006],\n",
      "        [    0.0013],\n",
      "        [    0.0014],\n",
      "        [    0.0008],\n",
      "        [    0.0016],\n",
      "        [    0.0169],\n",
      "        [    0.0033],\n",
      "        [    0.0019],\n",
      "        [    0.0062],\n",
      "        [    0.0015],\n",
      "        [    0.0055],\n",
      "        [    0.0055],\n",
      "        [    0.0081],\n",
      "        [    0.0197],\n",
      "        [    0.0287],\n",
      "        [    0.0197],\n",
      "        [    0.0198]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.15339732170105\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 28\n",
      "剩餘X 資料 torch.Size([79, 18])\n",
      "剩餘Y 資料 torch.Size([79, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0011205145856365561, 24)\n",
      "The second_loss value of k: (0.0013286741450428963, 25)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引24，y= tensor([0.8433])\n",
      "目前模型的Data狀態 torch.Size([28, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8982],\n",
      "        [0.9294],\n",
      "        [0.8446],\n",
      "        [0.8098],\n",
      "        [0.8141],\n",
      "        [0.8427],\n",
      "        [0.8458],\n",
      "        [0.9300],\n",
      "        [0.8886],\n",
      "        [0.9140],\n",
      "        [0.9373],\n",
      "        [0.9172],\n",
      "        [0.8548],\n",
      "        [0.8556],\n",
      "        [0.8470],\n",
      "        [0.8098],\n",
      "        [0.8098],\n",
      "        [0.8334],\n",
      "        [0.8098],\n",
      "        [0.9751],\n",
      "        [0.8580],\n",
      "        [0.8098],\n",
      "        [0.8344],\n",
      "        [0.8862],\n",
      "        [0.8382],\n",
      "        [0.8098],\n",
      "        [0.8098],\n",
      "        [0.8098]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0011],\n",
      "        [    0.0011],\n",
      "        [    0.0059],\n",
      "        [    0.0005],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0010],\n",
      "        [    0.0003],\n",
      "        [    0.0001],\n",
      "        [    0.0006],\n",
      "        [    0.0013],\n",
      "        [    0.0014],\n",
      "        [    0.0008],\n",
      "        [    0.0016],\n",
      "        [    0.0169],\n",
      "        [    0.0033],\n",
      "        [    0.0019],\n",
      "        [    0.0062],\n",
      "        [    0.0015],\n",
      "        [    0.0055],\n",
      "        [    0.0055],\n",
      "        [    0.0081],\n",
      "        [    0.0197],\n",
      "        [    0.0287],\n",
      "        [    0.0197],\n",
      "        [    0.0198],\n",
      "        [    0.0335]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0001],\n",
      "        [    0.0012],\n",
      "        [    0.0011],\n",
      "        [    0.0100],\n",
      "        [    0.0005],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0010],\n",
      "        [    0.0007],\n",
      "        [    0.0003],\n",
      "        [    0.0003],\n",
      "        [    0.0011],\n",
      "        [    0.0013],\n",
      "        [    0.0006],\n",
      "        [    0.0015],\n",
      "        [    0.0211],\n",
      "        [    0.0075],\n",
      "        [    0.0017],\n",
      "        [    0.0104],\n",
      "        [    0.0018],\n",
      "        [    0.0055],\n",
      "        [    0.0097],\n",
      "        [    0.0081],\n",
      "        [    0.0193],\n",
      "        [    0.0285],\n",
      "        [    0.0155],\n",
      "        [    0.0157],\n",
      "        [    0.0293]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.3989813327789307\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 29\n",
      "剩餘X 資料 torch.Size([78, 18])\n",
      "剩餘Y 資料 torch.Size([78, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0010410883696749806, 24)\n",
      "The second_loss value of k: (0.0012392959324643016, 11)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引24，y= tensor([0.8463])\n",
      "目前模型的Data狀態 torch.Size([29, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8981],\n",
      "        [0.9295],\n",
      "        [0.8446],\n",
      "        [0.8140],\n",
      "        [0.8140],\n",
      "        [0.8426],\n",
      "        [0.8458],\n",
      "        [0.9300],\n",
      "        [0.8883],\n",
      "        [0.9138],\n",
      "        [0.9370],\n",
      "        [0.9170],\n",
      "        [0.8546],\n",
      "        [0.8554],\n",
      "        [0.8469],\n",
      "        [0.8140],\n",
      "        [0.8140],\n",
      "        [0.8333],\n",
      "        [0.8140],\n",
      "        [0.9749],\n",
      "        [0.8580],\n",
      "        [0.8140],\n",
      "        [0.8344],\n",
      "        [0.8866],\n",
      "        [0.8380],\n",
      "        [0.8140],\n",
      "        [0.8140],\n",
      "        [0.8140],\n",
      "        [0.8140]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0001],\n",
      "        [    0.0012],\n",
      "        [    0.0011],\n",
      "        [    0.0100],\n",
      "        [    0.0005],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0010],\n",
      "        [    0.0007],\n",
      "        [    0.0003],\n",
      "        [    0.0003],\n",
      "        [    0.0011],\n",
      "        [    0.0013],\n",
      "        [    0.0006],\n",
      "        [    0.0015],\n",
      "        [    0.0211],\n",
      "        [    0.0075],\n",
      "        [    0.0017],\n",
      "        [    0.0104],\n",
      "        [    0.0018],\n",
      "        [    0.0055],\n",
      "        [    0.0097],\n",
      "        [    0.0081],\n",
      "        [    0.0193],\n",
      "        [    0.0285],\n",
      "        [    0.0155],\n",
      "        [    0.0157],\n",
      "        [    0.0293],\n",
      "        [    0.0323]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0014],\n",
      "        [    0.0012],\n",
      "        [    0.0133],\n",
      "        [    0.0037],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0010],\n",
      "        [    0.0008],\n",
      "        [    0.0005],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0013],\n",
      "        [    0.0005],\n",
      "        [    0.0014],\n",
      "        [    0.0244],\n",
      "        [    0.0107],\n",
      "        [    0.0016],\n",
      "        [    0.0136],\n",
      "        [    0.0019],\n",
      "        [    0.0055],\n",
      "        [    0.0130],\n",
      "        [    0.0082],\n",
      "        [    0.0188],\n",
      "        [    0.0283],\n",
      "        [    0.0123],\n",
      "        [    0.0124],\n",
      "        [    0.0261],\n",
      "        [    0.0290]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.6447622776031494\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 30\n",
      "剩餘X 資料 torch.Size([77, 18])\n",
      "剩餘Y 資料 torch.Size([77, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0010218347888439894, 11)\n",
      "The second_loss value of k: (0.0010470279958099127, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引11，y= tensor([0.8492])\n",
      "目前模型的Data狀態 torch.Size([30, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8981],\n",
      "        [0.9297],\n",
      "        [0.8448],\n",
      "        [0.8172],\n",
      "        [0.8172],\n",
      "        [0.8427],\n",
      "        [0.8458],\n",
      "        [0.9300],\n",
      "        [0.8881],\n",
      "        [0.9136],\n",
      "        [0.9369],\n",
      "        [0.9170],\n",
      "        [0.8546],\n",
      "        [0.8553],\n",
      "        [0.8469],\n",
      "        [0.8172],\n",
      "        [0.8172],\n",
      "        [0.8331],\n",
      "        [0.8172],\n",
      "        [0.9748],\n",
      "        [0.8580],\n",
      "        [0.8172],\n",
      "        [0.8343],\n",
      "        [0.8871],\n",
      "        [0.8377],\n",
      "        [0.8172],\n",
      "        [0.8172],\n",
      "        [0.8172],\n",
      "        [0.8172],\n",
      "        [0.8172]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0014],\n",
      "        [    0.0012],\n",
      "        [    0.0133],\n",
      "        [    0.0037],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0010],\n",
      "        [    0.0008],\n",
      "        [    0.0005],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0013],\n",
      "        [    0.0005],\n",
      "        [    0.0014],\n",
      "        [    0.0244],\n",
      "        [    0.0107],\n",
      "        [    0.0016],\n",
      "        [    0.0136],\n",
      "        [    0.0019],\n",
      "        [    0.0055],\n",
      "        [    0.0130],\n",
      "        [    0.0082],\n",
      "        [    0.0188],\n",
      "        [    0.0283],\n",
      "        [    0.0123],\n",
      "        [    0.0124],\n",
      "        [    0.0261],\n",
      "        [    0.0290],\n",
      "        [    0.0320]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0016],\n",
      "        [    0.0014],\n",
      "        [    0.0162],\n",
      "        [    0.0066],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0010],\n",
      "        [    0.0009],\n",
      "        [    0.0005],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0013],\n",
      "        [    0.0005],\n",
      "        [    0.0015],\n",
      "        [    0.0273],\n",
      "        [    0.0136],\n",
      "        [    0.0014],\n",
      "        [    0.0165],\n",
      "        [    0.0020],\n",
      "        [    0.0055],\n",
      "        [    0.0159],\n",
      "        [    0.0083],\n",
      "        [    0.0183],\n",
      "        [    0.0281],\n",
      "        [    0.0094],\n",
      "        [    0.0095],\n",
      "        [    0.0231],\n",
      "        [    0.0261],\n",
      "        [    0.0291]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.8913776874542236\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 31\n",
      "剩餘X 資料 torch.Size([76, 18])\n",
      "剩餘Y 資料 torch.Size([76, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.000866916321683675, 11)\n",
      "The second_loss value of k: (0.0010409461101517081, 23)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引11，y= tensor([0.8496])\n",
      "目前模型的Data狀態 torch.Size([31, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8982],\n",
      "        [0.9299],\n",
      "        [0.8449],\n",
      "        [0.8201],\n",
      "        [0.8201],\n",
      "        [0.8427],\n",
      "        [0.8458],\n",
      "        [0.9300],\n",
      "        [0.8880],\n",
      "        [0.9136],\n",
      "        [0.9369],\n",
      "        [0.9170],\n",
      "        [0.8547],\n",
      "        [0.8552],\n",
      "        [0.8469],\n",
      "        [0.8201],\n",
      "        [0.8201],\n",
      "        [0.8330],\n",
      "        [0.8201],\n",
      "        [0.9747],\n",
      "        [0.8580],\n",
      "        [0.8201],\n",
      "        [0.8343],\n",
      "        [0.8876],\n",
      "        [0.8375],\n",
      "        [0.8201],\n",
      "        [0.8201],\n",
      "        [0.8201],\n",
      "        [0.8201],\n",
      "        [0.8201],\n",
      "        [0.8201]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0016],\n",
      "        [    0.0014],\n",
      "        [    0.0162],\n",
      "        [    0.0066],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0010],\n",
      "        [    0.0009],\n",
      "        [    0.0005],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0013],\n",
      "        [    0.0005],\n",
      "        [    0.0015],\n",
      "        [    0.0273],\n",
      "        [    0.0136],\n",
      "        [    0.0014],\n",
      "        [    0.0165],\n",
      "        [    0.0020],\n",
      "        [    0.0055],\n",
      "        [    0.0159],\n",
      "        [    0.0083],\n",
      "        [    0.0183],\n",
      "        [    0.0281],\n",
      "        [    0.0094],\n",
      "        [    0.0095],\n",
      "        [    0.0231],\n",
      "        [    0.0261],\n",
      "        [    0.0291],\n",
      "        [    0.0294]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0001],\n",
      "        [0.0019],\n",
      "        [0.0016],\n",
      "        [0.0187],\n",
      "        [0.0091],\n",
      "        [0.0006],\n",
      "        [0.0011],\n",
      "        [0.0011],\n",
      "        [0.0009],\n",
      "        [0.0004],\n",
      "        [0.0003],\n",
      "        [0.0012],\n",
      "        [0.0015],\n",
      "        [0.0005],\n",
      "        [0.0016],\n",
      "        [0.0297],\n",
      "        [0.0161],\n",
      "        [0.0014],\n",
      "        [0.0190],\n",
      "        [0.0019],\n",
      "        [0.0055],\n",
      "        [0.0183],\n",
      "        [0.0083],\n",
      "        [0.0178],\n",
      "        [0.0279],\n",
      "        [0.0069],\n",
      "        [0.0070],\n",
      "        [0.0207],\n",
      "        [0.0236],\n",
      "        [0.0266],\n",
      "        [0.0270]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.136087417602539\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 32\n",
      "剩餘X 資料 torch.Size([75, 18])\n",
      "剩餘Y 資料 torch.Size([75, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0008875177591107786, 22)\n",
      "The second_loss value of k: (0.001641992130316794, 11)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引22，y= tensor([0.8524])\n",
      "目前模型的Data狀態 torch.Size([32, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8983],\n",
      "        [0.9302],\n",
      "        [0.8451],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8427],\n",
      "        [0.8458],\n",
      "        [0.9300],\n",
      "        [0.8881],\n",
      "        [0.9137],\n",
      "        [0.9370],\n",
      "        [0.9171],\n",
      "        [0.8548],\n",
      "        [0.8553],\n",
      "        [0.8470],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8329],\n",
      "        [0.8226],\n",
      "        [0.9748],\n",
      "        [0.8581],\n",
      "        [0.8226],\n",
      "        [0.8343],\n",
      "        [0.8881],\n",
      "        [0.8374],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0001],\n",
      "        [0.0019],\n",
      "        [0.0016],\n",
      "        [0.0187],\n",
      "        [0.0091],\n",
      "        [0.0006],\n",
      "        [0.0011],\n",
      "        [0.0011],\n",
      "        [0.0009],\n",
      "        [0.0004],\n",
      "        [0.0003],\n",
      "        [0.0012],\n",
      "        [0.0015],\n",
      "        [0.0005],\n",
      "        [0.0016],\n",
      "        [0.0297],\n",
      "        [0.0161],\n",
      "        [0.0014],\n",
      "        [0.0190],\n",
      "        [0.0019],\n",
      "        [0.0055],\n",
      "        [0.0183],\n",
      "        [0.0083],\n",
      "        [0.0178],\n",
      "        [0.0279],\n",
      "        [0.0069],\n",
      "        [0.0070],\n",
      "        [0.0207],\n",
      "        [0.0236],\n",
      "        [0.0266],\n",
      "        [0.0270],\n",
      "        [0.0298]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0019],\n",
      "        [    0.0015],\n",
      "        [    0.0210],\n",
      "        [    0.0114],\n",
      "        [    0.0005],\n",
      "        [    0.0009],\n",
      "        [    0.0009],\n",
      "        [    0.0010],\n",
      "        [    0.0005],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0014],\n",
      "        [    0.0004],\n",
      "        [    0.0015],\n",
      "        [    0.0320],\n",
      "        [    0.0184],\n",
      "        [    0.0011],\n",
      "        [    0.0213],\n",
      "        [    0.0021],\n",
      "        [    0.0056],\n",
      "        [    0.0206],\n",
      "        [    0.0084],\n",
      "        [    0.0175],\n",
      "        [    0.0276],\n",
      "        [    0.0046],\n",
      "        [    0.0047],\n",
      "        [    0.0184],\n",
      "        [    0.0214],\n",
      "        [    0.0243],\n",
      "        [    0.0247],\n",
      "        [    0.0275]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.381938695907593\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 33\n",
      "剩餘X 資料 torch.Size([74, 18])\n",
      "剩餘Y 資料 torch.Size([74, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0016212385380640626, 11)\n",
      "The second_loss value of k: (0.0018065809272229671, 25)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引11，y= tensor([0.8200])\n",
      "目前模型的Data狀態 torch.Size([33, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8982],\n",
      "        [0.9303],\n",
      "        [0.8451],\n",
      "        [0.8249],\n",
      "        [0.8249],\n",
      "        [0.8426],\n",
      "        [0.8456],\n",
      "        [0.9299],\n",
      "        [0.8879],\n",
      "        [0.9136],\n",
      "        [0.9369],\n",
      "        [0.9171],\n",
      "        [0.8548],\n",
      "        [0.8552],\n",
      "        [0.8469],\n",
      "        [0.8249],\n",
      "        [0.8249],\n",
      "        [0.8327],\n",
      "        [0.8249],\n",
      "        [0.9746],\n",
      "        [0.8580],\n",
      "        [0.8249],\n",
      "        [0.8341],\n",
      "        [0.8884],\n",
      "        [0.8371],\n",
      "        [0.8249],\n",
      "        [0.8249],\n",
      "        [0.8249],\n",
      "        [0.8249],\n",
      "        [0.8249],\n",
      "        [0.8249],\n",
      "        [0.8249],\n",
      "        [0.8602]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0019],\n",
      "        [    0.0015],\n",
      "        [    0.0210],\n",
      "        [    0.0114],\n",
      "        [    0.0005],\n",
      "        [    0.0009],\n",
      "        [    0.0009],\n",
      "        [    0.0010],\n",
      "        [    0.0005],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0014],\n",
      "        [    0.0004],\n",
      "        [    0.0015],\n",
      "        [    0.0320],\n",
      "        [    0.0184],\n",
      "        [    0.0011],\n",
      "        [    0.0213],\n",
      "        [    0.0021],\n",
      "        [    0.0056],\n",
      "        [    0.0206],\n",
      "        [    0.0084],\n",
      "        [    0.0175],\n",
      "        [    0.0276],\n",
      "        [    0.0046],\n",
      "        [    0.0047],\n",
      "        [    0.0184],\n",
      "        [    0.0214],\n",
      "        [    0.0243],\n",
      "        [    0.0247],\n",
      "        [    0.0275],\n",
      "        [    0.0403]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0006],\n",
      "        [0.0025],\n",
      "        [0.0019],\n",
      "        [0.0207],\n",
      "        [0.0111],\n",
      "        [0.0003],\n",
      "        [0.0004],\n",
      "        [0.0003],\n",
      "        [0.0024],\n",
      "        [0.0018],\n",
      "        [0.0016],\n",
      "        [0.0006],\n",
      "        [0.0003],\n",
      "        [0.0014],\n",
      "        [0.0007],\n",
      "        [0.0318],\n",
      "        [0.0181],\n",
      "        [0.0017],\n",
      "        [0.0210],\n",
      "        [0.0030],\n",
      "        [0.0093],\n",
      "        [0.0204],\n",
      "        [0.0124],\n",
      "        [0.0194],\n",
      "        [0.0236],\n",
      "        [0.0049],\n",
      "        [0.0050],\n",
      "        [0.0187],\n",
      "        [0.0216],\n",
      "        [0.0246],\n",
      "        [0.0250],\n",
      "        [0.0278],\n",
      "        [0.0359]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.626824140548706\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 34\n",
      "剩餘X 資料 torch.Size([73, 18])\n",
      "剩餘Y 資料 torch.Size([73, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0018301982199773192, 24)\n",
      "The second_loss value of k: (0.002092688111588359, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引24，y= tensor([0.8674])\n",
      "目前模型的Data狀態 torch.Size([34, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8987],\n",
      "        [0.9308],\n",
      "        [0.8454],\n",
      "        [0.8246],\n",
      "        [0.8246],\n",
      "        [0.8425],\n",
      "        [0.8451],\n",
      "        [0.9293],\n",
      "        [0.8866],\n",
      "        [0.9123],\n",
      "        [0.9351],\n",
      "        [0.9153],\n",
      "        [0.8530],\n",
      "        [0.8534],\n",
      "        [0.8448],\n",
      "        [0.8246],\n",
      "        [0.8246],\n",
      "        [0.8298],\n",
      "        [0.8246],\n",
      "        [0.9737],\n",
      "        [0.8543],\n",
      "        [0.8246],\n",
      "        [0.8301],\n",
      "        [0.8865],\n",
      "        [0.8330],\n",
      "        [0.8246],\n",
      "        [0.8246],\n",
      "        [0.8246],\n",
      "        [0.8246],\n",
      "        [0.8246],\n",
      "        [0.8246],\n",
      "        [0.8246],\n",
      "        [0.8559],\n",
      "        [0.8246]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0006],\n",
      "        [0.0025],\n",
      "        [0.0019],\n",
      "        [0.0207],\n",
      "        [0.0111],\n",
      "        [0.0003],\n",
      "        [0.0004],\n",
      "        [0.0003],\n",
      "        [0.0024],\n",
      "        [0.0018],\n",
      "        [0.0016],\n",
      "        [0.0006],\n",
      "        [0.0003],\n",
      "        [0.0014],\n",
      "        [0.0007],\n",
      "        [0.0318],\n",
      "        [0.0181],\n",
      "        [0.0017],\n",
      "        [0.0210],\n",
      "        [0.0030],\n",
      "        [0.0093],\n",
      "        [0.0204],\n",
      "        [0.0124],\n",
      "        [0.0194],\n",
      "        [0.0236],\n",
      "        [0.0049],\n",
      "        [0.0050],\n",
      "        [0.0187],\n",
      "        [0.0216],\n",
      "        [0.0246],\n",
      "        [0.0250],\n",
      "        [0.0278],\n",
      "        [0.0359],\n",
      "        [0.0428]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0015],\n",
      "        [0.0036],\n",
      "        [0.0027],\n",
      "        [0.0238],\n",
      "        [0.0142],\n",
      "        [0.0010],\n",
      "        [0.0008],\n",
      "        [0.0008],\n",
      "        [0.0021],\n",
      "        [0.0014],\n",
      "        [0.0014],\n",
      "        [0.0004],\n",
      "        [0.0002],\n",
      "        [0.0013],\n",
      "        [0.0007],\n",
      "        [0.0349],\n",
      "        [0.0212],\n",
      "        [0.0023],\n",
      "        [0.0241],\n",
      "        [0.0027],\n",
      "        [0.0103],\n",
      "        [0.0235],\n",
      "        [0.0137],\n",
      "        [0.0193],\n",
      "        [0.0222],\n",
      "        [0.0018],\n",
      "        [0.0019],\n",
      "        [0.0155],\n",
      "        [0.0185],\n",
      "        [0.0214],\n",
      "        [0.0218],\n",
      "        [0.0246],\n",
      "        [0.0344],\n",
      "        [0.0396]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.872408151626587\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 35\n",
      "剩餘X 資料 torch.Size([72, 18])\n",
      "剩餘Y 資料 torch.Size([72, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0019635374192148447, 12)\n",
      "The second_loss value of k: (0.003102437360212207, 23)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([0.8400])\n",
      "目前模型的Data狀態 torch.Size([35, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8997],\n",
      "        [0.9319],\n",
      "        [0.8463],\n",
      "        [0.8278],\n",
      "        [0.8278],\n",
      "        [0.8431],\n",
      "        [0.8455],\n",
      "        [0.9297],\n",
      "        [0.8868],\n",
      "        [0.9127],\n",
      "        [0.9352],\n",
      "        [0.9155],\n",
      "        [0.8531],\n",
      "        [0.8535],\n",
      "        [0.8447],\n",
      "        [0.8278],\n",
      "        [0.8278],\n",
      "        [0.8293],\n",
      "        [0.8278],\n",
      "        [0.9740],\n",
      "        [0.8532],\n",
      "        [0.8278],\n",
      "        [0.8289],\n",
      "        [0.8867],\n",
      "        [0.8317],\n",
      "        [0.8278],\n",
      "        [0.8278],\n",
      "        [0.8278],\n",
      "        [0.8278],\n",
      "        [0.8278],\n",
      "        [0.8278],\n",
      "        [0.8278],\n",
      "        [0.8544],\n",
      "        [0.8278],\n",
      "        [0.8843]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0015],\n",
      "        [0.0036],\n",
      "        [0.0027],\n",
      "        [0.0238],\n",
      "        [0.0142],\n",
      "        [0.0010],\n",
      "        [0.0008],\n",
      "        [0.0008],\n",
      "        [0.0021],\n",
      "        [0.0014],\n",
      "        [0.0014],\n",
      "        [0.0004],\n",
      "        [0.0002],\n",
      "        [0.0013],\n",
      "        [0.0007],\n",
      "        [0.0349],\n",
      "        [0.0212],\n",
      "        [0.0023],\n",
      "        [0.0241],\n",
      "        [0.0027],\n",
      "        [0.0103],\n",
      "        [0.0235],\n",
      "        [0.0137],\n",
      "        [0.0193],\n",
      "        [0.0222],\n",
      "        [0.0018],\n",
      "        [0.0019],\n",
      "        [0.0155],\n",
      "        [0.0185],\n",
      "        [0.0214],\n",
      "        [0.0218],\n",
      "        [0.0246],\n",
      "        [0.0344],\n",
      "        [0.0396],\n",
      "        [0.0443]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0022],\n",
      "        [    0.0040],\n",
      "        [    0.0029],\n",
      "        [    0.0236],\n",
      "        [    0.0140],\n",
      "        [    0.0009],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0035],\n",
      "        [    0.0028],\n",
      "        [    0.0034],\n",
      "        [    0.0025],\n",
      "        [    0.0023],\n",
      "        [    0.0032],\n",
      "        [    0.0030],\n",
      "        [    0.0347],\n",
      "        [    0.0210],\n",
      "        [    0.0040],\n",
      "        [    0.0239],\n",
      "        [    0.0037],\n",
      "        [    0.0151],\n",
      "        [    0.0233],\n",
      "        [    0.0150],\n",
      "        [    0.0214],\n",
      "        [    0.0181],\n",
      "        [    0.0020],\n",
      "        [    0.0021],\n",
      "        [    0.0157],\n",
      "        [    0.0187],\n",
      "        [    0.0216],\n",
      "        [    0.0220],\n",
      "        [    0.0249],\n",
      "        [    0.0291],\n",
      "        [    0.0399],\n",
      "        [    0.0389]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.117682218551636\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 36\n",
      "剩餘X 資料 torch.Size([71, 18])\n",
      "剩餘Y 資料 torch.Size([71, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0031269669998437166, 22)\n",
      "The second_loss value of k: (0.0033187444787472486, 11)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引22，y= tensor([0.8835])\n",
      "目前模型的Data狀態 torch.Size([36, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9003],\n",
      "        [0.9323],\n",
      "        [0.8464],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8430],\n",
      "        [0.8446],\n",
      "        [0.9289],\n",
      "        [0.8854],\n",
      "        [0.9113],\n",
      "        [0.9333],\n",
      "        [0.9134],\n",
      "        [0.8511],\n",
      "        [0.8516],\n",
      "        [0.8424],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.9730],\n",
      "        [0.8485],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8845],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8276],\n",
      "        [0.8491],\n",
      "        [0.8276],\n",
      "        [0.8789],\n",
      "        [0.8276]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0022],\n",
      "        [    0.0040],\n",
      "        [    0.0029],\n",
      "        [    0.0236],\n",
      "        [    0.0140],\n",
      "        [    0.0009],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0035],\n",
      "        [    0.0028],\n",
      "        [    0.0034],\n",
      "        [    0.0025],\n",
      "        [    0.0023],\n",
      "        [    0.0032],\n",
      "        [    0.0030],\n",
      "        [    0.0347],\n",
      "        [    0.0210],\n",
      "        [    0.0040],\n",
      "        [    0.0239],\n",
      "        [    0.0037],\n",
      "        [    0.0151],\n",
      "        [    0.0233],\n",
      "        [    0.0150],\n",
      "        [    0.0214],\n",
      "        [    0.0181],\n",
      "        [    0.0020],\n",
      "        [    0.0021],\n",
      "        [    0.0157],\n",
      "        [    0.0187],\n",
      "        [    0.0216],\n",
      "        [    0.0220],\n",
      "        [    0.0249],\n",
      "        [    0.0291],\n",
      "        [    0.0399],\n",
      "        [    0.0389],\n",
      "        [    0.0559]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0023],\n",
      "        [0.0040],\n",
      "        [0.0026],\n",
      "        [0.0267],\n",
      "        [0.0171],\n",
      "        [0.0006],\n",
      "        [0.0010],\n",
      "        [0.0010],\n",
      "        [0.0042],\n",
      "        [0.0034],\n",
      "        [0.0044],\n",
      "        [0.0037],\n",
      "        [0.0035],\n",
      "        [0.0042],\n",
      "        [0.0040],\n",
      "        [0.0378],\n",
      "        [0.0241],\n",
      "        [0.0009],\n",
      "        [0.0270],\n",
      "        [0.0046],\n",
      "        [0.0185],\n",
      "        [0.0264],\n",
      "        [0.0119],\n",
      "        [0.0224],\n",
      "        [0.0212],\n",
      "        [0.0011],\n",
      "        [0.0010],\n",
      "        [0.0127],\n",
      "        [0.0156],\n",
      "        [0.0186],\n",
      "        [0.0190],\n",
      "        [0.0218],\n",
      "        [0.0252],\n",
      "        [0.0368],\n",
      "        [0.0348],\n",
      "        [0.0528]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.362032175064087\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 37\n",
      "剩餘X 資料 torch.Size([70, 18])\n",
      "剩餘Y 資料 torch.Size([70, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0029087646398693323, 11)\n",
      "The second_loss value of k: (0.0034339958801865578, 20)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引11，y= tensor([0.8145])\n",
      "目前模型的Data狀態 torch.Size([37, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9005],\n",
      "        [0.9323],\n",
      "        [0.8462],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8427],\n",
      "        [0.8436],\n",
      "        [0.9279],\n",
      "        [0.8847],\n",
      "        [0.9107],\n",
      "        [0.9322],\n",
      "        [0.9122],\n",
      "        [0.8499],\n",
      "        [0.8506],\n",
      "        [0.8414],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.9721],\n",
      "        [0.8450],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8835],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8452],\n",
      "        [0.8306],\n",
      "        [0.8748],\n",
      "        [0.8306],\n",
      "        [0.8684]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0023],\n",
      "        [0.0040],\n",
      "        [0.0026],\n",
      "        [0.0267],\n",
      "        [0.0171],\n",
      "        [0.0006],\n",
      "        [0.0010],\n",
      "        [0.0010],\n",
      "        [0.0042],\n",
      "        [0.0034],\n",
      "        [0.0044],\n",
      "        [0.0037],\n",
      "        [0.0035],\n",
      "        [0.0042],\n",
      "        [0.0040],\n",
      "        [0.0378],\n",
      "        [0.0241],\n",
      "        [0.0009],\n",
      "        [0.0270],\n",
      "        [0.0046],\n",
      "        [0.0185],\n",
      "        [0.0264],\n",
      "        [0.0119],\n",
      "        [0.0224],\n",
      "        [0.0212],\n",
      "        [0.0011],\n",
      "        [0.0010],\n",
      "        [0.0127],\n",
      "        [0.0156],\n",
      "        [0.0186],\n",
      "        [0.0190],\n",
      "        [0.0218],\n",
      "        [0.0252],\n",
      "        [0.0368],\n",
      "        [0.0348],\n",
      "        [0.0528],\n",
      "        [0.0539]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0051],\n",
      "        [0.0064],\n",
      "        [0.0046],\n",
      "        [0.0266],\n",
      "        [0.0170],\n",
      "        [0.0021],\n",
      "        [0.0007],\n",
      "        [0.0006],\n",
      "        [0.0044],\n",
      "        [0.0035],\n",
      "        [0.0055],\n",
      "        [0.0050],\n",
      "        [0.0047],\n",
      "        [0.0051],\n",
      "        [0.0057],\n",
      "        [0.0377],\n",
      "        [0.0240],\n",
      "        [0.0010],\n",
      "        [0.0269],\n",
      "        [0.0041],\n",
      "        [0.0243],\n",
      "        [0.0263],\n",
      "        [0.0120],\n",
      "        [0.0242],\n",
      "        [0.0211],\n",
      "        [0.0010],\n",
      "        [0.0009],\n",
      "        [0.0127],\n",
      "        [0.0157],\n",
      "        [0.0186],\n",
      "        [0.0190],\n",
      "        [0.0218],\n",
      "        [0.0186],\n",
      "        [0.0368],\n",
      "        [0.0279],\n",
      "        [0.0529],\n",
      "        [0.0475]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.6060099601745605\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 38\n",
      "剩餘X 資料 torch.Size([69, 18])\n",
      "剩餘Y 資料 torch.Size([69, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0034401461016386747, 19)\n",
      "The second_loss value of k: (0.0038442187942564487, 21)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引19，y= tensor([0.8892])\n",
      "目前模型的Data狀態 torch.Size([38, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9032],\n",
      "        [0.9348],\n",
      "        [0.8481],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8442],\n",
      "        [0.8440],\n",
      "        [0.9283],\n",
      "        [0.8845],\n",
      "        [0.9106],\n",
      "        [0.9312],\n",
      "        [0.9109],\n",
      "        [0.8486],\n",
      "        [0.8496],\n",
      "        [0.8397],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.9726],\n",
      "        [0.8393],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8818],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8306],\n",
      "        [0.8386],\n",
      "        [0.8306],\n",
      "        [0.8680],\n",
      "        [0.8306],\n",
      "        [0.8620],\n",
      "        [0.8306]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0051],\n",
      "        [0.0064],\n",
      "        [0.0046],\n",
      "        [0.0266],\n",
      "        [0.0170],\n",
      "        [0.0021],\n",
      "        [0.0007],\n",
      "        [0.0006],\n",
      "        [0.0044],\n",
      "        [0.0035],\n",
      "        [0.0055],\n",
      "        [0.0050],\n",
      "        [0.0047],\n",
      "        [0.0051],\n",
      "        [0.0057],\n",
      "        [0.0377],\n",
      "        [0.0240],\n",
      "        [0.0010],\n",
      "        [0.0269],\n",
      "        [0.0041],\n",
      "        [0.0243],\n",
      "        [0.0263],\n",
      "        [0.0120],\n",
      "        [0.0242],\n",
      "        [0.0211],\n",
      "        [0.0010],\n",
      "        [0.0009],\n",
      "        [0.0127],\n",
      "        [0.0157],\n",
      "        [0.0186],\n",
      "        [0.0190],\n",
      "        [0.0218],\n",
      "        [0.0186],\n",
      "        [0.0368],\n",
      "        [0.0279],\n",
      "        [0.0529],\n",
      "        [0.0475],\n",
      "        [0.0587]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0066],\n",
      "        [0.0078],\n",
      "        [0.0057],\n",
      "        [0.0298],\n",
      "        [0.0202],\n",
      "        [0.0030],\n",
      "        [0.0005],\n",
      "        [0.0003],\n",
      "        [0.0035],\n",
      "        [0.0026],\n",
      "        [0.0050],\n",
      "        [0.0048],\n",
      "        [0.0045],\n",
      "        [0.0047],\n",
      "        [0.0054],\n",
      "        [0.0409],\n",
      "        [0.0272],\n",
      "        [0.0023],\n",
      "        [0.0301],\n",
      "        [0.0035],\n",
      "        [0.0269],\n",
      "        [0.0295],\n",
      "        [0.0087],\n",
      "        [0.0240],\n",
      "        [0.0244],\n",
      "        [0.0043],\n",
      "        [0.0041],\n",
      "        [0.0095],\n",
      "        [0.0125],\n",
      "        [0.0154],\n",
      "        [0.0158],\n",
      "        [0.0186],\n",
      "        [0.0154],\n",
      "        [0.0336],\n",
      "        [0.0246],\n",
      "        [0.0497],\n",
      "        [0.0446],\n",
      "        [0.0554]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.851851940155029\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 39\n",
      "剩餘X 資料 torch.Size([68, 18])\n",
      "剩餘Y 資料 torch.Size([68, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0034559029154479504, 20)\n",
      "The second_loss value of k: (0.00410307664424181, 19)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引20，y= tensor([0.8926])\n",
      "目前模型的Data狀態 torch.Size([39, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9048],\n",
      "        [0.9361],\n",
      "        [0.8492],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8452],\n",
      "        [0.8442],\n",
      "        [0.9286],\n",
      "        [0.8854],\n",
      "        [0.9115],\n",
      "        [0.9316],\n",
      "        [0.9111],\n",
      "        [0.8489],\n",
      "        [0.8501],\n",
      "        [0.8400],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.9732],\n",
      "        [0.8367],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8819],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8338],\n",
      "        [0.8354],\n",
      "        [0.8338],\n",
      "        [0.8646],\n",
      "        [0.8338],\n",
      "        [0.8590],\n",
      "        [0.8338],\n",
      "        [0.8338]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0066],\n",
      "        [0.0078],\n",
      "        [0.0057],\n",
      "        [0.0298],\n",
      "        [0.0202],\n",
      "        [0.0030],\n",
      "        [0.0005],\n",
      "        [0.0003],\n",
      "        [0.0035],\n",
      "        [0.0026],\n",
      "        [0.0050],\n",
      "        [0.0048],\n",
      "        [0.0045],\n",
      "        [0.0047],\n",
      "        [0.0054],\n",
      "        [0.0409],\n",
      "        [0.0272],\n",
      "        [0.0023],\n",
      "        [0.0301],\n",
      "        [0.0035],\n",
      "        [0.0269],\n",
      "        [0.0295],\n",
      "        [0.0087],\n",
      "        [0.0240],\n",
      "        [0.0244],\n",
      "        [0.0043],\n",
      "        [0.0041],\n",
      "        [0.0095],\n",
      "        [0.0125],\n",
      "        [0.0154],\n",
      "        [0.0158],\n",
      "        [0.0186],\n",
      "        [0.0154],\n",
      "        [0.0336],\n",
      "        [0.0246],\n",
      "        [0.0497],\n",
      "        [0.0446],\n",
      "        [0.0554],\n",
      "        [0.0588]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0065],\n",
      "        [0.0075],\n",
      "        [0.0051],\n",
      "        [0.0332],\n",
      "        [0.0236],\n",
      "        [0.0026],\n",
      "        [0.0015],\n",
      "        [0.0012],\n",
      "        [0.0036],\n",
      "        [0.0027],\n",
      "        [0.0054],\n",
      "        [0.0054],\n",
      "        [0.0050],\n",
      "        [0.0050],\n",
      "        [0.0058],\n",
      "        [0.0443],\n",
      "        [0.0306],\n",
      "        [0.0056],\n",
      "        [0.0335],\n",
      "        [0.0039],\n",
      "        [0.0264],\n",
      "        [0.0329],\n",
      "        [0.0054],\n",
      "        [0.0244],\n",
      "        [0.0277],\n",
      "        [0.0076],\n",
      "        [0.0075],\n",
      "        [0.0061],\n",
      "        [0.0091],\n",
      "        [0.0120],\n",
      "        [0.0124],\n",
      "        [0.0152],\n",
      "        [0.0172],\n",
      "        [0.0302],\n",
      "        [0.0214],\n",
      "        [0.0463],\n",
      "        [0.0418],\n",
      "        [0.0521],\n",
      "        [0.0554]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.113485813140869\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 40\n",
      "剩餘X 資料 torch.Size([67, 18])\n",
      "剩餘Y 資料 torch.Size([67, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003680641297250986, 19)\n",
      "The second_loss value of k: (0.004181379918009043, 17)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引19，y= tensor([0.8978])\n",
      "目前模型的Data狀態 torch.Size([40, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9046],\n",
      "        [0.9359],\n",
      "        [0.8486],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8448],\n",
      "        [0.8432],\n",
      "        [0.9278],\n",
      "        [0.8853],\n",
      "        [0.9114],\n",
      "        [0.9313],\n",
      "        [0.9105],\n",
      "        [0.8483],\n",
      "        [0.8497],\n",
      "        [0.8397],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.9728],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8815],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8614],\n",
      "        [0.8372],\n",
      "        [0.8562],\n",
      "        [0.8372],\n",
      "        [0.8372],\n",
      "        [0.8372]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0065],\n",
      "        [0.0075],\n",
      "        [0.0051],\n",
      "        [0.0332],\n",
      "        [0.0236],\n",
      "        [0.0026],\n",
      "        [0.0015],\n",
      "        [0.0012],\n",
      "        [0.0036],\n",
      "        [0.0027],\n",
      "        [0.0054],\n",
      "        [0.0054],\n",
      "        [0.0050],\n",
      "        [0.0050],\n",
      "        [0.0058],\n",
      "        [0.0443],\n",
      "        [0.0306],\n",
      "        [0.0056],\n",
      "        [0.0335],\n",
      "        [0.0039],\n",
      "        [0.0264],\n",
      "        [0.0329],\n",
      "        [0.0054],\n",
      "        [0.0244],\n",
      "        [0.0277],\n",
      "        [0.0076],\n",
      "        [0.0075],\n",
      "        [0.0061],\n",
      "        [0.0091],\n",
      "        [0.0120],\n",
      "        [0.0124],\n",
      "        [0.0152],\n",
      "        [0.0172],\n",
      "        [0.0302],\n",
      "        [0.0214],\n",
      "        [0.0463],\n",
      "        [0.0418],\n",
      "        [0.0521],\n",
      "        [0.0554],\n",
      "        [0.0607]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0055],\n",
      "        [0.0064],\n",
      "        [0.0037],\n",
      "        [0.0360],\n",
      "        [0.0264],\n",
      "        [0.0013],\n",
      "        [0.0033],\n",
      "        [0.0028],\n",
      "        [0.0051],\n",
      "        [0.0043],\n",
      "        [0.0072],\n",
      "        [0.0075],\n",
      "        [0.0070],\n",
      "        [0.0068],\n",
      "        [0.0055],\n",
      "        [0.0471],\n",
      "        [0.0334],\n",
      "        [0.0084],\n",
      "        [0.0363],\n",
      "        [0.0053],\n",
      "        [0.0236],\n",
      "        [0.0357],\n",
      "        [0.0026],\n",
      "        [0.0262],\n",
      "        [0.0305],\n",
      "        [0.0104],\n",
      "        [0.0103],\n",
      "        [0.0033],\n",
      "        [0.0063],\n",
      "        [0.0093],\n",
      "        [0.0096],\n",
      "        [0.0125],\n",
      "        [0.0200],\n",
      "        [0.0275],\n",
      "        [0.0168],\n",
      "        [0.0435],\n",
      "        [0.0375],\n",
      "        [0.0493],\n",
      "        [0.0526],\n",
      "        [0.0579]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.443876504898071\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 41\n",
      "剩餘X 資料 torch.Size([66, 18])\n",
      "剩餘Y 資料 torch.Size([66, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003831280395388603, 17)\n",
      "The second_loss value of k: (0.004555018153041601, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.9018])\n",
      "目前模型的Data狀態 torch.Size([41, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9037],\n",
      "        [0.9347],\n",
      "        [0.8472],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8435],\n",
      "        [0.8414],\n",
      "        [0.9261],\n",
      "        [0.8838],\n",
      "        [0.9098],\n",
      "        [0.9295],\n",
      "        [0.9085],\n",
      "        [0.8464],\n",
      "        [0.8480],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.9714],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8797],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8568],\n",
      "        [0.8399],\n",
      "        [0.8519],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399],\n",
      "        [0.8399]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0055],\n",
      "        [0.0064],\n",
      "        [0.0037],\n",
      "        [0.0360],\n",
      "        [0.0264],\n",
      "        [0.0013],\n",
      "        [0.0033],\n",
      "        [0.0028],\n",
      "        [0.0051],\n",
      "        [0.0043],\n",
      "        [0.0072],\n",
      "        [0.0075],\n",
      "        [0.0070],\n",
      "        [0.0068],\n",
      "        [0.0055],\n",
      "        [0.0471],\n",
      "        [0.0334],\n",
      "        [0.0084],\n",
      "        [0.0363],\n",
      "        [0.0053],\n",
      "        [0.0236],\n",
      "        [0.0357],\n",
      "        [0.0026],\n",
      "        [0.0262],\n",
      "        [0.0305],\n",
      "        [0.0104],\n",
      "        [0.0103],\n",
      "        [0.0033],\n",
      "        [0.0063],\n",
      "        [0.0093],\n",
      "        [0.0096],\n",
      "        [0.0125],\n",
      "        [0.0200],\n",
      "        [0.0275],\n",
      "        [0.0168],\n",
      "        [0.0435],\n",
      "        [0.0375],\n",
      "        [0.0493],\n",
      "        [0.0526],\n",
      "        [0.0579],\n",
      "        [0.0619]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0058],\n",
      "        [    0.0065],\n",
      "        [    0.0035],\n",
      "        [    0.0386],\n",
      "        [    0.0290],\n",
      "        [    0.0013],\n",
      "        [    0.0022],\n",
      "        [    0.0033],\n",
      "        [    0.0047],\n",
      "        [    0.0039],\n",
      "        [    0.0071],\n",
      "        [    0.0076],\n",
      "        [    0.0071],\n",
      "        [    0.0067],\n",
      "        [    0.0029],\n",
      "        [    0.0497],\n",
      "        [    0.0360],\n",
      "        [    0.0110],\n",
      "        [    0.0389],\n",
      "        [    0.0051],\n",
      "        [    0.0210],\n",
      "        [    0.0383],\n",
      "        [    0.0000],\n",
      "        [    0.0261],\n",
      "        [    0.0331],\n",
      "        [    0.0130],\n",
      "        [    0.0129],\n",
      "        [    0.0008],\n",
      "        [    0.0037],\n",
      "        [    0.0067],\n",
      "        [    0.0071],\n",
      "        [    0.0099],\n",
      "        [    0.0225],\n",
      "        [    0.0249],\n",
      "        [    0.0139],\n",
      "        [    0.0409],\n",
      "        [    0.0350],\n",
      "        [    0.0467],\n",
      "        [    0.0501],\n",
      "        [    0.0553],\n",
      "        [    0.0593]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.691776752471924\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 42\n",
      "剩餘X 資料 torch.Size([65, 18])\n",
      "剩餘Y 資料 torch.Size([65, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004498649854212999, 18)\n",
      "The second_loss value of k: (0.0045783319510519505, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引18，y= tensor([0.9096])\n",
      "目前模型的Data狀態 torch.Size([42, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9039],\n",
      "        [0.9348],\n",
      "        [0.8470],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8434],\n",
      "        [0.8425],\n",
      "        [0.9257],\n",
      "        [0.8842],\n",
      "        [0.9102],\n",
      "        [0.9296],\n",
      "        [0.9083],\n",
      "        [0.8462],\n",
      "        [0.8480],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.9716],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8798],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8539],\n",
      "        [0.8425],\n",
      "        [0.8495],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425],\n",
      "        [0.8425]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0058],\n",
      "        [    0.0065],\n",
      "        [    0.0035],\n",
      "        [    0.0386],\n",
      "        [    0.0290],\n",
      "        [    0.0013],\n",
      "        [    0.0022],\n",
      "        [    0.0033],\n",
      "        [    0.0047],\n",
      "        [    0.0039],\n",
      "        [    0.0071],\n",
      "        [    0.0076],\n",
      "        [    0.0071],\n",
      "        [    0.0067],\n",
      "        [    0.0029],\n",
      "        [    0.0497],\n",
      "        [    0.0360],\n",
      "        [    0.0110],\n",
      "        [    0.0389],\n",
      "        [    0.0051],\n",
      "        [    0.0210],\n",
      "        [    0.0383],\n",
      "        [    0.0000],\n",
      "        [    0.0261],\n",
      "        [    0.0331],\n",
      "        [    0.0130],\n",
      "        [    0.0129],\n",
      "        [    0.0008],\n",
      "        [    0.0037],\n",
      "        [    0.0067],\n",
      "        [    0.0071],\n",
      "        [    0.0099],\n",
      "        [    0.0225],\n",
      "        [    0.0249],\n",
      "        [    0.0139],\n",
      "        [    0.0409],\n",
      "        [    0.0350],\n",
      "        [    0.0467],\n",
      "        [    0.0501],\n",
      "        [    0.0553],\n",
      "        [    0.0593],\n",
      "        [    0.0671]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0059],\n",
      "        [0.0064],\n",
      "        [0.0032],\n",
      "        [0.0410],\n",
      "        [0.0314],\n",
      "        [0.0028],\n",
      "        [0.0003],\n",
      "        [0.0038],\n",
      "        [0.0043],\n",
      "        [0.0036],\n",
      "        [0.0068],\n",
      "        [0.0076],\n",
      "        [0.0071],\n",
      "        [0.0066],\n",
      "        [0.0005],\n",
      "        [0.0521],\n",
      "        [0.0384],\n",
      "        [0.0134],\n",
      "        [0.0413],\n",
      "        [0.0049],\n",
      "        [0.0186],\n",
      "        [0.0407],\n",
      "        [0.0024],\n",
      "        [0.0259],\n",
      "        [0.0355],\n",
      "        [0.0154],\n",
      "        [0.0153],\n",
      "        [0.0017],\n",
      "        [0.0013],\n",
      "        [0.0042],\n",
      "        [0.0046],\n",
      "        [0.0074],\n",
      "        [0.0250],\n",
      "        [0.0225],\n",
      "        [0.0116],\n",
      "        [0.0385],\n",
      "        [0.0330],\n",
      "        [0.0443],\n",
      "        [0.0476],\n",
      "        [0.0529],\n",
      "        [0.0569],\n",
      "        [0.0646]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.939965009689331\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 43\n",
      "剩餘X 資料 torch.Size([64, 18])\n",
      "剩餘Y 資料 torch.Size([64, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004594058264046907, 2)\n",
      "The second_loss value of k: (0.0069925058633089066, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引2，y= tensor([0.9994])\n",
      "目前模型的Data狀態 torch.Size([43, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9040],\n",
      "        [0.9347],\n",
      "        [0.8467],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.9252],\n",
      "        [0.8847],\n",
      "        [0.9105],\n",
      "        [0.9299],\n",
      "        [0.9083],\n",
      "        [0.8462],\n",
      "        [0.8482],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.9718],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8800],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8516],\n",
      "        [0.8450],\n",
      "        [0.8475],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [0.8450],\n",
      "        [1.0672]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0059],\n",
      "        [0.0064],\n",
      "        [0.0032],\n",
      "        [0.0410],\n",
      "        [0.0314],\n",
      "        [0.0028],\n",
      "        [0.0003],\n",
      "        [0.0038],\n",
      "        [0.0043],\n",
      "        [0.0036],\n",
      "        [0.0068],\n",
      "        [0.0076],\n",
      "        [0.0071],\n",
      "        [0.0066],\n",
      "        [0.0005],\n",
      "        [0.0521],\n",
      "        [0.0384],\n",
      "        [0.0134],\n",
      "        [0.0413],\n",
      "        [0.0049],\n",
      "        [0.0186],\n",
      "        [0.0407],\n",
      "        [0.0024],\n",
      "        [0.0259],\n",
      "        [0.0355],\n",
      "        [0.0154],\n",
      "        [0.0153],\n",
      "        [0.0017],\n",
      "        [0.0013],\n",
      "        [0.0042],\n",
      "        [0.0046],\n",
      "        [0.0074],\n",
      "        [0.0250],\n",
      "        [0.0225],\n",
      "        [0.0116],\n",
      "        [0.0385],\n",
      "        [0.0330],\n",
      "        [0.0443],\n",
      "        [0.0476],\n",
      "        [0.0529],\n",
      "        [0.0569],\n",
      "        [0.0646],\n",
      "        [0.0678]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0024],\n",
      "        [    0.0029],\n",
      "        [    0.0012],\n",
      "        [    0.0408],\n",
      "        [    0.0312],\n",
      "        [    0.0026],\n",
      "        [    0.0001],\n",
      "        [    0.0070],\n",
      "        [    0.0077],\n",
      "        [    0.0069],\n",
      "        [    0.0101],\n",
      "        [    0.0108],\n",
      "        [    0.0086],\n",
      "        [    0.0097],\n",
      "        [    0.0007],\n",
      "        [    0.0519],\n",
      "        [    0.0382],\n",
      "        [    0.0132],\n",
      "        [    0.0411],\n",
      "        [    0.0084],\n",
      "        [    0.0188],\n",
      "        [    0.0405],\n",
      "        [    0.0022],\n",
      "        [    0.0289],\n",
      "        [    0.0353],\n",
      "        [    0.0152],\n",
      "        [    0.0151],\n",
      "        [    0.0015],\n",
      "        [    0.0015],\n",
      "        [    0.0044],\n",
      "        [    0.0048],\n",
      "        [    0.0076],\n",
      "        [    0.0248],\n",
      "        [    0.0226],\n",
      "        [    0.0089],\n",
      "        [    0.0387],\n",
      "        [    0.0303],\n",
      "        [    0.0445],\n",
      "        [    0.0478],\n",
      "        [    0.0531],\n",
      "        [    0.0571],\n",
      "        [    0.0648],\n",
      "        [    0.0643]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.189358711242676\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 44\n",
      "剩餘X 資料 torch.Size([63, 18])\n",
      "剩餘Y 資料 torch.Size([63, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.006761885713785887, 17)\n",
      "The second_loss value of k: (0.00758030079305172, 8)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.9200])\n",
      "目前模型的Data狀態 torch.Size([44, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9005],\n",
      "        [0.9312],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.9219],\n",
      "        [0.8813],\n",
      "        [0.9072],\n",
      "        [0.9266],\n",
      "        [0.9051],\n",
      "        [0.8448],\n",
      "        [0.8450],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.9683],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8770],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8489],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [0.8448],\n",
      "        [1.0637],\n",
      "        [1.0022]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0024],\n",
      "        [    0.0029],\n",
      "        [    0.0012],\n",
      "        [    0.0408],\n",
      "        [    0.0312],\n",
      "        [    0.0026],\n",
      "        [    0.0001],\n",
      "        [    0.0070],\n",
      "        [    0.0077],\n",
      "        [    0.0069],\n",
      "        [    0.0101],\n",
      "        [    0.0108],\n",
      "        [    0.0086],\n",
      "        [    0.0097],\n",
      "        [    0.0007],\n",
      "        [    0.0519],\n",
      "        [    0.0382],\n",
      "        [    0.0132],\n",
      "        [    0.0411],\n",
      "        [    0.0084],\n",
      "        [    0.0188],\n",
      "        [    0.0405],\n",
      "        [    0.0022],\n",
      "        [    0.0289],\n",
      "        [    0.0353],\n",
      "        [    0.0152],\n",
      "        [    0.0151],\n",
      "        [    0.0015],\n",
      "        [    0.0015],\n",
      "        [    0.0044],\n",
      "        [    0.0048],\n",
      "        [    0.0076],\n",
      "        [    0.0248],\n",
      "        [    0.0226],\n",
      "        [    0.0089],\n",
      "        [    0.0387],\n",
      "        [    0.0303],\n",
      "        [    0.0445],\n",
      "        [    0.0478],\n",
      "        [    0.0531],\n",
      "        [    0.0571],\n",
      "        [    0.0648],\n",
      "        [    0.0643],\n",
      "        [    0.0822]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0048],\n",
      "        [0.0046],\n",
      "        [0.0008],\n",
      "        [0.0404],\n",
      "        [0.0308],\n",
      "        [0.0022],\n",
      "        [0.0004],\n",
      "        [0.0155],\n",
      "        [0.0129],\n",
      "        [0.0116],\n",
      "        [0.0154],\n",
      "        [0.0167],\n",
      "        [0.0090],\n",
      "        [0.0104],\n",
      "        [0.0011],\n",
      "        [0.0515],\n",
      "        [0.0378],\n",
      "        [0.0128],\n",
      "        [0.0407],\n",
      "        [0.0185],\n",
      "        [0.0192],\n",
      "        [0.0401],\n",
      "        [0.0018],\n",
      "        [0.0372],\n",
      "        [0.0349],\n",
      "        [0.0148],\n",
      "        [0.0147],\n",
      "        [0.0010],\n",
      "        [0.0019],\n",
      "        [0.0049],\n",
      "        [0.0053],\n",
      "        [0.0081],\n",
      "        [0.0243],\n",
      "        [0.0231],\n",
      "        [0.0043],\n",
      "        [0.0391],\n",
      "        [0.0299],\n",
      "        [0.0449],\n",
      "        [0.0483],\n",
      "        [0.0535],\n",
      "        [0.0575],\n",
      "        [0.0653],\n",
      "        [0.0520],\n",
      "        [0.0716]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.43016791343689\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 45\n",
      "剩餘X 資料 torch.Size([62, 18])\n",
      "剩餘Y 資料 torch.Size([62, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.006123173050582409, 17)\n",
      "The second_loss value of k: (0.00756777822971344, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.9354])\n",
      "目前模型的Data狀態 torch.Size([45, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8933],\n",
      "        [0.9237],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.9134],\n",
      "        [0.8761],\n",
      "        [0.9025],\n",
      "        [0.9212],\n",
      "        [0.8992],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.9582],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8687],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [0.8443],\n",
      "        [1.0514],\n",
      "        [0.9915],\n",
      "        [1.0137]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0048],\n",
      "        [0.0046],\n",
      "        [0.0008],\n",
      "        [0.0404],\n",
      "        [0.0308],\n",
      "        [0.0022],\n",
      "        [0.0004],\n",
      "        [0.0155],\n",
      "        [0.0129],\n",
      "        [0.0116],\n",
      "        [0.0154],\n",
      "        [0.0167],\n",
      "        [0.0090],\n",
      "        [0.0104],\n",
      "        [0.0011],\n",
      "        [0.0515],\n",
      "        [0.0378],\n",
      "        [0.0128],\n",
      "        [0.0407],\n",
      "        [0.0185],\n",
      "        [0.0192],\n",
      "        [0.0401],\n",
      "        [0.0018],\n",
      "        [0.0372],\n",
      "        [0.0349],\n",
      "        [0.0148],\n",
      "        [0.0147],\n",
      "        [0.0010],\n",
      "        [0.0019],\n",
      "        [0.0049],\n",
      "        [0.0053],\n",
      "        [0.0081],\n",
      "        [0.0243],\n",
      "        [0.0231],\n",
      "        [0.0043],\n",
      "        [0.0391],\n",
      "        [0.0299],\n",
      "        [0.0449],\n",
      "        [0.0483],\n",
      "        [0.0535],\n",
      "        [0.0575],\n",
      "        [0.0653],\n",
      "        [0.0520],\n",
      "        [0.0716],\n",
      "        [0.0783]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0016],\n",
      "        [    0.0025],\n",
      "        [    0.0012],\n",
      "        [    0.0407],\n",
      "        [    0.0311],\n",
      "        [    0.0025],\n",
      "        [    0.0000],\n",
      "        [    0.0139],\n",
      "        [    0.0127],\n",
      "        [    0.0111],\n",
      "        [    0.0171],\n",
      "        [    0.0184],\n",
      "        [    0.0087],\n",
      "        [    0.0101],\n",
      "        [    0.0007],\n",
      "        [    0.0518],\n",
      "        [    0.0381],\n",
      "        [    0.0132],\n",
      "        [    0.0410],\n",
      "        [    0.0202],\n",
      "        [    0.0188],\n",
      "        [    0.0404],\n",
      "        [    0.0021],\n",
      "        [    0.0455],\n",
      "        [    0.0352],\n",
      "        [    0.0152],\n",
      "        [    0.0150],\n",
      "        [    0.0014],\n",
      "        [    0.0016],\n",
      "        [    0.0045],\n",
      "        [    0.0049],\n",
      "        [    0.0077],\n",
      "        [    0.0247],\n",
      "        [    0.0227],\n",
      "        [    0.0047],\n",
      "        [    0.0388],\n",
      "        [    0.0302],\n",
      "        [    0.0445],\n",
      "        [    0.0479],\n",
      "        [    0.0532],\n",
      "        [    0.0572],\n",
      "        [    0.0649],\n",
      "        [    0.0487],\n",
      "        [    0.0605],\n",
      "        [    0.0654]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.669908046722412\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 46\n",
      "剩餘X 資料 torch.Size([61, 18])\n",
      "剩餘Y 資料 torch.Size([61, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.006651627831161022, 18)\n",
      "The second_loss value of k: (0.007215707562863827, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引18，y= tensor([0.9552])\n",
      "目前模型的Data狀態 torch.Size([46, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8965],\n",
      "        [0.9258],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.9151],\n",
      "        [0.8763],\n",
      "        [0.9030],\n",
      "        [0.9196],\n",
      "        [0.8975],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.9565],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8605],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [0.8447],\n",
      "        [1.0481],\n",
      "        [0.9805],\n",
      "        [1.0008],\n",
      "        [1.0368]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0016],\n",
      "        [    0.0025],\n",
      "        [    0.0012],\n",
      "        [    0.0407],\n",
      "        [    0.0311],\n",
      "        [    0.0025],\n",
      "        [    0.0000],\n",
      "        [    0.0139],\n",
      "        [    0.0127],\n",
      "        [    0.0111],\n",
      "        [    0.0171],\n",
      "        [    0.0184],\n",
      "        [    0.0087],\n",
      "        [    0.0101],\n",
      "        [    0.0007],\n",
      "        [    0.0518],\n",
      "        [    0.0381],\n",
      "        [    0.0132],\n",
      "        [    0.0410],\n",
      "        [    0.0202],\n",
      "        [    0.0188],\n",
      "        [    0.0404],\n",
      "        [    0.0021],\n",
      "        [    0.0455],\n",
      "        [    0.0352],\n",
      "        [    0.0152],\n",
      "        [    0.0150],\n",
      "        [    0.0014],\n",
      "        [    0.0016],\n",
      "        [    0.0045],\n",
      "        [    0.0049],\n",
      "        [    0.0077],\n",
      "        [    0.0247],\n",
      "        [    0.0227],\n",
      "        [    0.0047],\n",
      "        [    0.0388],\n",
      "        [    0.0302],\n",
      "        [    0.0445],\n",
      "        [    0.0479],\n",
      "        [    0.0532],\n",
      "        [    0.0572],\n",
      "        [    0.0649],\n",
      "        [    0.0487],\n",
      "        [    0.0605],\n",
      "        [    0.0654],\n",
      "        [    0.0816]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0092],\n",
      "        [0.0117],\n",
      "        [0.0022],\n",
      "        [0.0417],\n",
      "        [0.0321],\n",
      "        [0.0035],\n",
      "        [0.0010],\n",
      "        [0.0210],\n",
      "        [0.0240],\n",
      "        [0.0224],\n",
      "        [0.0313],\n",
      "        [0.0324],\n",
      "        [0.0077],\n",
      "        [0.0091],\n",
      "        [0.0003],\n",
      "        [0.0528],\n",
      "        [0.0392],\n",
      "        [0.0142],\n",
      "        [0.0421],\n",
      "        [0.0319],\n",
      "        [0.0178],\n",
      "        [0.0414],\n",
      "        [0.0032],\n",
      "        [0.0602],\n",
      "        [0.0363],\n",
      "        [0.0162],\n",
      "        [0.0160],\n",
      "        [0.0024],\n",
      "        [0.0006],\n",
      "        [0.0035],\n",
      "        [0.0039],\n",
      "        [0.0067],\n",
      "        [0.0257],\n",
      "        [0.0217],\n",
      "        [0.0057],\n",
      "        [0.0378],\n",
      "        [0.0312],\n",
      "        [0.0435],\n",
      "        [0.0469],\n",
      "        [0.0521],\n",
      "        [0.0561],\n",
      "        [0.0639],\n",
      "        [0.0354],\n",
      "        [0.0337],\n",
      "        [0.0359],\n",
      "        [0.0488]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.909741401672363\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 47\n",
      "剩餘X 資料 torch.Size([60, 18])\n",
      "剩餘Y 資料 torch.Size([60, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005201407708227634, 17)\n",
      "The second_loss value of k: (0.005374446045607328, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.9594])\n",
      "目前模型的Data狀態 torch.Size([47, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8889],\n",
      "        [0.9166],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.9080],\n",
      "        [0.8649],\n",
      "        [0.8917],\n",
      "        [0.9054],\n",
      "        [0.8835],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.9447],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [0.8457],\n",
      "        [1.0348],\n",
      "        [0.9537],\n",
      "        [0.9713],\n",
      "        [1.0040],\n",
      "        [1.0315]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0092],\n",
      "        [0.0117],\n",
      "        [0.0022],\n",
      "        [0.0417],\n",
      "        [0.0321],\n",
      "        [0.0035],\n",
      "        [0.0010],\n",
      "        [0.0210],\n",
      "        [0.0240],\n",
      "        [0.0224],\n",
      "        [0.0313],\n",
      "        [0.0324],\n",
      "        [0.0077],\n",
      "        [0.0091],\n",
      "        [0.0003],\n",
      "        [0.0528],\n",
      "        [0.0392],\n",
      "        [0.0142],\n",
      "        [0.0421],\n",
      "        [0.0319],\n",
      "        [0.0178],\n",
      "        [0.0414],\n",
      "        [0.0032],\n",
      "        [0.0602],\n",
      "        [0.0363],\n",
      "        [0.0162],\n",
      "        [0.0160],\n",
      "        [0.0024],\n",
      "        [0.0006],\n",
      "        [0.0035],\n",
      "        [0.0039],\n",
      "        [0.0067],\n",
      "        [0.0257],\n",
      "        [0.0217],\n",
      "        [0.0057],\n",
      "        [0.0378],\n",
      "        [0.0312],\n",
      "        [0.0435],\n",
      "        [0.0469],\n",
      "        [0.0521],\n",
      "        [0.0561],\n",
      "        [0.0639],\n",
      "        [0.0354],\n",
      "        [0.0337],\n",
      "        [0.0359],\n",
      "        [0.0488],\n",
      "        [0.0721]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0015],\n",
      "        [0.0027],\n",
      "        [0.0030],\n",
      "        [0.0425],\n",
      "        [0.0329],\n",
      "        [0.0043],\n",
      "        [0.0018],\n",
      "        [0.0110],\n",
      "        [0.0173],\n",
      "        [0.0157],\n",
      "        [0.0278],\n",
      "        [0.0290],\n",
      "        [0.0069],\n",
      "        [0.0083],\n",
      "        [0.0011],\n",
      "        [0.0536],\n",
      "        [0.0400],\n",
      "        [0.0150],\n",
      "        [0.0429],\n",
      "        [0.0248],\n",
      "        [0.0170],\n",
      "        [0.0422],\n",
      "        [0.0040],\n",
      "        [0.0594],\n",
      "        [0.0371],\n",
      "        [0.0170],\n",
      "        [0.0168],\n",
      "        [0.0032],\n",
      "        [0.0002],\n",
      "        [0.0027],\n",
      "        [0.0031],\n",
      "        [0.0059],\n",
      "        [0.0265],\n",
      "        [0.0209],\n",
      "        [0.0065],\n",
      "        [0.0370],\n",
      "        [0.0320],\n",
      "        [0.0427],\n",
      "        [0.0461],\n",
      "        [0.0514],\n",
      "        [0.0553],\n",
      "        [0.0631],\n",
      "        [0.0411],\n",
      "        [0.0233],\n",
      "        [0.0227],\n",
      "        [0.0328],\n",
      "        [0.0567]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.150225400924683\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 48\n",
      "剩餘X 資料 torch.Size([59, 18])\n",
      "剩餘Y 資料 torch.Size([59, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0053296806290745735, 17)\n",
      "The second_loss value of k: (0.0063458578661084175, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.9203])\n",
      "目前模型的Data狀態 torch.Size([48, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8997],\n",
      "        [0.9257],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.9180],\n",
      "        [0.8717],\n",
      "        [0.8984],\n",
      "        [0.9088],\n",
      "        [0.8869],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.9519],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [1.0405],\n",
      "        [0.9433],\n",
      "        [0.9582],\n",
      "        [0.9880],\n",
      "        [1.0161],\n",
      "        [0.9933]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0015],\n",
      "        [0.0027],\n",
      "        [0.0030],\n",
      "        [0.0425],\n",
      "        [0.0329],\n",
      "        [0.0043],\n",
      "        [0.0018],\n",
      "        [0.0110],\n",
      "        [0.0173],\n",
      "        [0.0157],\n",
      "        [0.0278],\n",
      "        [0.0290],\n",
      "        [0.0069],\n",
      "        [0.0083],\n",
      "        [0.0011],\n",
      "        [0.0536],\n",
      "        [0.0400],\n",
      "        [0.0150],\n",
      "        [0.0429],\n",
      "        [0.0248],\n",
      "        [0.0170],\n",
      "        [0.0422],\n",
      "        [0.0040],\n",
      "        [0.0594],\n",
      "        [0.0371],\n",
      "        [0.0170],\n",
      "        [0.0168],\n",
      "        [0.0032],\n",
      "        [0.0002],\n",
      "        [0.0027],\n",
      "        [0.0031],\n",
      "        [0.0059],\n",
      "        [0.0265],\n",
      "        [0.0209],\n",
      "        [0.0065],\n",
      "        [0.0370],\n",
      "        [0.0320],\n",
      "        [0.0427],\n",
      "        [0.0461],\n",
      "        [0.0514],\n",
      "        [0.0553],\n",
      "        [0.0631],\n",
      "        [0.0411],\n",
      "        [0.0233],\n",
      "        [0.0227],\n",
      "        [0.0328],\n",
      "        [0.0567],\n",
      "        [0.0730]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0011],\n",
      "        [0.0066],\n",
      "        [0.0023],\n",
      "        [0.0419],\n",
      "        [0.0323],\n",
      "        [0.0037],\n",
      "        [0.0011],\n",
      "        [0.0125],\n",
      "        [0.0214],\n",
      "        [0.0199],\n",
      "        [0.0347],\n",
      "        [0.0359],\n",
      "        [0.0075],\n",
      "        [0.0089],\n",
      "        [0.0004],\n",
      "        [0.0530],\n",
      "        [0.0393],\n",
      "        [0.0143],\n",
      "        [0.0422],\n",
      "        [0.0290],\n",
      "        [0.0177],\n",
      "        [0.0416],\n",
      "        [0.0033],\n",
      "        [0.0601],\n",
      "        [0.0364],\n",
      "        [0.0163],\n",
      "        [0.0162],\n",
      "        [0.0026],\n",
      "        [0.0004],\n",
      "        [0.0034],\n",
      "        [0.0037],\n",
      "        [0.0066],\n",
      "        [0.0259],\n",
      "        [0.0216],\n",
      "        [0.0058],\n",
      "        [0.0376],\n",
      "        [0.0314],\n",
      "        [0.0434],\n",
      "        [0.0467],\n",
      "        [0.0520],\n",
      "        [0.0560],\n",
      "        [0.0638],\n",
      "        [0.0356],\n",
      "        [0.0040],\n",
      "        [0.0010],\n",
      "        [0.0079],\n",
      "        [0.0328],\n",
      "        [0.0477]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.38898491859436\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 49\n",
      "剩餘X 資料 torch.Size([58, 18])\n",
      "剩餘Y 資料 torch.Size([58, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0056228614412248135, 0)\n",
      "The second_loss value of k: (0.009594081901013851, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.9821])\n",
      "目前模型的Data狀態 torch.Size([49, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8971],\n",
      "        [0.9217],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.9164],\n",
      "        [0.8675],\n",
      "        [0.8942],\n",
      "        [0.9019],\n",
      "        [0.8800],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.9477],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [0.8458],\n",
      "        [1.0350],\n",
      "        [0.9239],\n",
      "        [0.9364],\n",
      "        [0.9631],\n",
      "        [0.9922],\n",
      "        [0.9680],\n",
      "        [1.0571]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0011],\n",
      "        [0.0066],\n",
      "        [0.0023],\n",
      "        [0.0419],\n",
      "        [0.0323],\n",
      "        [0.0037],\n",
      "        [0.0011],\n",
      "        [0.0125],\n",
      "        [0.0214],\n",
      "        [0.0199],\n",
      "        [0.0347],\n",
      "        [0.0359],\n",
      "        [0.0075],\n",
      "        [0.0089],\n",
      "        [0.0004],\n",
      "        [0.0530],\n",
      "        [0.0393],\n",
      "        [0.0143],\n",
      "        [0.0422],\n",
      "        [0.0290],\n",
      "        [0.0177],\n",
      "        [0.0416],\n",
      "        [0.0033],\n",
      "        [0.0601],\n",
      "        [0.0364],\n",
      "        [0.0163],\n",
      "        [0.0162],\n",
      "        [0.0026],\n",
      "        [0.0004],\n",
      "        [0.0034],\n",
      "        [0.0037],\n",
      "        [0.0066],\n",
      "        [0.0259],\n",
      "        [0.0216],\n",
      "        [0.0058],\n",
      "        [0.0376],\n",
      "        [0.0314],\n",
      "        [0.0434],\n",
      "        [0.0467],\n",
      "        [0.0520],\n",
      "        [0.0560],\n",
      "        [0.0638],\n",
      "        [0.0356],\n",
      "        [0.0040],\n",
      "        [0.0010],\n",
      "        [0.0079],\n",
      "        [0.0328],\n",
      "        [0.0477],\n",
      "        [0.0750]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0042],\n",
      "        [0.0107],\n",
      "        [0.0024],\n",
      "        [0.0420],\n",
      "        [0.0324],\n",
      "        [0.0038],\n",
      "        [0.0012],\n",
      "        [0.0172],\n",
      "        [0.0188],\n",
      "        [0.0173],\n",
      "        [0.0331],\n",
      "        [0.0350],\n",
      "        [0.0074],\n",
      "        [0.0088],\n",
      "        [0.0005],\n",
      "        [0.0531],\n",
      "        [0.0394],\n",
      "        [0.0144],\n",
      "        [0.0423],\n",
      "        [0.0323],\n",
      "        [0.0176],\n",
      "        [0.0417],\n",
      "        [0.0034],\n",
      "        [0.0600],\n",
      "        [0.0365],\n",
      "        [0.0164],\n",
      "        [0.0163],\n",
      "        [0.0027],\n",
      "        [0.0003],\n",
      "        [0.0033],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0260],\n",
      "        [0.0215],\n",
      "        [0.0059],\n",
      "        [0.0375],\n",
      "        [0.0315],\n",
      "        [0.0433],\n",
      "        [0.0466],\n",
      "        [0.0519],\n",
      "        [0.0559],\n",
      "        [0.0637],\n",
      "        [0.0289],\n",
      "        [0.0017],\n",
      "        [0.0049],\n",
      "        [0.0002],\n",
      "        [0.0250],\n",
      "        [0.0399],\n",
      "        [0.0667]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.627624034881592\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 50\n",
      "剩餘X 資料 torch.Size([57, 18])\n",
      "剩餘Y 資料 torch.Size([57, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.009334818460047245, 0)\n",
      "The second_loss value of k: (0.009575140662491322, 8)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.9747])\n",
      "目前模型的Data狀態 torch.Size([50, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8940],\n",
      "        [0.9176],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.9117],\n",
      "        [0.8702],\n",
      "        [0.8968],\n",
      "        [0.9035],\n",
      "        [0.8809],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.9444],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [0.8459],\n",
      "        [1.0283],\n",
      "        [0.9183],\n",
      "        [0.9306],\n",
      "        [0.9550],\n",
      "        [0.9844],\n",
      "        [0.9602],\n",
      "        [1.0488],\n",
      "        [1.0714]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0042],\n",
      "        [0.0107],\n",
      "        [0.0024],\n",
      "        [0.0420],\n",
      "        [0.0324],\n",
      "        [0.0038],\n",
      "        [0.0012],\n",
      "        [0.0172],\n",
      "        [0.0188],\n",
      "        [0.0173],\n",
      "        [0.0331],\n",
      "        [0.0350],\n",
      "        [0.0074],\n",
      "        [0.0088],\n",
      "        [0.0005],\n",
      "        [0.0531],\n",
      "        [0.0394],\n",
      "        [0.0144],\n",
      "        [0.0423],\n",
      "        [0.0323],\n",
      "        [0.0176],\n",
      "        [0.0417],\n",
      "        [0.0034],\n",
      "        [0.0600],\n",
      "        [0.0365],\n",
      "        [0.0164],\n",
      "        [0.0163],\n",
      "        [0.0027],\n",
      "        [0.0003],\n",
      "        [0.0033],\n",
      "        [0.0036],\n",
      "        [0.0065],\n",
      "        [0.0260],\n",
      "        [0.0215],\n",
      "        [0.0059],\n",
      "        [0.0375],\n",
      "        [0.0315],\n",
      "        [0.0433],\n",
      "        [0.0466],\n",
      "        [0.0519],\n",
      "        [0.0559],\n",
      "        [0.0637],\n",
      "        [0.0289],\n",
      "        [0.0017],\n",
      "        [0.0049],\n",
      "        [0.0002],\n",
      "        [0.0250],\n",
      "        [0.0399],\n",
      "        [0.0667],\n",
      "        [0.0966]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0066],\n",
      "        [0.0138],\n",
      "        [0.0030],\n",
      "        [0.0426],\n",
      "        [0.0330],\n",
      "        [0.0044],\n",
      "        [0.0018],\n",
      "        [0.0238],\n",
      "        [0.0130],\n",
      "        [0.0113],\n",
      "        [0.0279],\n",
      "        [0.0310],\n",
      "        [0.0068],\n",
      "        [0.0082],\n",
      "        [0.0011],\n",
      "        [0.0537],\n",
      "        [0.0400],\n",
      "        [0.0150],\n",
      "        [0.0429],\n",
      "        [0.0368],\n",
      "        [0.0170],\n",
      "        [0.0423],\n",
      "        [0.0040],\n",
      "        [0.0594],\n",
      "        [0.0371],\n",
      "        [0.0170],\n",
      "        [0.0169],\n",
      "        [0.0033],\n",
      "        [0.0003],\n",
      "        [0.0027],\n",
      "        [0.0031],\n",
      "        [0.0059],\n",
      "        [0.0266],\n",
      "        [0.0209],\n",
      "        [0.0065],\n",
      "        [0.0369],\n",
      "        [0.0321],\n",
      "        [0.0427],\n",
      "        [0.0460],\n",
      "        [0.0513],\n",
      "        [0.0553],\n",
      "        [0.0631],\n",
      "        [0.0192],\n",
      "        [0.0018],\n",
      "        [0.0041],\n",
      "        [0.0014],\n",
      "        [0.0236],\n",
      "        [0.0393],\n",
      "        [0.0547],\n",
      "        [0.0840]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.867730140686035\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 51\n",
      "剩餘X 資料 torch.Size([56, 18])\n",
      "剩餘Y 資料 torch.Size([56, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.009459031745791435, 7)\n",
      "The second_loss value of k: (0.009960989467799664, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引7，y= tensor([0.9438])\n",
      "目前模型的Data狀態 torch.Size([51, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8915],\n",
      "        [0.9145],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.9052],\n",
      "        [0.8759],\n",
      "        [0.9028],\n",
      "        [0.9088],\n",
      "        [0.8849],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.9399],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [0.8465],\n",
      "        [1.0186],\n",
      "        [0.9182],\n",
      "        [0.9314],\n",
      "        [0.9538],\n",
      "        [0.9830],\n",
      "        [0.9596],\n",
      "        [1.0368],\n",
      "        [1.0587],\n",
      "        [0.8465]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0066],\n",
      "        [0.0138],\n",
      "        [0.0030],\n",
      "        [0.0426],\n",
      "        [0.0330],\n",
      "        [0.0044],\n",
      "        [0.0018],\n",
      "        [0.0238],\n",
      "        [0.0130],\n",
      "        [0.0113],\n",
      "        [0.0279],\n",
      "        [0.0310],\n",
      "        [0.0068],\n",
      "        [0.0082],\n",
      "        [0.0011],\n",
      "        [0.0537],\n",
      "        [0.0400],\n",
      "        [0.0150],\n",
      "        [0.0429],\n",
      "        [0.0368],\n",
      "        [0.0170],\n",
      "        [0.0423],\n",
      "        [0.0040],\n",
      "        [0.0594],\n",
      "        [0.0371],\n",
      "        [0.0170],\n",
      "        [0.0169],\n",
      "        [0.0033],\n",
      "        [0.0003],\n",
      "        [0.0027],\n",
      "        [0.0031],\n",
      "        [0.0059],\n",
      "        [0.0266],\n",
      "        [0.0209],\n",
      "        [0.0065],\n",
      "        [0.0369],\n",
      "        [0.0321],\n",
      "        [0.0427],\n",
      "        [0.0460],\n",
      "        [0.0513],\n",
      "        [0.0553],\n",
      "        [0.0631],\n",
      "        [0.0192],\n",
      "        [0.0018],\n",
      "        [0.0041],\n",
      "        [0.0014],\n",
      "        [0.0236],\n",
      "        [0.0393],\n",
      "        [0.0547],\n",
      "        [0.0840],\n",
      "        [0.0973]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0102],\n",
      "        [0.0181],\n",
      "        [0.0052],\n",
      "        [0.0447],\n",
      "        [0.0351],\n",
      "        [0.0065],\n",
      "        [0.0040],\n",
      "        [0.0302],\n",
      "        [0.0120],\n",
      "        [0.0103],\n",
      "        [0.0275],\n",
      "        [0.0314],\n",
      "        [0.0047],\n",
      "        [0.0061],\n",
      "        [0.0032],\n",
      "        [0.0558],\n",
      "        [0.0421],\n",
      "        [0.0171],\n",
      "        [0.0450],\n",
      "        [0.0426],\n",
      "        [0.0149],\n",
      "        [0.0444],\n",
      "        [0.0061],\n",
      "        [0.0572],\n",
      "        [0.0392],\n",
      "        [0.0191],\n",
      "        [0.0190],\n",
      "        [0.0054],\n",
      "        [0.0024],\n",
      "        [0.0005],\n",
      "        [0.0009],\n",
      "        [0.0037],\n",
      "        [0.0287],\n",
      "        [0.0187],\n",
      "        [0.0086],\n",
      "        [0.0348],\n",
      "        [0.0342],\n",
      "        [0.0406],\n",
      "        [0.0439],\n",
      "        [0.0492],\n",
      "        [0.0532],\n",
      "        [0.0609],\n",
      "        [0.0095],\n",
      "        [0.0057],\n",
      "        [0.0077],\n",
      "        [0.0068],\n",
      "        [0.0179],\n",
      "        [0.0342],\n",
      "        [0.0436],\n",
      "        [0.0721],\n",
      "        [0.0951]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.107506036758423\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 52\n",
      "剩餘X 資料 torch.Size([55, 18])\n",
      "剩餘Y 資料 torch.Size([55, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00981830433011055, 6)\n",
      "The second_loss value of k: (0.010704209096729755, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.9673])\n",
      "目前模型的Data狀態 torch.Size([52, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8880],\n",
      "        [0.9103],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8988],\n",
      "        [0.8769],\n",
      "        [0.9038],\n",
      "        [0.9091],\n",
      "        [0.8845],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.9341],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [0.8487],\n",
      "        [1.0089],\n",
      "        [0.9143],\n",
      "        [0.9277],\n",
      "        [0.9484],\n",
      "        [0.9773],\n",
      "        [0.9545],\n",
      "        [1.0257],\n",
      "        [1.0468],\n",
      "        [0.8487],\n",
      "        [0.8682]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0102],\n",
      "        [0.0181],\n",
      "        [0.0052],\n",
      "        [0.0447],\n",
      "        [0.0351],\n",
      "        [0.0065],\n",
      "        [0.0040],\n",
      "        [0.0302],\n",
      "        [0.0120],\n",
      "        [0.0103],\n",
      "        [0.0275],\n",
      "        [0.0314],\n",
      "        [0.0047],\n",
      "        [0.0061],\n",
      "        [0.0032],\n",
      "        [0.0558],\n",
      "        [0.0421],\n",
      "        [0.0171],\n",
      "        [0.0450],\n",
      "        [0.0426],\n",
      "        [0.0149],\n",
      "        [0.0444],\n",
      "        [0.0061],\n",
      "        [0.0572],\n",
      "        [0.0392],\n",
      "        [0.0191],\n",
      "        [0.0190],\n",
      "        [0.0054],\n",
      "        [0.0024],\n",
      "        [0.0005],\n",
      "        [0.0009],\n",
      "        [0.0037],\n",
      "        [0.0287],\n",
      "        [0.0187],\n",
      "        [0.0086],\n",
      "        [0.0348],\n",
      "        [0.0342],\n",
      "        [0.0406],\n",
      "        [0.0439],\n",
      "        [0.0492],\n",
      "        [0.0532],\n",
      "        [0.0609],\n",
      "        [0.0095],\n",
      "        [0.0057],\n",
      "        [0.0077],\n",
      "        [0.0068],\n",
      "        [0.0179],\n",
      "        [0.0342],\n",
      "        [0.0436],\n",
      "        [0.0721],\n",
      "        [0.0951],\n",
      "        [0.0991]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0023],\n",
      "        [    0.0111],\n",
      "        [    0.0051],\n",
      "        [    0.0446],\n",
      "        [    0.0351],\n",
      "        [    0.0065],\n",
      "        [    0.0039],\n",
      "        [    0.0265],\n",
      "        [    0.0025],\n",
      "        [    0.0035],\n",
      "        [    0.0151],\n",
      "        [    0.0197],\n",
      "        [    0.0047],\n",
      "        [    0.0039],\n",
      "        [    0.0032],\n",
      "        [    0.0557],\n",
      "        [    0.0421],\n",
      "        [    0.0171],\n",
      "        [    0.0450],\n",
      "        [    0.0356],\n",
      "        [    0.0149],\n",
      "        [    0.0443],\n",
      "        [    0.0061],\n",
      "        [    0.0573],\n",
      "        [    0.0392],\n",
      "        [    0.0191],\n",
      "        [    0.0190],\n",
      "        [    0.0053],\n",
      "        [    0.0023],\n",
      "        [    0.0006],\n",
      "        [    0.0010],\n",
      "        [    0.0038],\n",
      "        [    0.0286],\n",
      "        [    0.0188],\n",
      "        [    0.0086],\n",
      "        [    0.0349],\n",
      "        [    0.0342],\n",
      "        [    0.0406],\n",
      "        [    0.0440],\n",
      "        [    0.0492],\n",
      "        [    0.0532],\n",
      "        [    0.0610],\n",
      "        [    0.0113],\n",
      "        [    0.0000],\n",
      "        [    0.0015],\n",
      "        [    0.0030],\n",
      "        [    0.0216],\n",
      "        [    0.0386],\n",
      "        [    0.0420],\n",
      "        [    0.0704],\n",
      "        [    0.0952],\n",
      "        [    0.0846]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.346630811691284\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 53\n",
      "剩餘X 資料 torch.Size([54, 18])\n",
      "剩餘Y 資料 torch.Size([54, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010718372650444508, 11)\n",
      "The second_loss value of k: (0.010897550731897354, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引11，y= tensor([0.9521])\n",
      "目前模型的Data狀態 torch.Size([53, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8959],\n",
      "        [0.9172],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.9025],\n",
      "        [0.8915],\n",
      "        [0.9176],\n",
      "        [0.9216],\n",
      "        [0.8962],\n",
      "        [0.8486],\n",
      "        [0.8509],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.9411],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [0.8486],\n",
      "        [1.0107],\n",
      "        [0.9200],\n",
      "        [0.9339],\n",
      "        [0.9523],\n",
      "        [0.9810],\n",
      "        [0.9589],\n",
      "        [1.0241],\n",
      "        [1.0451],\n",
      "        [0.8486],\n",
      "        [0.8827],\n",
      "        [0.8486]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0023],\n",
      "        [    0.0111],\n",
      "        [    0.0051],\n",
      "        [    0.0446],\n",
      "        [    0.0351],\n",
      "        [    0.0065],\n",
      "        [    0.0039],\n",
      "        [    0.0265],\n",
      "        [    0.0025],\n",
      "        [    0.0035],\n",
      "        [    0.0151],\n",
      "        [    0.0197],\n",
      "        [    0.0047],\n",
      "        [    0.0039],\n",
      "        [    0.0032],\n",
      "        [    0.0557],\n",
      "        [    0.0421],\n",
      "        [    0.0171],\n",
      "        [    0.0450],\n",
      "        [    0.0356],\n",
      "        [    0.0149],\n",
      "        [    0.0443],\n",
      "        [    0.0061],\n",
      "        [    0.0573],\n",
      "        [    0.0392],\n",
      "        [    0.0191],\n",
      "        [    0.0190],\n",
      "        [    0.0053],\n",
      "        [    0.0023],\n",
      "        [    0.0006],\n",
      "        [    0.0010],\n",
      "        [    0.0038],\n",
      "        [    0.0286],\n",
      "        [    0.0188],\n",
      "        [    0.0086],\n",
      "        [    0.0349],\n",
      "        [    0.0342],\n",
      "        [    0.0406],\n",
      "        [    0.0440],\n",
      "        [    0.0492],\n",
      "        [    0.0532],\n",
      "        [    0.0610],\n",
      "        [    0.0113],\n",
      "        [    0.0000],\n",
      "        [    0.0015],\n",
      "        [    0.0030],\n",
      "        [    0.0216],\n",
      "        [    0.0386],\n",
      "        [    0.0420],\n",
      "        [    0.0704],\n",
      "        [    0.0952],\n",
      "        [    0.0846],\n",
      "        [    0.1035]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0021],\n",
      "        [0.0115],\n",
      "        [0.0079],\n",
      "        [0.0474],\n",
      "        [0.0378],\n",
      "        [0.0092],\n",
      "        [0.0067],\n",
      "        [0.0282],\n",
      "        [0.0061],\n",
      "        [0.0065],\n",
      "        [0.0127],\n",
      "        [0.0176],\n",
      "        [0.0020],\n",
      "        [0.0003],\n",
      "        [0.0060],\n",
      "        [0.0585],\n",
      "        [0.0449],\n",
      "        [0.0199],\n",
      "        [0.0478],\n",
      "        [0.0363],\n",
      "        [0.0121],\n",
      "        [0.0471],\n",
      "        [0.0089],\n",
      "        [0.0545],\n",
      "        [0.0420],\n",
      "        [0.0219],\n",
      "        [0.0217],\n",
      "        [0.0081],\n",
      "        [0.0051],\n",
      "        [0.0022],\n",
      "        [0.0018],\n",
      "        [0.0010],\n",
      "        [0.0314],\n",
      "        [0.0160],\n",
      "        [0.0114],\n",
      "        [0.0321],\n",
      "        [0.0369],\n",
      "        [0.0378],\n",
      "        [0.0412],\n",
      "        [0.0465],\n",
      "        [0.0504],\n",
      "        [0.0582],\n",
      "        [0.0075],\n",
      "        [0.0014],\n",
      "        [0.0028],\n",
      "        [0.0058],\n",
      "        [0.0185],\n",
      "        [0.0359],\n",
      "        [0.0364],\n",
      "        [0.0645],\n",
      "        [0.0924],\n",
      "        [0.0810],\n",
      "        [0.1007]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.586409091949463\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 54\n",
      "剩餘X 資料 torch.Size([53, 18])\n",
      "剩餘Y 資料 torch.Size([53, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.01032295823097229, 6)\n",
      "The second_loss value of k: (0.010894502513110638, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.9530])\n",
      "目前模型的Data狀態 torch.Size([54, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8961],\n",
      "        [0.9168],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.9007],\n",
      "        [0.8950],\n",
      "        [0.9206],\n",
      "        [0.9239],\n",
      "        [0.8983],\n",
      "        [0.8514],\n",
      "        [0.8545],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.9404],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [0.8514],\n",
      "        [1.0069],\n",
      "        [0.9186],\n",
      "        [0.9326],\n",
      "        [0.9494],\n",
      "        [0.9779],\n",
      "        [0.9562],\n",
      "        [1.0185],\n",
      "        [1.0392],\n",
      "        [0.8514],\n",
      "        [0.8863],\n",
      "        [0.8514],\n",
      "        [0.8514]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0021],\n",
      "        [0.0115],\n",
      "        [0.0079],\n",
      "        [0.0474],\n",
      "        [0.0378],\n",
      "        [0.0092],\n",
      "        [0.0067],\n",
      "        [0.0282],\n",
      "        [0.0061],\n",
      "        [0.0065],\n",
      "        [0.0127],\n",
      "        [0.0176],\n",
      "        [0.0020],\n",
      "        [0.0003],\n",
      "        [0.0060],\n",
      "        [0.0585],\n",
      "        [0.0449],\n",
      "        [0.0199],\n",
      "        [0.0478],\n",
      "        [0.0363],\n",
      "        [0.0121],\n",
      "        [0.0471],\n",
      "        [0.0089],\n",
      "        [0.0545],\n",
      "        [0.0420],\n",
      "        [0.0219],\n",
      "        [0.0217],\n",
      "        [0.0081],\n",
      "        [0.0051],\n",
      "        [0.0022],\n",
      "        [0.0018],\n",
      "        [0.0010],\n",
      "        [0.0314],\n",
      "        [0.0160],\n",
      "        [0.0114],\n",
      "        [0.0321],\n",
      "        [0.0369],\n",
      "        [0.0378],\n",
      "        [0.0412],\n",
      "        [0.0465],\n",
      "        [0.0504],\n",
      "        [0.0582],\n",
      "        [0.0075],\n",
      "        [0.0014],\n",
      "        [0.0028],\n",
      "        [0.0058],\n",
      "        [0.0185],\n",
      "        [0.0359],\n",
      "        [0.0364],\n",
      "        [0.0645],\n",
      "        [0.0924],\n",
      "        [0.0810],\n",
      "        [0.1007],\n",
      "        [0.1016]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0009],\n",
      "        [0.0108],\n",
      "        [0.0108],\n",
      "        [0.0503],\n",
      "        [0.0407],\n",
      "        [0.0121],\n",
      "        [0.0096],\n",
      "        [0.0286],\n",
      "        [0.0097],\n",
      "        [0.0096],\n",
      "        [0.0104],\n",
      "        [0.0153],\n",
      "        [0.0009],\n",
      "        [0.0033],\n",
      "        [0.0088],\n",
      "        [0.0614],\n",
      "        [0.0477],\n",
      "        [0.0227],\n",
      "        [0.0506],\n",
      "        [0.0358],\n",
      "        [0.0093],\n",
      "        [0.0500],\n",
      "        [0.0117],\n",
      "        [0.0516],\n",
      "        [0.0448],\n",
      "        [0.0247],\n",
      "        [0.0246],\n",
      "        [0.0110],\n",
      "        [0.0080],\n",
      "        [0.0051],\n",
      "        [0.0047],\n",
      "        [0.0019],\n",
      "        [0.0343],\n",
      "        [0.0131],\n",
      "        [0.0142],\n",
      "        [0.0292],\n",
      "        [0.0398],\n",
      "        [0.0350],\n",
      "        [0.0383],\n",
      "        [0.0436],\n",
      "        [0.0476],\n",
      "        [0.0553],\n",
      "        [0.0053],\n",
      "        [0.0020],\n",
      "        [0.0033],\n",
      "        [0.0077],\n",
      "        [0.0165],\n",
      "        [0.0341],\n",
      "        [0.0326],\n",
      "        [0.0604],\n",
      "        [0.0895],\n",
      "        [0.0774],\n",
      "        [0.0979],\n",
      "        [0.0987]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.825871229171753\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 55\n",
      "剩餘X 資料 torch.Size([52, 18])\n",
      "剩餘Y 資料 torch.Size([52, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010118706151843071, 4)\n",
      "The second_loss value of k: (0.012694369070231915, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([0.9834])\n",
      "目前模型的Data狀態 torch.Size([55, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8973],\n",
      "        [0.9175],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.9004],\n",
      "        [0.8986],\n",
      "        [0.9237],\n",
      "        [0.9263],\n",
      "        [0.9006],\n",
      "        [0.8543],\n",
      "        [0.8580],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.9409],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [1.0047],\n",
      "        [0.9180],\n",
      "        [0.9321],\n",
      "        [0.9476],\n",
      "        [0.9758],\n",
      "        [0.9544],\n",
      "        [1.0147],\n",
      "        [1.0352],\n",
      "        [0.8543],\n",
      "        [0.8900],\n",
      "        [0.8543],\n",
      "        [0.8543],\n",
      "        [0.8828]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0009],\n",
      "        [0.0108],\n",
      "        [0.0108],\n",
      "        [0.0503],\n",
      "        [0.0407],\n",
      "        [0.0121],\n",
      "        [0.0096],\n",
      "        [0.0286],\n",
      "        [0.0097],\n",
      "        [0.0096],\n",
      "        [0.0104],\n",
      "        [0.0153],\n",
      "        [0.0009],\n",
      "        [0.0033],\n",
      "        [0.0088],\n",
      "        [0.0614],\n",
      "        [0.0477],\n",
      "        [0.0227],\n",
      "        [0.0506],\n",
      "        [0.0358],\n",
      "        [0.0093],\n",
      "        [0.0500],\n",
      "        [0.0117],\n",
      "        [0.0516],\n",
      "        [0.0448],\n",
      "        [0.0247],\n",
      "        [0.0246],\n",
      "        [0.0110],\n",
      "        [0.0080],\n",
      "        [0.0051],\n",
      "        [0.0047],\n",
      "        [0.0019],\n",
      "        [0.0343],\n",
      "        [0.0131],\n",
      "        [0.0142],\n",
      "        [0.0292],\n",
      "        [0.0398],\n",
      "        [0.0350],\n",
      "        [0.0383],\n",
      "        [0.0436],\n",
      "        [0.0476],\n",
      "        [0.0553],\n",
      "        [0.0053],\n",
      "        [0.0020],\n",
      "        [0.0033],\n",
      "        [0.0077],\n",
      "        [0.0165],\n",
      "        [0.0341],\n",
      "        [0.0326],\n",
      "        [0.0604],\n",
      "        [0.0895],\n",
      "        [0.0774],\n",
      "        [0.0979],\n",
      "        [0.0987],\n",
      "        [0.1006]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0047],\n",
      "        [0.0082],\n",
      "        [0.0477],\n",
      "        [0.0381],\n",
      "        [0.0158],\n",
      "        [0.0070],\n",
      "        [0.0247],\n",
      "        [0.0207],\n",
      "        [0.0192],\n",
      "        [0.0015],\n",
      "        [0.0067],\n",
      "        [0.0057],\n",
      "        [0.0129],\n",
      "        [0.0065],\n",
      "        [0.0588],\n",
      "        [0.0451],\n",
      "        [0.0202],\n",
      "        [0.0480],\n",
      "        [0.0286],\n",
      "        [0.0118],\n",
      "        [0.0474],\n",
      "        [0.0092],\n",
      "        [0.0542],\n",
      "        [0.0423],\n",
      "        [0.0222],\n",
      "        [0.0220],\n",
      "        [0.0084],\n",
      "        [0.0054],\n",
      "        [0.0025],\n",
      "        [0.0021],\n",
      "        [0.0007],\n",
      "        [0.0317],\n",
      "        [0.0157],\n",
      "        [0.0117],\n",
      "        [0.0318],\n",
      "        [0.0372],\n",
      "        [0.0375],\n",
      "        [0.0409],\n",
      "        [0.0462],\n",
      "        [0.0502],\n",
      "        [0.0579],\n",
      "        [0.0089],\n",
      "        [0.0031],\n",
      "        [0.0025],\n",
      "        [0.0034],\n",
      "        [0.0205],\n",
      "        [0.0386],\n",
      "        [0.0329],\n",
      "        [0.0611],\n",
      "        [0.0854],\n",
      "        [0.0659],\n",
      "        [0.1004],\n",
      "        [0.1013],\n",
      "        [0.0882]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.064334630966187\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 56\n",
      "剩餘X 資料 torch.Size([51, 18])\n",
      "剩餘Y 資料 torch.Size([51, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.011747895739972591, 4)\n",
      "The second_loss value of k: (0.013282560743391514, 8)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([0.9800])\n",
      "目前模型的Data狀態 torch.Size([56, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9039],\n",
      "        [0.9236],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8579],\n",
      "        [0.8517],\n",
      "        [0.9042],\n",
      "        [0.9096],\n",
      "        [0.9333],\n",
      "        [0.9352],\n",
      "        [0.9092],\n",
      "        [0.8591],\n",
      "        [0.8676],\n",
      "        [0.8519],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.9481],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [1.0083],\n",
      "        [0.9231],\n",
      "        [0.9379],\n",
      "        [0.9519],\n",
      "        [0.9799],\n",
      "        [0.9589],\n",
      "        [1.0150],\n",
      "        [1.0359],\n",
      "        [0.8584],\n",
      "        [0.9014],\n",
      "        [0.8517],\n",
      "        [0.8517],\n",
      "        [0.8952],\n",
      "        [0.8716]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0047],\n",
      "        [0.0082],\n",
      "        [0.0477],\n",
      "        [0.0381],\n",
      "        [0.0158],\n",
      "        [0.0070],\n",
      "        [0.0247],\n",
      "        [0.0207],\n",
      "        [0.0192],\n",
      "        [0.0015],\n",
      "        [0.0067],\n",
      "        [0.0057],\n",
      "        [0.0129],\n",
      "        [0.0065],\n",
      "        [0.0588],\n",
      "        [0.0451],\n",
      "        [0.0202],\n",
      "        [0.0480],\n",
      "        [0.0286],\n",
      "        [0.0118],\n",
      "        [0.0474],\n",
      "        [0.0092],\n",
      "        [0.0542],\n",
      "        [0.0423],\n",
      "        [0.0222],\n",
      "        [0.0220],\n",
      "        [0.0084],\n",
      "        [0.0054],\n",
      "        [0.0025],\n",
      "        [0.0021],\n",
      "        [0.0007],\n",
      "        [0.0317],\n",
      "        [0.0157],\n",
      "        [0.0117],\n",
      "        [0.0318],\n",
      "        [0.0372],\n",
      "        [0.0375],\n",
      "        [0.0409],\n",
      "        [0.0462],\n",
      "        [0.0502],\n",
      "        [0.0579],\n",
      "        [0.0089],\n",
      "        [0.0031],\n",
      "        [0.0025],\n",
      "        [0.0034],\n",
      "        [0.0205],\n",
      "        [0.0386],\n",
      "        [0.0329],\n",
      "        [0.0611],\n",
      "        [0.0854],\n",
      "        [0.0659],\n",
      "        [0.1004],\n",
      "        [0.1013],\n",
      "        [0.0882],\n",
      "        [0.1084]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0098],\n",
      "        [    0.0013],\n",
      "        [    0.0127],\n",
      "        [    0.0479],\n",
      "        [    0.0383],\n",
      "        [    0.0208],\n",
      "        [    0.0072],\n",
      "        [    0.0234],\n",
      "        [    0.0301],\n",
      "        [    0.0270],\n",
      "        [    0.0054],\n",
      "        [    0.0001],\n",
      "        [    0.0134],\n",
      "        [    0.0205],\n",
      "        [    0.0148],\n",
      "        [    0.0590],\n",
      "        [    0.0453],\n",
      "        [    0.0203],\n",
      "        [    0.0482],\n",
      "        [    0.0233],\n",
      "        [    0.0117],\n",
      "        [    0.0476],\n",
      "        [    0.0093],\n",
      "        [    0.0541],\n",
      "        [    0.0424],\n",
      "        [    0.0223],\n",
      "        [    0.0222],\n",
      "        [    0.0086],\n",
      "        [    0.0056],\n",
      "        [    0.0027],\n",
      "        [    0.0023],\n",
      "        [    0.0006],\n",
      "        [    0.0319],\n",
      "        [    0.0156],\n",
      "        [    0.0118],\n",
      "        [    0.0316],\n",
      "        [    0.0374],\n",
      "        [    0.0374],\n",
      "        [    0.0407],\n",
      "        [    0.0460],\n",
      "        [    0.0500],\n",
      "        [    0.0577],\n",
      "        [    0.0102],\n",
      "        [    0.0063],\n",
      "        [    0.0066],\n",
      "        [    0.0010],\n",
      "        [    0.0228],\n",
      "        [    0.0412],\n",
      "        [    0.0304],\n",
      "        [    0.0592],\n",
      "        [    0.0734],\n",
      "        [    0.0560],\n",
      "        [    0.1003],\n",
      "        [    0.1011],\n",
      "        [    0.0770],\n",
      "        [    0.0951]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.302119016647339\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 57\n",
      "剩餘X 資料 torch.Size([50, 18])\n",
      "剩餘Y 資料 torch.Size([50, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0132460817694664, 7)\n",
      "The second_loss value of k: (0.013531607575714588, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引7，y= tensor([0.9669])\n",
      "目前模型的Data狀態 torch.Size([57, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9080],\n",
      "        [0.9271],\n",
      "        [0.8562],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8630],\n",
      "        [0.8518],\n",
      "        [0.9056],\n",
      "        [0.9191],\n",
      "        [0.9411],\n",
      "        [0.9421],\n",
      "        [0.9160],\n",
      "        [0.8667],\n",
      "        [0.8753],\n",
      "        [0.8602],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.9534],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [1.0096],\n",
      "        [0.9262],\n",
      "        [0.9421],\n",
      "        [0.9542],\n",
      "        [0.9822],\n",
      "        [0.9615],\n",
      "        [1.0126],\n",
      "        [1.0339],\n",
      "        [0.8704],\n",
      "        [0.9114],\n",
      "        [0.8518],\n",
      "        [0.8518],\n",
      "        [0.9064],\n",
      "        [0.8849],\n",
      "        [0.8518]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0098],\n",
      "        [    0.0013],\n",
      "        [    0.0127],\n",
      "        [    0.0479],\n",
      "        [    0.0383],\n",
      "        [    0.0208],\n",
      "        [    0.0072],\n",
      "        [    0.0234],\n",
      "        [    0.0301],\n",
      "        [    0.0270],\n",
      "        [    0.0054],\n",
      "        [    0.0001],\n",
      "        [    0.0134],\n",
      "        [    0.0205],\n",
      "        [    0.0148],\n",
      "        [    0.0590],\n",
      "        [    0.0453],\n",
      "        [    0.0203],\n",
      "        [    0.0482],\n",
      "        [    0.0233],\n",
      "        [    0.0117],\n",
      "        [    0.0476],\n",
      "        [    0.0093],\n",
      "        [    0.0541],\n",
      "        [    0.0424],\n",
      "        [    0.0223],\n",
      "        [    0.0222],\n",
      "        [    0.0086],\n",
      "        [    0.0056],\n",
      "        [    0.0027],\n",
      "        [    0.0023],\n",
      "        [    0.0006],\n",
      "        [    0.0319],\n",
      "        [    0.0156],\n",
      "        [    0.0118],\n",
      "        [    0.0316],\n",
      "        [    0.0374],\n",
      "        [    0.0374],\n",
      "        [    0.0407],\n",
      "        [    0.0460],\n",
      "        [    0.0500],\n",
      "        [    0.0577],\n",
      "        [    0.0102],\n",
      "        [    0.0063],\n",
      "        [    0.0066],\n",
      "        [    0.0010],\n",
      "        [    0.0228],\n",
      "        [    0.0412],\n",
      "        [    0.0304],\n",
      "        [    0.0592],\n",
      "        [    0.0734],\n",
      "        [    0.0560],\n",
      "        [    0.1003],\n",
      "        [    0.1011],\n",
      "        [    0.0770],\n",
      "        [    0.0951],\n",
      "        [    0.1151]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0082],\n",
      "        [0.0033],\n",
      "        [0.0121],\n",
      "        [0.0515],\n",
      "        [0.0419],\n",
      "        [0.0204],\n",
      "        [0.0108],\n",
      "        [0.0265],\n",
      "        [0.0325],\n",
      "        [0.0278],\n",
      "        [0.0057],\n",
      "        [0.0004],\n",
      "        [0.0146],\n",
      "        [0.0216],\n",
      "        [0.0165],\n",
      "        [0.0626],\n",
      "        [0.0489],\n",
      "        [0.0240],\n",
      "        [0.0518],\n",
      "        [0.0238],\n",
      "        [0.0080],\n",
      "        [0.0512],\n",
      "        [0.0129],\n",
      "        [0.0504],\n",
      "        [0.0460],\n",
      "        [0.0260],\n",
      "        [0.0258],\n",
      "        [0.0122],\n",
      "        [0.0092],\n",
      "        [0.0063],\n",
      "        [0.0059],\n",
      "        [0.0031],\n",
      "        [0.0355],\n",
      "        [0.0119],\n",
      "        [0.0155],\n",
      "        [0.0280],\n",
      "        [0.0410],\n",
      "        [0.0337],\n",
      "        [0.0371],\n",
      "        [0.0424],\n",
      "        [0.0464],\n",
      "        [0.0541],\n",
      "        [0.0067],\n",
      "        [0.0040],\n",
      "        [0.0052],\n",
      "        [0.0041],\n",
      "        [0.0197],\n",
      "        [0.0380],\n",
      "        [0.0240],\n",
      "        [0.0529],\n",
      "        [0.0689],\n",
      "        [0.0532],\n",
      "        [0.0966],\n",
      "        [0.0975],\n",
      "        [0.0730],\n",
      "        [0.0895],\n",
      "        [0.1115]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.543255805969238\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 58\n",
      "剩餘X 資料 torch.Size([49, 18])\n",
      "剩餘Y 資料 torch.Size([49, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.012698962353169918, 6)\n",
      "The second_loss value of k: (0.012765263207256794, 5)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.9682])\n",
      "目前模型的Data狀態 torch.Size([58, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9063],\n",
      "        [0.9250],\n",
      "        [0.8557],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8626],\n",
      "        [0.8555],\n",
      "        [0.9025],\n",
      "        [0.9214],\n",
      "        [0.9419],\n",
      "        [0.9424],\n",
      "        [0.9163],\n",
      "        [0.8679],\n",
      "        [0.8764],\n",
      "        [0.8619],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.9529],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [1.0061],\n",
      "        [0.9240],\n",
      "        [0.9407],\n",
      "        [0.9511],\n",
      "        [0.9791],\n",
      "        [0.9583],\n",
      "        [1.0062],\n",
      "        [1.0277],\n",
      "        [0.8748],\n",
      "        [0.9142],\n",
      "        [0.8555],\n",
      "        [0.8555],\n",
      "        [0.9104],\n",
      "        [0.8905],\n",
      "        [0.8555],\n",
      "        [0.8555]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0082],\n",
      "        [0.0033],\n",
      "        [0.0121],\n",
      "        [0.0515],\n",
      "        [0.0419],\n",
      "        [0.0204],\n",
      "        [0.0108],\n",
      "        [0.0265],\n",
      "        [0.0325],\n",
      "        [0.0278],\n",
      "        [0.0057],\n",
      "        [0.0004],\n",
      "        [0.0146],\n",
      "        [0.0216],\n",
      "        [0.0165],\n",
      "        [0.0626],\n",
      "        [0.0489],\n",
      "        [0.0240],\n",
      "        [0.0518],\n",
      "        [0.0238],\n",
      "        [0.0080],\n",
      "        [0.0512],\n",
      "        [0.0129],\n",
      "        [0.0504],\n",
      "        [0.0460],\n",
      "        [0.0260],\n",
      "        [0.0258],\n",
      "        [0.0122],\n",
      "        [0.0092],\n",
      "        [0.0063],\n",
      "        [0.0059],\n",
      "        [0.0031],\n",
      "        [0.0355],\n",
      "        [0.0119],\n",
      "        [0.0155],\n",
      "        [0.0280],\n",
      "        [0.0410],\n",
      "        [0.0337],\n",
      "        [0.0371],\n",
      "        [0.0424],\n",
      "        [0.0464],\n",
      "        [0.0541],\n",
      "        [0.0067],\n",
      "        [0.0040],\n",
      "        [0.0052],\n",
      "        [0.0041],\n",
      "        [0.0197],\n",
      "        [0.0380],\n",
      "        [0.0240],\n",
      "        [0.0529],\n",
      "        [0.0689],\n",
      "        [0.0532],\n",
      "        [0.0966],\n",
      "        [0.0975],\n",
      "        [0.0730],\n",
      "        [0.0895],\n",
      "        [0.1115],\n",
      "        [0.1127]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0126],\n",
      "        [0.0008],\n",
      "        [0.0172],\n",
      "        [0.0554],\n",
      "        [0.0459],\n",
      "        [0.0253],\n",
      "        [0.0147],\n",
      "        [0.0234],\n",
      "        [0.0387],\n",
      "        [0.0330],\n",
      "        [0.0104],\n",
      "        [0.0052],\n",
      "        [0.0199],\n",
      "        [0.0268],\n",
      "        [0.0218],\n",
      "        [0.0665],\n",
      "        [0.0529],\n",
      "        [0.0279],\n",
      "        [0.0558],\n",
      "        [0.0190],\n",
      "        [0.0041],\n",
      "        [0.0551],\n",
      "        [0.0169],\n",
      "        [0.0465],\n",
      "        [0.0500],\n",
      "        [0.0299],\n",
      "        [0.0298],\n",
      "        [0.0161],\n",
      "        [0.0131],\n",
      "        [0.0102],\n",
      "        [0.0098],\n",
      "        [0.0070],\n",
      "        [0.0394],\n",
      "        [0.0080],\n",
      "        [0.0194],\n",
      "        [0.0241],\n",
      "        [0.0449],\n",
      "        [0.0298],\n",
      "        [0.0332],\n",
      "        [0.0384],\n",
      "        [0.0424],\n",
      "        [0.0502],\n",
      "        [0.0096],\n",
      "        [0.0070],\n",
      "        [0.0087],\n",
      "        [0.0017],\n",
      "        [0.0221],\n",
      "        [0.0405],\n",
      "        [0.0250],\n",
      "        [0.0541],\n",
      "        [0.0613],\n",
      "        [0.0466],\n",
      "        [0.0927],\n",
      "        [0.0936],\n",
      "        [0.0655],\n",
      "        [0.0810],\n",
      "        [0.1075],\n",
      "        [0.1088]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.78249979019165\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 59\n",
      "剩餘X 資料 torch.Size([48, 18])\n",
      "剩餘Y 資料 torch.Size([48, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.011710119433701038, 3)\n",
      "The second_loss value of k: (0.011895199306309223, 5)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.9973])\n",
      "目前模型的Data狀態 torch.Size([59, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9107],\n",
      "        [0.9292],\n",
      "        [0.8607],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8674],\n",
      "        [0.8594],\n",
      "        [0.9056],\n",
      "        [0.9276],\n",
      "        [0.9471],\n",
      "        [0.9471],\n",
      "        [0.9211],\n",
      "        [0.8732],\n",
      "        [0.8815],\n",
      "        [0.8672],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.9577],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [1.0091],\n",
      "        [0.9270],\n",
      "        [0.9441],\n",
      "        [0.9536],\n",
      "        [0.9815],\n",
      "        [0.9608],\n",
      "        [1.0071],\n",
      "        [1.0288],\n",
      "        [0.8825],\n",
      "        [0.9208],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.9179],\n",
      "        [0.8990],\n",
      "        [0.8594],\n",
      "        [0.8594],\n",
      "        [0.8890]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0126],\n",
      "        [0.0008],\n",
      "        [0.0172],\n",
      "        [0.0554],\n",
      "        [0.0459],\n",
      "        [0.0253],\n",
      "        [0.0147],\n",
      "        [0.0234],\n",
      "        [0.0387],\n",
      "        [0.0330],\n",
      "        [0.0104],\n",
      "        [0.0052],\n",
      "        [0.0199],\n",
      "        [0.0268],\n",
      "        [0.0218],\n",
      "        [0.0665],\n",
      "        [0.0529],\n",
      "        [0.0279],\n",
      "        [0.0558],\n",
      "        [0.0190],\n",
      "        [0.0041],\n",
      "        [0.0551],\n",
      "        [0.0169],\n",
      "        [0.0465],\n",
      "        [0.0500],\n",
      "        [0.0299],\n",
      "        [0.0298],\n",
      "        [0.0161],\n",
      "        [0.0131],\n",
      "        [0.0102],\n",
      "        [0.0098],\n",
      "        [0.0070],\n",
      "        [0.0394],\n",
      "        [0.0080],\n",
      "        [0.0194],\n",
      "        [0.0241],\n",
      "        [0.0449],\n",
      "        [0.0298],\n",
      "        [0.0332],\n",
      "        [0.0384],\n",
      "        [0.0424],\n",
      "        [0.0502],\n",
      "        [0.0096],\n",
      "        [0.0070],\n",
      "        [0.0087],\n",
      "        [0.0017],\n",
      "        [0.0221],\n",
      "        [0.0405],\n",
      "        [0.0250],\n",
      "        [0.0541],\n",
      "        [0.0613],\n",
      "        [0.0466],\n",
      "        [0.0927],\n",
      "        [0.0936],\n",
      "        [0.0655],\n",
      "        [0.0810],\n",
      "        [0.1075],\n",
      "        [0.1088],\n",
      "        [0.1082]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0162],\n",
      "        [0.0040],\n",
      "        [0.0218],\n",
      "        [0.0556],\n",
      "        [0.0460],\n",
      "        [0.0293],\n",
      "        [0.0149],\n",
      "        [0.0215],\n",
      "        [0.0451],\n",
      "        [0.0376],\n",
      "        [0.0144],\n",
      "        [0.0094],\n",
      "        [0.0247],\n",
      "        [0.0313],\n",
      "        [0.0265],\n",
      "        [0.0667],\n",
      "        [0.0530],\n",
      "        [0.0280],\n",
      "        [0.0559],\n",
      "        [0.0142],\n",
      "        [0.0040],\n",
      "        [0.0553],\n",
      "        [0.0170],\n",
      "        [0.0464],\n",
      "        [0.0501],\n",
      "        [0.0300],\n",
      "        [0.0299],\n",
      "        [0.0163],\n",
      "        [0.0133],\n",
      "        [0.0104],\n",
      "        [0.0100],\n",
      "        [0.0071],\n",
      "        [0.0396],\n",
      "        [0.0079],\n",
      "        [0.0195],\n",
      "        [0.0239],\n",
      "        [0.0451],\n",
      "        [0.0297],\n",
      "        [0.0330],\n",
      "        [0.0383],\n",
      "        [0.0423],\n",
      "        [0.0500],\n",
      "        [0.0116],\n",
      "        [0.0087],\n",
      "        [0.0113],\n",
      "        [0.0003],\n",
      "        [0.0233],\n",
      "        [0.0418],\n",
      "        [0.0238],\n",
      "        [0.0533],\n",
      "        [0.0528],\n",
      "        [0.0394],\n",
      "        [0.0926],\n",
      "        [0.0934],\n",
      "        [0.0565],\n",
      "        [0.0710],\n",
      "        [0.1074],\n",
      "        [0.1086],\n",
      "        [0.0994]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.02026104927063\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 60\n",
      "剩餘X 資料 torch.Size([47, 18])\n",
      "剩餘Y 資料 torch.Size([47, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.011861640028655529, 4)\n",
      "The second_loss value of k: (0.013447108678519726, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([0.9685])\n",
      "目前模型的Data狀態 torch.Size([60, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9144],\n",
      "        [0.9323],\n",
      "        [0.8653],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8715],\n",
      "        [0.8596],\n",
      "        [0.9075],\n",
      "        [0.9340],\n",
      "        [0.9517],\n",
      "        [0.9510],\n",
      "        [0.9253],\n",
      "        [0.8781],\n",
      "        [0.8861],\n",
      "        [0.8719],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.9625],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [1.0110],\n",
      "        [0.9287],\n",
      "        [0.9467],\n",
      "        [0.9550],\n",
      "        [0.9826],\n",
      "        [0.9621],\n",
      "        [1.0059],\n",
      "        [1.0281],\n",
      "        [0.8910],\n",
      "        [0.9279],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.9269],\n",
      "        [0.9090],\n",
      "        [0.8596],\n",
      "        [0.8596],\n",
      "        [0.8979],\n",
      "        [0.8596]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0162],\n",
      "        [0.0040],\n",
      "        [0.0218],\n",
      "        [0.0556],\n",
      "        [0.0460],\n",
      "        [0.0293],\n",
      "        [0.0149],\n",
      "        [0.0215],\n",
      "        [0.0451],\n",
      "        [0.0376],\n",
      "        [0.0144],\n",
      "        [0.0094],\n",
      "        [0.0247],\n",
      "        [0.0313],\n",
      "        [0.0265],\n",
      "        [0.0667],\n",
      "        [0.0530],\n",
      "        [0.0280],\n",
      "        [0.0559],\n",
      "        [0.0142],\n",
      "        [0.0040],\n",
      "        [0.0553],\n",
      "        [0.0170],\n",
      "        [0.0464],\n",
      "        [0.0501],\n",
      "        [0.0300],\n",
      "        [0.0299],\n",
      "        [0.0163],\n",
      "        [0.0133],\n",
      "        [0.0104],\n",
      "        [0.0100],\n",
      "        [0.0071],\n",
      "        [0.0396],\n",
      "        [0.0079],\n",
      "        [0.0195],\n",
      "        [0.0239],\n",
      "        [0.0451],\n",
      "        [0.0297],\n",
      "        [0.0330],\n",
      "        [0.0383],\n",
      "        [0.0423],\n",
      "        [0.0500],\n",
      "        [0.0116],\n",
      "        [0.0087],\n",
      "        [0.0113],\n",
      "        [0.0003],\n",
      "        [0.0233],\n",
      "        [0.0418],\n",
      "        [0.0238],\n",
      "        [0.0533],\n",
      "        [0.0528],\n",
      "        [0.0394],\n",
      "        [0.0926],\n",
      "        [0.0934],\n",
      "        [0.0565],\n",
      "        [0.0710],\n",
      "        [0.1074],\n",
      "        [0.1086],\n",
      "        [0.0994],\n",
      "        [0.1089]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0156],\n",
      "        [0.0031],\n",
      "        [0.0221],\n",
      "        [0.0589],\n",
      "        [0.0493],\n",
      "        [0.0293],\n",
      "        [0.0181],\n",
      "        [0.0230],\n",
      "        [0.0465],\n",
      "        [0.0374],\n",
      "        [0.0138],\n",
      "        [0.0092],\n",
      "        [0.0251],\n",
      "        [0.0314],\n",
      "        [0.0267],\n",
      "        [0.0699],\n",
      "        [0.0563],\n",
      "        [0.0313],\n",
      "        [0.0592],\n",
      "        [0.0136],\n",
      "        [0.0007],\n",
      "        [0.0585],\n",
      "        [0.0203],\n",
      "        [0.0431],\n",
      "        [0.0534],\n",
      "        [0.0333],\n",
      "        [0.0332],\n",
      "        [0.0195],\n",
      "        [0.0166],\n",
      "        [0.0136],\n",
      "        [0.0132],\n",
      "        [0.0104],\n",
      "        [0.0428],\n",
      "        [0.0046],\n",
      "        [0.0228],\n",
      "        [0.0207],\n",
      "        [0.0484],\n",
      "        [0.0264],\n",
      "        [0.0298],\n",
      "        [0.0350],\n",
      "        [0.0390],\n",
      "        [0.0468],\n",
      "        [0.0099],\n",
      "        [0.0068],\n",
      "        [0.0101],\n",
      "        [0.0026],\n",
      "        [0.0209],\n",
      "        [0.0393],\n",
      "        [0.0196],\n",
      "        [0.0493],\n",
      "        [0.0494],\n",
      "        [0.0373],\n",
      "        [0.0893],\n",
      "        [0.0902],\n",
      "        [0.0526],\n",
      "        [0.0664],\n",
      "        [0.1041],\n",
      "        [0.1054],\n",
      "        [0.0955],\n",
      "        [0.1057]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.259137392044067\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 61\n",
      "剩餘X 資料 torch.Size([46, 18])\n",
      "剩餘Y 資料 torch.Size([46, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.012702535837888718, 0)\n",
      "The second_loss value of k: (0.013509595766663551, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.9755])\n",
      "目前模型的Data狀態 torch.Size([61, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9137],\n",
      "        [0.9314],\n",
      "        [0.8657],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8715],\n",
      "        [0.8628],\n",
      "        [0.9059],\n",
      "        [0.9355],\n",
      "        [0.9515],\n",
      "        [0.9505],\n",
      "        [0.9251],\n",
      "        [0.8784],\n",
      "        [0.8862],\n",
      "        [0.8721],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.9630],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [1.0093],\n",
      "        [0.9268],\n",
      "        [0.9456],\n",
      "        [0.9527],\n",
      "        [0.9802],\n",
      "        [0.9596],\n",
      "        [1.0017],\n",
      "        [1.0241],\n",
      "        [0.8944],\n",
      "        [0.9300],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.9307],\n",
      "        [0.9137],\n",
      "        [0.8628],\n",
      "        [0.8628],\n",
      "        [0.9018],\n",
      "        [0.8628],\n",
      "        [0.8628]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0156],\n",
      "        [0.0031],\n",
      "        [0.0221],\n",
      "        [0.0589],\n",
      "        [0.0493],\n",
      "        [0.0293],\n",
      "        [0.0181],\n",
      "        [0.0230],\n",
      "        [0.0465],\n",
      "        [0.0374],\n",
      "        [0.0138],\n",
      "        [0.0092],\n",
      "        [0.0251],\n",
      "        [0.0314],\n",
      "        [0.0267],\n",
      "        [0.0699],\n",
      "        [0.0563],\n",
      "        [0.0313],\n",
      "        [0.0592],\n",
      "        [0.0136],\n",
      "        [0.0007],\n",
      "        [0.0585],\n",
      "        [0.0203],\n",
      "        [0.0431],\n",
      "        [0.0534],\n",
      "        [0.0333],\n",
      "        [0.0332],\n",
      "        [0.0195],\n",
      "        [0.0166],\n",
      "        [0.0136],\n",
      "        [0.0132],\n",
      "        [0.0104],\n",
      "        [0.0428],\n",
      "        [0.0046],\n",
      "        [0.0228],\n",
      "        [0.0207],\n",
      "        [0.0484],\n",
      "        [0.0264],\n",
      "        [0.0298],\n",
      "        [0.0350],\n",
      "        [0.0390],\n",
      "        [0.0468],\n",
      "        [0.0099],\n",
      "        [0.0068],\n",
      "        [0.0101],\n",
      "        [0.0026],\n",
      "        [0.0209],\n",
      "        [0.0393],\n",
      "        [0.0196],\n",
      "        [0.0493],\n",
      "        [0.0494],\n",
      "        [0.0373],\n",
      "        [0.0893],\n",
      "        [0.0902],\n",
      "        [0.0526],\n",
      "        [0.0664],\n",
      "        [0.1041],\n",
      "        [0.1054],\n",
      "        [0.0955],\n",
      "        [0.1057],\n",
      "        [0.1127]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0156],\n",
      "        [0.0029],\n",
      "        [0.0229],\n",
      "        [0.0618],\n",
      "        [0.0522],\n",
      "        [0.0296],\n",
      "        [0.0210],\n",
      "        [0.0236],\n",
      "        [0.0472],\n",
      "        [0.0370],\n",
      "        [0.0131],\n",
      "        [0.0088],\n",
      "        [0.0251],\n",
      "        [0.0312],\n",
      "        [0.0265],\n",
      "        [0.0728],\n",
      "        [0.0592],\n",
      "        [0.0342],\n",
      "        [0.0621],\n",
      "        [0.0131],\n",
      "        [0.0022],\n",
      "        [0.0614],\n",
      "        [0.0232],\n",
      "        [0.0402],\n",
      "        [0.0563],\n",
      "        [0.0362],\n",
      "        [0.0361],\n",
      "        [0.0224],\n",
      "        [0.0195],\n",
      "        [0.0165],\n",
      "        [0.0161],\n",
      "        [0.0133],\n",
      "        [0.0457],\n",
      "        [0.0017],\n",
      "        [0.0257],\n",
      "        [0.0178],\n",
      "        [0.0513],\n",
      "        [0.0235],\n",
      "        [0.0269],\n",
      "        [0.0321],\n",
      "        [0.0361],\n",
      "        [0.0439],\n",
      "        [0.0091],\n",
      "        [0.0054],\n",
      "        [0.0092],\n",
      "        [0.0042],\n",
      "        [0.0192],\n",
      "        [0.0375],\n",
      "        [0.0172],\n",
      "        [0.0471],\n",
      "        [0.0474],\n",
      "        [0.0361],\n",
      "        [0.0864],\n",
      "        [0.0873],\n",
      "        [0.0501],\n",
      "        [0.0634],\n",
      "        [0.1012],\n",
      "        [0.1025],\n",
      "        [0.0929],\n",
      "        [0.1028],\n",
      "        [0.1098]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.499439239501953\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 62\n",
      "剩餘X 資料 torch.Size([45, 18])\n",
      "剩餘Y 資料 torch.Size([45, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.012844366021454334, 1)\n",
      "The second_loss value of k: (0.015905329957604408, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.9790])\n",
      "目前模型的Data狀態 torch.Size([62, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9137],\n",
      "        [0.9312],\n",
      "        [0.8664],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8718],\n",
      "        [0.8657],\n",
      "        [0.9053],\n",
      "        [0.9362],\n",
      "        [0.9511],\n",
      "        [0.9498],\n",
      "        [0.9247],\n",
      "        [0.8785],\n",
      "        [0.8860],\n",
      "        [0.8719],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.9635],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [1.0085],\n",
      "        [0.9254],\n",
      "        [0.9447],\n",
      "        [0.9511],\n",
      "        [0.9785],\n",
      "        [0.9578],\n",
      "        [0.9993],\n",
      "        [1.0218],\n",
      "        [0.8964],\n",
      "        [0.9312],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.9333],\n",
      "        [0.9166],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.9044],\n",
      "        [0.8657],\n",
      "        [0.8657],\n",
      "        [0.8657]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0156],\n",
      "        [0.0029],\n",
      "        [0.0229],\n",
      "        [0.0618],\n",
      "        [0.0522],\n",
      "        [0.0296],\n",
      "        [0.0210],\n",
      "        [0.0236],\n",
      "        [0.0472],\n",
      "        [0.0370],\n",
      "        [0.0131],\n",
      "        [0.0088],\n",
      "        [0.0251],\n",
      "        [0.0312],\n",
      "        [0.0265],\n",
      "        [0.0728],\n",
      "        [0.0592],\n",
      "        [0.0342],\n",
      "        [0.0621],\n",
      "        [0.0131],\n",
      "        [0.0022],\n",
      "        [0.0614],\n",
      "        [0.0232],\n",
      "        [0.0402],\n",
      "        [0.0563],\n",
      "        [0.0362],\n",
      "        [0.0361],\n",
      "        [0.0224],\n",
      "        [0.0195],\n",
      "        [0.0165],\n",
      "        [0.0161],\n",
      "        [0.0133],\n",
      "        [0.0457],\n",
      "        [0.0017],\n",
      "        [0.0257],\n",
      "        [0.0178],\n",
      "        [0.0513],\n",
      "        [0.0235],\n",
      "        [0.0269],\n",
      "        [0.0321],\n",
      "        [0.0361],\n",
      "        [0.0439],\n",
      "        [0.0091],\n",
      "        [0.0054],\n",
      "        [0.0092],\n",
      "        [0.0042],\n",
      "        [0.0192],\n",
      "        [0.0375],\n",
      "        [0.0172],\n",
      "        [0.0471],\n",
      "        [0.0474],\n",
      "        [0.0361],\n",
      "        [0.0864],\n",
      "        [0.0873],\n",
      "        [0.0501],\n",
      "        [0.0634],\n",
      "        [0.1012],\n",
      "        [0.1025],\n",
      "        [0.0929],\n",
      "        [0.1028],\n",
      "        [0.1098],\n",
      "        [0.1133]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0131],\n",
      "        [0.0002],\n",
      "        [0.0244],\n",
      "        [0.0640],\n",
      "        [0.0544],\n",
      "        [0.0275],\n",
      "        [0.0232],\n",
      "        [0.0268],\n",
      "        [0.0451],\n",
      "        [0.0335],\n",
      "        [0.0092],\n",
      "        [0.0054],\n",
      "        [0.0222],\n",
      "        [0.0279],\n",
      "        [0.0232],\n",
      "        [0.0750],\n",
      "        [0.0614],\n",
      "        [0.0364],\n",
      "        [0.0643],\n",
      "        [0.0151],\n",
      "        [0.0044],\n",
      "        [0.0636],\n",
      "        [0.0254],\n",
      "        [0.0380],\n",
      "        [0.0585],\n",
      "        [0.0384],\n",
      "        [0.0383],\n",
      "        [0.0246],\n",
      "        [0.0216],\n",
      "        [0.0187],\n",
      "        [0.0183],\n",
      "        [0.0155],\n",
      "        [0.0479],\n",
      "        [0.0005],\n",
      "        [0.0279],\n",
      "        [0.0156],\n",
      "        [0.0535],\n",
      "        [0.0213],\n",
      "        [0.0247],\n",
      "        [0.0299],\n",
      "        [0.0339],\n",
      "        [0.0417],\n",
      "        [0.0055],\n",
      "        [0.0009],\n",
      "        [0.0053],\n",
      "        [0.0090],\n",
      "        [0.0142],\n",
      "        [0.0325],\n",
      "        [0.0117],\n",
      "        [0.0416],\n",
      "        [0.0479],\n",
      "        [0.0375],\n",
      "        [0.0842],\n",
      "        [0.0851],\n",
      "        [0.0496],\n",
      "        [0.0625],\n",
      "        [0.0990],\n",
      "        [0.1003],\n",
      "        [0.0923],\n",
      "        [0.1006],\n",
      "        [0.1076],\n",
      "        [0.1111]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.738611221313477\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 63\n",
      "剩餘X 資料 torch.Size([44, 18])\n",
      "剩餘Y 資料 torch.Size([44, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.01544871274381876, 0)\n",
      "The second_loss value of k: (0.017448406666517258, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.9928])\n",
      "目前模型的Data狀態 torch.Size([63, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9112],\n",
      "        [0.9286],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8696],\n",
      "        [0.8679],\n",
      "        [0.9021],\n",
      "        [0.9341],\n",
      "        [0.9476],\n",
      "        [0.9458],\n",
      "        [0.9213],\n",
      "        [0.8756],\n",
      "        [0.8827],\n",
      "        [0.8686],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.9615],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [1.0049],\n",
      "        [0.9208],\n",
      "        [0.9407],\n",
      "        [0.9463],\n",
      "        [0.9736],\n",
      "        [0.9527],\n",
      "        [0.9938],\n",
      "        [1.0164],\n",
      "        [0.8959],\n",
      "        [0.9299],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.9337],\n",
      "        [0.9175],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.9049],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8679],\n",
      "        [0.8685]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0131],\n",
      "        [0.0002],\n",
      "        [0.0244],\n",
      "        [0.0640],\n",
      "        [0.0544],\n",
      "        [0.0275],\n",
      "        [0.0232],\n",
      "        [0.0268],\n",
      "        [0.0451],\n",
      "        [0.0335],\n",
      "        [0.0092],\n",
      "        [0.0054],\n",
      "        [0.0222],\n",
      "        [0.0279],\n",
      "        [0.0232],\n",
      "        [0.0750],\n",
      "        [0.0614],\n",
      "        [0.0364],\n",
      "        [0.0643],\n",
      "        [0.0151],\n",
      "        [0.0044],\n",
      "        [0.0636],\n",
      "        [0.0254],\n",
      "        [0.0380],\n",
      "        [0.0585],\n",
      "        [0.0384],\n",
      "        [0.0383],\n",
      "        [0.0246],\n",
      "        [0.0216],\n",
      "        [0.0187],\n",
      "        [0.0183],\n",
      "        [0.0155],\n",
      "        [0.0479],\n",
      "        [0.0005],\n",
      "        [0.0279],\n",
      "        [0.0156],\n",
      "        [0.0535],\n",
      "        [0.0213],\n",
      "        [0.0247],\n",
      "        [0.0299],\n",
      "        [0.0339],\n",
      "        [0.0417],\n",
      "        [0.0055],\n",
      "        [0.0009],\n",
      "        [0.0053],\n",
      "        [0.0090],\n",
      "        [0.0142],\n",
      "        [0.0325],\n",
      "        [0.0117],\n",
      "        [0.0416],\n",
      "        [0.0479],\n",
      "        [0.0375],\n",
      "        [0.0842],\n",
      "        [0.0851],\n",
      "        [0.0496],\n",
      "        [0.0625],\n",
      "        [0.0990],\n",
      "        [0.1003],\n",
      "        [0.0923],\n",
      "        [0.1006],\n",
      "        [0.1076],\n",
      "        [0.1111],\n",
      "        [0.1243]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0209],\n",
      "        [0.0070],\n",
      "        [0.0301],\n",
      "        [0.0611],\n",
      "        [0.0515],\n",
      "        [0.0356],\n",
      "        [0.0204],\n",
      "        [0.0212],\n",
      "        [0.0542],\n",
      "        [0.0399],\n",
      "        [0.0153],\n",
      "        [0.0121],\n",
      "        [0.0297],\n",
      "        [0.0350],\n",
      "        [0.0304],\n",
      "        [0.0722],\n",
      "        [0.0585],\n",
      "        [0.0335],\n",
      "        [0.0614],\n",
      "        [0.0058],\n",
      "        [0.0015],\n",
      "        [0.0608],\n",
      "        [0.0225],\n",
      "        [0.0408],\n",
      "        [0.0556],\n",
      "        [0.0355],\n",
      "        [0.0354],\n",
      "        [0.0218],\n",
      "        [0.0188],\n",
      "        [0.0159],\n",
      "        [0.0155],\n",
      "        [0.0127],\n",
      "        [0.0451],\n",
      "        [0.0023],\n",
      "        [0.0250],\n",
      "        [0.0184],\n",
      "        [0.0506],\n",
      "        [0.0241],\n",
      "        [0.0275],\n",
      "        [0.0328],\n",
      "        [0.0368],\n",
      "        [0.0445],\n",
      "        [0.0114],\n",
      "        [0.0055],\n",
      "        [0.0110],\n",
      "        [0.0045],\n",
      "        [0.0182],\n",
      "        [0.0368],\n",
      "        [0.0136],\n",
      "        [0.0442],\n",
      "        [0.0358],\n",
      "        [0.0272],\n",
      "        [0.0871],\n",
      "        [0.0879],\n",
      "        [0.0365],\n",
      "        [0.0487],\n",
      "        [0.1019],\n",
      "        [0.1031],\n",
      "        [0.0790],\n",
      "        [0.1034],\n",
      "        [0.1104],\n",
      "        [0.1045],\n",
      "        [0.1082]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.978548049926758\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 64\n",
      "剩餘X 資料 torch.Size([43, 18])\n",
      "剩餘Y 資料 torch.Size([43, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.018203550949692726, 0)\n",
      "The second_loss value of k: (0.024701528251171112, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([1.])\n",
      "目前模型的Data狀態 torch.Size([64, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9190],\n",
      "        [0.9354],\n",
      "        [0.8736],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8778],\n",
      "        [0.8651],\n",
      "        [0.9078],\n",
      "        [0.9431],\n",
      "        [0.9540],\n",
      "        [0.9520],\n",
      "        [0.9280],\n",
      "        [0.8830],\n",
      "        [0.8898],\n",
      "        [0.8758],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.9709],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [1.0109],\n",
      "        [0.9255],\n",
      "        [0.9464],\n",
      "        [0.9507],\n",
      "        [0.9776],\n",
      "        [0.9570],\n",
      "        [0.9957],\n",
      "        [1.0189],\n",
      "        [0.9079],\n",
      "        [0.9401],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.9468],\n",
      "        [0.9313],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.9182],\n",
      "        [0.8651],\n",
      "        [0.8651],\n",
      "        [0.8745],\n",
      "        [0.8846],\n",
      "        [0.8651]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0209],\n",
      "        [0.0070],\n",
      "        [0.0301],\n",
      "        [0.0611],\n",
      "        [0.0515],\n",
      "        [0.0356],\n",
      "        [0.0204],\n",
      "        [0.0212],\n",
      "        [0.0542],\n",
      "        [0.0399],\n",
      "        [0.0153],\n",
      "        [0.0121],\n",
      "        [0.0297],\n",
      "        [0.0350],\n",
      "        [0.0304],\n",
      "        [0.0722],\n",
      "        [0.0585],\n",
      "        [0.0335],\n",
      "        [0.0614],\n",
      "        [0.0058],\n",
      "        [0.0015],\n",
      "        [0.0608],\n",
      "        [0.0225],\n",
      "        [0.0408],\n",
      "        [0.0556],\n",
      "        [0.0355],\n",
      "        [0.0354],\n",
      "        [0.0218],\n",
      "        [0.0188],\n",
      "        [0.0159],\n",
      "        [0.0155],\n",
      "        [0.0127],\n",
      "        [0.0451],\n",
      "        [0.0023],\n",
      "        [0.0250],\n",
      "        [0.0184],\n",
      "        [0.0506],\n",
      "        [0.0241],\n",
      "        [0.0275],\n",
      "        [0.0328],\n",
      "        [0.0368],\n",
      "        [0.0445],\n",
      "        [0.0114],\n",
      "        [0.0055],\n",
      "        [0.0110],\n",
      "        [0.0045],\n",
      "        [0.0182],\n",
      "        [0.0368],\n",
      "        [0.0136],\n",
      "        [0.0442],\n",
      "        [0.0358],\n",
      "        [0.0272],\n",
      "        [0.0871],\n",
      "        [0.0879],\n",
      "        [0.0365],\n",
      "        [0.0487],\n",
      "        [0.1019],\n",
      "        [0.1031],\n",
      "        [0.0790],\n",
      "        [0.1034],\n",
      "        [0.1104],\n",
      "        [0.1045],\n",
      "        [0.1082],\n",
      "        [0.1349]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0194],\n",
      "        [0.0049],\n",
      "        [0.0298],\n",
      "        [0.0649],\n",
      "        [0.0553],\n",
      "        [0.0353],\n",
      "        [0.0242],\n",
      "        [0.0229],\n",
      "        [0.0538],\n",
      "        [0.0372],\n",
      "        [0.0129],\n",
      "        [0.0103],\n",
      "        [0.0287],\n",
      "        [0.0337],\n",
      "        [0.0296],\n",
      "        [0.0760],\n",
      "        [0.0623],\n",
      "        [0.0374],\n",
      "        [0.0652],\n",
      "        [0.0054],\n",
      "        [0.0054],\n",
      "        [0.0646],\n",
      "        [0.0263],\n",
      "        [0.0370],\n",
      "        [0.0594],\n",
      "        [0.0394],\n",
      "        [0.0392],\n",
      "        [0.0256],\n",
      "        [0.0226],\n",
      "        [0.0197],\n",
      "        [0.0193],\n",
      "        [0.0165],\n",
      "        [0.0489],\n",
      "        [0.0015],\n",
      "        [0.0289],\n",
      "        [0.0146],\n",
      "        [0.0544],\n",
      "        [0.0203],\n",
      "        [0.0237],\n",
      "        [0.0290],\n",
      "        [0.0330],\n",
      "        [0.0407],\n",
      "        [0.0092],\n",
      "        [0.0031],\n",
      "        [0.0095],\n",
      "        [0.0072],\n",
      "        [0.0152],\n",
      "        [0.0337],\n",
      "        [0.0084],\n",
      "        [0.0392],\n",
      "        [0.0336],\n",
      "        [0.0266],\n",
      "        [0.0832],\n",
      "        [0.0841],\n",
      "        [0.0333],\n",
      "        [0.0451],\n",
      "        [0.0981],\n",
      "        [0.0993],\n",
      "        [0.0753],\n",
      "        [0.0996],\n",
      "        [0.1066],\n",
      "        [0.0970],\n",
      "        [0.1020],\n",
      "        [0.1311]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.220159769058228\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 65\n",
      "剩餘X 資料 torch.Size([42, 18])\n",
      "剩餘Y 資料 torch.Size([42, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.025912810117006302, 0)\n",
      "The second_loss value of k: (0.027176856994628906, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.7079])\n",
      "目前模型的Data狀態 torch.Size([65, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9176],\n",
      "        [0.9332],\n",
      "        [0.8733],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8775],\n",
      "        [0.8689],\n",
      "        [0.9061],\n",
      "        [0.9428],\n",
      "        [0.9513],\n",
      "        [0.9496],\n",
      "        [0.9262],\n",
      "        [0.8820],\n",
      "        [0.8885],\n",
      "        [0.8750],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.9713],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [1.0086],\n",
      "        [0.9231],\n",
      "        [0.9449],\n",
      "        [0.9480],\n",
      "        [0.9746],\n",
      "        [0.9539],\n",
      "        [0.9905],\n",
      "        [1.0140],\n",
      "        [0.9102],\n",
      "        [0.9407],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.9501],\n",
      "        [0.9349],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.9220],\n",
      "        [0.8689],\n",
      "        [0.8689],\n",
      "        [0.8820],\n",
      "        [0.8907],\n",
      "        [0.8689],\n",
      "        [0.8689]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0194],\n",
      "        [0.0049],\n",
      "        [0.0298],\n",
      "        [0.0649],\n",
      "        [0.0553],\n",
      "        [0.0353],\n",
      "        [0.0242],\n",
      "        [0.0229],\n",
      "        [0.0538],\n",
      "        [0.0372],\n",
      "        [0.0129],\n",
      "        [0.0103],\n",
      "        [0.0287],\n",
      "        [0.0337],\n",
      "        [0.0296],\n",
      "        [0.0760],\n",
      "        [0.0623],\n",
      "        [0.0374],\n",
      "        [0.0652],\n",
      "        [0.0054],\n",
      "        [0.0054],\n",
      "        [0.0646],\n",
      "        [0.0263],\n",
      "        [0.0370],\n",
      "        [0.0594],\n",
      "        [0.0394],\n",
      "        [0.0392],\n",
      "        [0.0256],\n",
      "        [0.0226],\n",
      "        [0.0197],\n",
      "        [0.0193],\n",
      "        [0.0165],\n",
      "        [0.0489],\n",
      "        [0.0015],\n",
      "        [0.0289],\n",
      "        [0.0146],\n",
      "        [0.0544],\n",
      "        [0.0203],\n",
      "        [0.0237],\n",
      "        [0.0290],\n",
      "        [0.0330],\n",
      "        [0.0407],\n",
      "        [0.0092],\n",
      "        [0.0031],\n",
      "        [0.0095],\n",
      "        [0.0072],\n",
      "        [0.0152],\n",
      "        [0.0337],\n",
      "        [0.0084],\n",
      "        [0.0392],\n",
      "        [0.0336],\n",
      "        [0.0266],\n",
      "        [0.0832],\n",
      "        [0.0841],\n",
      "        [0.0333],\n",
      "        [0.0451],\n",
      "        [0.0981],\n",
      "        [0.0993],\n",
      "        [0.0753],\n",
      "        [0.0996],\n",
      "        [0.1066],\n",
      "        [0.0970],\n",
      "        [0.1020],\n",
      "        [0.1311],\n",
      "        [0.1610]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0279],\n",
      "        [0.0124],\n",
      "        [0.0386],\n",
      "        [0.0579],\n",
      "        [0.0498],\n",
      "        [0.0437],\n",
      "        [0.0175],\n",
      "        [0.0162],\n",
      "        [0.0630],\n",
      "        [0.0447],\n",
      "        [0.0202],\n",
      "        [0.0179],\n",
      "        [0.0367],\n",
      "        [0.0416],\n",
      "        [0.0376],\n",
      "        [0.0689],\n",
      "        [0.0553],\n",
      "        [0.0303],\n",
      "        [0.0582],\n",
      "        [0.0042],\n",
      "        [0.0017],\n",
      "        [0.0575],\n",
      "        [0.0193],\n",
      "        [0.0358],\n",
      "        [0.0524],\n",
      "        [0.0323],\n",
      "        [0.0322],\n",
      "        [0.0185],\n",
      "        [0.0156],\n",
      "        [0.0126],\n",
      "        [0.0122],\n",
      "        [0.0094],\n",
      "        [0.0418],\n",
      "        [0.0056],\n",
      "        [0.0218],\n",
      "        [0.0217],\n",
      "        [0.0474],\n",
      "        [0.0274],\n",
      "        [0.0308],\n",
      "        [0.0360],\n",
      "        [0.0400],\n",
      "        [0.0478],\n",
      "        [0.0165],\n",
      "        [0.0095],\n",
      "        [0.0163],\n",
      "        [0.0009],\n",
      "        [0.0211],\n",
      "        [0.0400],\n",
      "        [0.0128],\n",
      "        [0.0444],\n",
      "        [0.0226],\n",
      "        [0.0167],\n",
      "        [0.0903],\n",
      "        [0.0912],\n",
      "        [0.0219],\n",
      "        [0.0331],\n",
      "        [0.1051],\n",
      "        [0.1064],\n",
      "        [0.0638],\n",
      "        [0.1067],\n",
      "        [0.0988],\n",
      "        [0.0828],\n",
      "        [0.0885],\n",
      "        [0.1382],\n",
      "        [0.1539]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.47763729095459\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 66\n",
      "剩餘X 資料 torch.Size([41, 18])\n",
      "剩餘Y 資料 torch.Size([41, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.02866344526410103, 0)\n",
      "The second_loss value of k: (0.035933058708906174, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.8833])\n",
      "目前模型的Data狀態 torch.Size([66, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9260],\n",
      "        [0.9408],\n",
      "        [0.8821],\n",
      "        [0.8618],\n",
      "        [0.8633],\n",
      "        [0.8858],\n",
      "        [0.8622],\n",
      "        [0.9127],\n",
      "        [0.9519],\n",
      "        [0.9588],\n",
      "        [0.9569],\n",
      "        [0.9338],\n",
      "        [0.8901],\n",
      "        [0.8963],\n",
      "        [0.8830],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.9809],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8702],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [1.0159],\n",
      "        [0.9295],\n",
      "        [0.9518],\n",
      "        [0.9544],\n",
      "        [0.9805],\n",
      "        [0.9603],\n",
      "        [0.9949],\n",
      "        [1.0191],\n",
      "        [0.9212],\n",
      "        [0.9506],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.9614],\n",
      "        [0.9469],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [0.9335],\n",
      "        [0.8618],\n",
      "        [0.8768],\n",
      "        [0.8963],\n",
      "        [0.9042],\n",
      "        [0.8618],\n",
      "        [0.8618],\n",
      "        [1.0526]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0279],\n",
      "        [0.0124],\n",
      "        [0.0386],\n",
      "        [0.0579],\n",
      "        [0.0498],\n",
      "        [0.0437],\n",
      "        [0.0175],\n",
      "        [0.0162],\n",
      "        [0.0630],\n",
      "        [0.0447],\n",
      "        [0.0202],\n",
      "        [0.0179],\n",
      "        [0.0367],\n",
      "        [0.0416],\n",
      "        [0.0376],\n",
      "        [0.0689],\n",
      "        [0.0553],\n",
      "        [0.0303],\n",
      "        [0.0582],\n",
      "        [0.0042],\n",
      "        [0.0017],\n",
      "        [0.0575],\n",
      "        [0.0193],\n",
      "        [0.0358],\n",
      "        [0.0524],\n",
      "        [0.0323],\n",
      "        [0.0322],\n",
      "        [0.0185],\n",
      "        [0.0156],\n",
      "        [0.0126],\n",
      "        [0.0122],\n",
      "        [0.0094],\n",
      "        [0.0418],\n",
      "        [0.0056],\n",
      "        [0.0218],\n",
      "        [0.0217],\n",
      "        [0.0474],\n",
      "        [0.0274],\n",
      "        [0.0308],\n",
      "        [0.0360],\n",
      "        [0.0400],\n",
      "        [0.0478],\n",
      "        [0.0165],\n",
      "        [0.0095],\n",
      "        [0.0163],\n",
      "        [0.0009],\n",
      "        [0.0211],\n",
      "        [0.0400],\n",
      "        [0.0128],\n",
      "        [0.0444],\n",
      "        [0.0226],\n",
      "        [0.0167],\n",
      "        [0.0903],\n",
      "        [0.0912],\n",
      "        [0.0219],\n",
      "        [0.0331],\n",
      "        [0.1051],\n",
      "        [0.1064],\n",
      "        [0.0638],\n",
      "        [0.1067],\n",
      "        [0.0988],\n",
      "        [0.0828],\n",
      "        [0.0885],\n",
      "        [0.1382],\n",
      "        [0.1539],\n",
      "        [0.1693]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 77\n",
      "Number of shrink: 23\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0238],\n",
      "        [    0.0070],\n",
      "        [    0.0373],\n",
      "        [    0.0578],\n",
      "        [    0.0486],\n",
      "        [    0.0417],\n",
      "        [    0.0174],\n",
      "        [    0.0192],\n",
      "        [    0.0569],\n",
      "        [    0.0364],\n",
      "        [    0.0117],\n",
      "        [    0.0111],\n",
      "        [    0.0321],\n",
      "        [    0.0364],\n",
      "        [    0.0324],\n",
      "        [    0.0689],\n",
      "        [    0.0552],\n",
      "        [    0.0302],\n",
      "        [    0.0581],\n",
      "        [    0.0000],\n",
      "        [    0.0018],\n",
      "        [    0.0575],\n",
      "        [    0.0192],\n",
      "        [    0.0403],\n",
      "        [    0.0523],\n",
      "        [    0.0322],\n",
      "        [    0.0321],\n",
      "        [    0.0184],\n",
      "        [    0.0155],\n",
      "        [    0.0125],\n",
      "        [    0.0121],\n",
      "        [    0.0093],\n",
      "        [    0.0417],\n",
      "        [    0.0057],\n",
      "        [    0.0217],\n",
      "        [    0.0217],\n",
      "        [    0.0473],\n",
      "        [    0.0275],\n",
      "        [    0.0309],\n",
      "        [    0.0361],\n",
      "        [    0.0401],\n",
      "        [    0.0479],\n",
      "        [    0.0093],\n",
      "        [    0.0002],\n",
      "        [    0.0061],\n",
      "        [    0.0126],\n",
      "        [    0.0083],\n",
      "        [    0.0274],\n",
      "        [    0.0041],\n",
      "        [    0.0353],\n",
      "        [    0.0255],\n",
      "        [    0.0222],\n",
      "        [    0.0904],\n",
      "        [    0.0913],\n",
      "        [    0.0263],\n",
      "        [    0.0366],\n",
      "        [    0.1052],\n",
      "        [    0.1064],\n",
      "        [    0.0664],\n",
      "        [    0.1067],\n",
      "        [    0.0957],\n",
      "        [    0.0813],\n",
      "        [    0.0874],\n",
      "        [    0.1383],\n",
      "        [    0.1538],\n",
      "        [    0.1507]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.796421766281128\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 67\n",
      "剩餘X 資料 torch.Size([40, 18])\n",
      "剩餘Y 資料 torch.Size([40, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.029809661209583282, 0)\n",
      "The second_loss value of k: (0.04292600601911545, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.8617])\n",
      "目前模型的Data狀態 torch.Size([67, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9220],\n",
      "        [0.9353],\n",
      "        [0.8809],\n",
      "        [0.8617],\n",
      "        [0.8622],\n",
      "        [0.8839],\n",
      "        [0.8621],\n",
      "        [0.9097],\n",
      "        [0.9459],\n",
      "        [0.9505],\n",
      "        [0.9483],\n",
      "        [0.9270],\n",
      "        [0.8855],\n",
      "        [0.8911],\n",
      "        [0.8779],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.9767],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8656],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [1.0087],\n",
      "        [0.9201],\n",
      "        [0.9416],\n",
      "        [0.9426],\n",
      "        [0.9677],\n",
      "        [0.9477],\n",
      "        [0.9862],\n",
      "        [1.0100],\n",
      "        [0.9183],\n",
      "        [0.9452],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.9571],\n",
      "        [0.9434],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [0.9309],\n",
      "        [0.8617],\n",
      "        [0.8799],\n",
      "        [0.8978],\n",
      "        [0.9053],\n",
      "        [0.8617],\n",
      "        [0.8617],\n",
      "        [1.0340],\n",
      "        [1.0343]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0238],\n",
      "        [    0.0070],\n",
      "        [    0.0373],\n",
      "        [    0.0578],\n",
      "        [    0.0486],\n",
      "        [    0.0417],\n",
      "        [    0.0174],\n",
      "        [    0.0192],\n",
      "        [    0.0569],\n",
      "        [    0.0364],\n",
      "        [    0.0117],\n",
      "        [    0.0111],\n",
      "        [    0.0321],\n",
      "        [    0.0364],\n",
      "        [    0.0324],\n",
      "        [    0.0689],\n",
      "        [    0.0552],\n",
      "        [    0.0302],\n",
      "        [    0.0581],\n",
      "        [    0.0000],\n",
      "        [    0.0018],\n",
      "        [    0.0575],\n",
      "        [    0.0192],\n",
      "        [    0.0403],\n",
      "        [    0.0523],\n",
      "        [    0.0322],\n",
      "        [    0.0321],\n",
      "        [    0.0184],\n",
      "        [    0.0155],\n",
      "        [    0.0125],\n",
      "        [    0.0121],\n",
      "        [    0.0093],\n",
      "        [    0.0417],\n",
      "        [    0.0057],\n",
      "        [    0.0217],\n",
      "        [    0.0217],\n",
      "        [    0.0473],\n",
      "        [    0.0275],\n",
      "        [    0.0309],\n",
      "        [    0.0361],\n",
      "        [    0.0401],\n",
      "        [    0.0479],\n",
      "        [    0.0093],\n",
      "        [    0.0002],\n",
      "        [    0.0061],\n",
      "        [    0.0126],\n",
      "        [    0.0083],\n",
      "        [    0.0274],\n",
      "        [    0.0041],\n",
      "        [    0.0353],\n",
      "        [    0.0255],\n",
      "        [    0.0222],\n",
      "        [    0.0904],\n",
      "        [    0.0913],\n",
      "        [    0.0263],\n",
      "        [    0.0366],\n",
      "        [    0.1052],\n",
      "        [    0.1064],\n",
      "        [    0.0664],\n",
      "        [    0.1067],\n",
      "        [    0.0957],\n",
      "        [    0.0813],\n",
      "        [    0.0874],\n",
      "        [    0.1383],\n",
      "        [    0.1538],\n",
      "        [    0.1507],\n",
      "        [    0.1727]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0203],\n",
      "        [    0.0018],\n",
      "        [    0.0383],\n",
      "        [    0.0595],\n",
      "        [    0.0499],\n",
      "        [    0.0411],\n",
      "        [    0.0200],\n",
      "        [    0.0207],\n",
      "        [    0.0509],\n",
      "        [    0.0279],\n",
      "        [    0.0025],\n",
      "        [    0.0044],\n",
      "        [    0.0290],\n",
      "        [    0.0323],\n",
      "        [    0.0282],\n",
      "        [    0.0706],\n",
      "        [    0.0570],\n",
      "        [    0.0320],\n",
      "        [    0.0598],\n",
      "        [    0.0048],\n",
      "        [    0.0000],\n",
      "        [    0.0592],\n",
      "        [    0.0210],\n",
      "        [    0.0424],\n",
      "        [    0.0541],\n",
      "        [    0.0340],\n",
      "        [    0.0338],\n",
      "        [    0.0202],\n",
      "        [    0.0172],\n",
      "        [    0.0143],\n",
      "        [    0.0139],\n",
      "        [    0.0111],\n",
      "        [    0.0435],\n",
      "        [    0.0039],\n",
      "        [    0.0235],\n",
      "        [    0.0200],\n",
      "        [    0.0490],\n",
      "        [    0.0257],\n",
      "        [    0.0291],\n",
      "        [    0.0344],\n",
      "        [    0.0383],\n",
      "        [    0.0461],\n",
      "        [    0.0008],\n",
      "        [    0.0101],\n",
      "        [    0.0058],\n",
      "        [    0.0263],\n",
      "        [    0.0069],\n",
      "        [    0.0126],\n",
      "        [    0.0052],\n",
      "        [    0.0249],\n",
      "        [    0.0277],\n",
      "        [    0.0276],\n",
      "        [    0.0886],\n",
      "        [    0.0895],\n",
      "        [    0.0311],\n",
      "        [    0.0404],\n",
      "        [    0.1034],\n",
      "        [    0.1047],\n",
      "        [    0.0686],\n",
      "        [    0.1050],\n",
      "        [    0.0911],\n",
      "        [    0.0789],\n",
      "        [    0.0855],\n",
      "        [    0.1365],\n",
      "        [    0.1556],\n",
      "        [    0.1271],\n",
      "        [    0.1509]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.0436851978302\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 68\n",
      "剩餘X 資料 torch.Size([39, 18])\n",
      "剩餘Y 資料 torch.Size([39, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.032760631293058395, 0)\n",
      "The second_loss value of k: (0.07159262895584106, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.8743])\n",
      "目前模型的Data狀態 torch.Size([68, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9184],\n",
      "        [0.9301],\n",
      "        [0.8818],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8833],\n",
      "        [0.8647],\n",
      "        [0.9082],\n",
      "        [0.9398],\n",
      "        [0.9420],\n",
      "        [0.9392],\n",
      "        [0.9203],\n",
      "        [0.8824],\n",
      "        [0.8870],\n",
      "        [0.8736],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.9719],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [1.0002],\n",
      "        [0.9098],\n",
      "        [0.9296],\n",
      "        [0.9290],\n",
      "        [0.9525],\n",
      "        [0.9329],\n",
      "        [0.9770],\n",
      "        [0.9996],\n",
      "        [0.9161],\n",
      "        [0.9397],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.9522],\n",
      "        [0.9397],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.9287],\n",
      "        [0.8635],\n",
      "        [0.8845],\n",
      "        [0.9002],\n",
      "        [0.9073],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [1.0104],\n",
      "        [1.0126],\n",
      "        [1.0553]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0203],\n",
      "        [    0.0018],\n",
      "        [    0.0383],\n",
      "        [    0.0595],\n",
      "        [    0.0499],\n",
      "        [    0.0411],\n",
      "        [    0.0200],\n",
      "        [    0.0207],\n",
      "        [    0.0509],\n",
      "        [    0.0279],\n",
      "        [    0.0025],\n",
      "        [    0.0044],\n",
      "        [    0.0290],\n",
      "        [    0.0323],\n",
      "        [    0.0282],\n",
      "        [    0.0706],\n",
      "        [    0.0570],\n",
      "        [    0.0320],\n",
      "        [    0.0598],\n",
      "        [    0.0048],\n",
      "        [    0.0000],\n",
      "        [    0.0592],\n",
      "        [    0.0210],\n",
      "        [    0.0424],\n",
      "        [    0.0541],\n",
      "        [    0.0340],\n",
      "        [    0.0338],\n",
      "        [    0.0202],\n",
      "        [    0.0172],\n",
      "        [    0.0143],\n",
      "        [    0.0139],\n",
      "        [    0.0111],\n",
      "        [    0.0435],\n",
      "        [    0.0039],\n",
      "        [    0.0235],\n",
      "        [    0.0200],\n",
      "        [    0.0490],\n",
      "        [    0.0257],\n",
      "        [    0.0291],\n",
      "        [    0.0344],\n",
      "        [    0.0383],\n",
      "        [    0.0461],\n",
      "        [    0.0008],\n",
      "        [    0.0101],\n",
      "        [    0.0058],\n",
      "        [    0.0263],\n",
      "        [    0.0069],\n",
      "        [    0.0126],\n",
      "        [    0.0052],\n",
      "        [    0.0249],\n",
      "        [    0.0277],\n",
      "        [    0.0276],\n",
      "        [    0.0886],\n",
      "        [    0.0895],\n",
      "        [    0.0311],\n",
      "        [    0.0404],\n",
      "        [    0.1034],\n",
      "        [    0.1047],\n",
      "        [    0.0686],\n",
      "        [    0.1050],\n",
      "        [    0.0911],\n",
      "        [    0.0789],\n",
      "        [    0.0855],\n",
      "        [    0.1365],\n",
      "        [    0.1556],\n",
      "        [    0.1271],\n",
      "        [    0.1509],\n",
      "        [    0.1810]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0121],\n",
      "        [0.0079],\n",
      "        [0.0361],\n",
      "        [0.0583],\n",
      "        [0.0487],\n",
      "        [0.0371],\n",
      "        [0.0197],\n",
      "        [0.0263],\n",
      "        [0.0407],\n",
      "        [0.0157],\n",
      "        [0.0102],\n",
      "        [0.0053],\n",
      "        [0.0243],\n",
      "        [0.0262],\n",
      "        [0.0227],\n",
      "        [0.0694],\n",
      "        [0.0557],\n",
      "        [0.0307],\n",
      "        [0.0586],\n",
      "        [0.0161],\n",
      "        [0.0013],\n",
      "        [0.0580],\n",
      "        [0.0197],\n",
      "        [0.0437],\n",
      "        [0.0528],\n",
      "        [0.0327],\n",
      "        [0.0326],\n",
      "        [0.0190],\n",
      "        [0.0160],\n",
      "        [0.0130],\n",
      "        [0.0126],\n",
      "        [0.0098],\n",
      "        [0.0423],\n",
      "        [0.0052],\n",
      "        [0.0222],\n",
      "        [0.0212],\n",
      "        [0.0478],\n",
      "        [0.0270],\n",
      "        [0.0303],\n",
      "        [0.0356],\n",
      "        [0.0396],\n",
      "        [0.0474],\n",
      "        [0.0148],\n",
      "        [0.0223],\n",
      "        [0.0203],\n",
      "        [0.0417],\n",
      "        [0.0250],\n",
      "        [0.0041],\n",
      "        [0.0202],\n",
      "        [0.0078],\n",
      "        [0.0337],\n",
      "        [0.0373],\n",
      "        [0.0899],\n",
      "        [0.0908],\n",
      "        [0.0409],\n",
      "        [0.0488],\n",
      "        [0.1047],\n",
      "        [0.1059],\n",
      "        [0.0750],\n",
      "        [0.1062],\n",
      "        [0.0906],\n",
      "        [0.0805],\n",
      "        [0.0881],\n",
      "        [0.1378],\n",
      "        [0.1543],\n",
      "        [0.0991],\n",
      "        [0.1236],\n",
      "        [0.1477]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.280935525894165\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 69\n",
      "剩餘X 資料 torch.Size([38, 18])\n",
      "剩餘Y 資料 torch.Size([38, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.05147445946931839, 0)\n",
      "The second_loss value of k: (0.07302940636873245, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.8356])\n",
      "目前模型的Data狀態 torch.Size([69, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9103],\n",
      "        [0.9204],\n",
      "        [0.8796],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8792],\n",
      "        [0.8644],\n",
      "        [0.9026],\n",
      "        [0.9297],\n",
      "        [0.9298],\n",
      "        [0.9265],\n",
      "        [0.9106],\n",
      "        [0.8776],\n",
      "        [0.8810],\n",
      "        [0.8681],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.9606],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.9846],\n",
      "        [0.8977],\n",
      "        [0.9152],\n",
      "        [0.9135],\n",
      "        [0.9344],\n",
      "        [0.9162],\n",
      "        [0.9619],\n",
      "        [0.9826],\n",
      "        [0.9101],\n",
      "        [0.9300],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.9425],\n",
      "        [0.9313],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.9223],\n",
      "        [0.8622],\n",
      "        [0.8849],\n",
      "        [0.8985],\n",
      "        [0.9047],\n",
      "        [0.8622],\n",
      "        [0.8622],\n",
      "        [0.9824],\n",
      "        [0.9853],\n",
      "        [1.0221],\n",
      "        [1.0625]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0121],\n",
      "        [0.0079],\n",
      "        [0.0361],\n",
      "        [0.0583],\n",
      "        [0.0487],\n",
      "        [0.0371],\n",
      "        [0.0197],\n",
      "        [0.0263],\n",
      "        [0.0407],\n",
      "        [0.0157],\n",
      "        [0.0102],\n",
      "        [0.0053],\n",
      "        [0.0243],\n",
      "        [0.0262],\n",
      "        [0.0227],\n",
      "        [0.0694],\n",
      "        [0.0557],\n",
      "        [0.0307],\n",
      "        [0.0586],\n",
      "        [0.0161],\n",
      "        [0.0013],\n",
      "        [0.0580],\n",
      "        [0.0197],\n",
      "        [0.0437],\n",
      "        [0.0528],\n",
      "        [0.0327],\n",
      "        [0.0326],\n",
      "        [0.0190],\n",
      "        [0.0160],\n",
      "        [0.0130],\n",
      "        [0.0126],\n",
      "        [0.0098],\n",
      "        [0.0423],\n",
      "        [0.0052],\n",
      "        [0.0222],\n",
      "        [0.0212],\n",
      "        [0.0478],\n",
      "        [0.0270],\n",
      "        [0.0303],\n",
      "        [0.0356],\n",
      "        [0.0396],\n",
      "        [0.0474],\n",
      "        [0.0148],\n",
      "        [0.0223],\n",
      "        [0.0203],\n",
      "        [0.0417],\n",
      "        [0.0250],\n",
      "        [0.0041],\n",
      "        [0.0202],\n",
      "        [0.0078],\n",
      "        [0.0337],\n",
      "        [0.0373],\n",
      "        [0.0899],\n",
      "        [0.0908],\n",
      "        [0.0409],\n",
      "        [0.0488],\n",
      "        [0.1047],\n",
      "        [0.1059],\n",
      "        [0.0750],\n",
      "        [0.1062],\n",
      "        [0.0906],\n",
      "        [0.0805],\n",
      "        [0.0881],\n",
      "        [0.1378],\n",
      "        [0.1543],\n",
      "        [0.0991],\n",
      "        [0.1236],\n",
      "        [0.1477],\n",
      "        [0.2269]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.2\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 53\n",
      "Number of shrink: 8\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0067],\n",
      "        [0.0145],\n",
      "        [0.0347],\n",
      "        [0.0583],\n",
      "        [0.0487],\n",
      "        [0.0348],\n",
      "        [0.0197],\n",
      "        [0.0304],\n",
      "        [0.0336],\n",
      "        [0.0077],\n",
      "        [0.0182],\n",
      "        [0.0113],\n",
      "        [0.0220],\n",
      "        [0.0233],\n",
      "        [0.0206],\n",
      "        [0.0694],\n",
      "        [0.0557],\n",
      "        [0.0307],\n",
      "        [0.0586],\n",
      "        [0.0254],\n",
      "        [0.0013],\n",
      "        [0.0580],\n",
      "        [0.0197],\n",
      "        [0.0437],\n",
      "        [0.0528],\n",
      "        [0.0327],\n",
      "        [0.0326],\n",
      "        [0.0190],\n",
      "        [0.0160],\n",
      "        [0.0130],\n",
      "        [0.0126],\n",
      "        [0.0098],\n",
      "        [0.0423],\n",
      "        [0.0052],\n",
      "        [0.0222],\n",
      "        [0.0212],\n",
      "        [0.0478],\n",
      "        [0.0270],\n",
      "        [0.0303],\n",
      "        [0.0356],\n",
      "        [0.0396],\n",
      "        [0.0474],\n",
      "        [0.0271],\n",
      "        [0.0288],\n",
      "        [0.0285],\n",
      "        [0.0503],\n",
      "        [0.0357],\n",
      "        [0.0133],\n",
      "        [0.0313],\n",
      "        [0.0051],\n",
      "        [0.0380],\n",
      "        [0.0441],\n",
      "        [0.0899],\n",
      "        [0.0908],\n",
      "        [0.0481],\n",
      "        [0.0550],\n",
      "        [0.1047],\n",
      "        [0.1059],\n",
      "        [0.0799],\n",
      "        [0.1062],\n",
      "        [0.0911],\n",
      "        [0.0823],\n",
      "        [0.0906],\n",
      "        [0.1378],\n",
      "        [0.1543],\n",
      "        [0.0816],\n",
      "        [0.1062],\n",
      "        [0.1258],\n",
      "        [0.1996]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.19584802]\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 13\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0071],\n",
      "        [0.0140],\n",
      "        [0.0351],\n",
      "        [0.0584],\n",
      "        [0.0488],\n",
      "        [0.0353],\n",
      "        [0.0201],\n",
      "        [0.0300],\n",
      "        [0.0341],\n",
      "        [0.0082],\n",
      "        [0.0178],\n",
      "        [0.0109],\n",
      "        [0.0224],\n",
      "        [0.0237],\n",
      "        [0.0210],\n",
      "        [0.0695],\n",
      "        [0.0558],\n",
      "        [0.0308],\n",
      "        [0.0587],\n",
      "        [0.0249],\n",
      "        [0.0012],\n",
      "        [0.0581],\n",
      "        [0.0198],\n",
      "        [0.0436],\n",
      "        [0.0529],\n",
      "        [0.0328],\n",
      "        [0.0327],\n",
      "        [0.0191],\n",
      "        [0.0161],\n",
      "        [0.0132],\n",
      "        [0.0128],\n",
      "        [0.0100],\n",
      "        [0.0424],\n",
      "        [0.0051],\n",
      "        [0.0223],\n",
      "        [0.0211],\n",
      "        [0.0479],\n",
      "        [0.0269],\n",
      "        [0.0302],\n",
      "        [0.0355],\n",
      "        [0.0395],\n",
      "        [0.0472],\n",
      "        [0.0267],\n",
      "        [0.0284],\n",
      "        [0.0281],\n",
      "        [0.0499],\n",
      "        [0.0354],\n",
      "        [0.0129],\n",
      "        [0.0309],\n",
      "        [0.0047],\n",
      "        [0.0376],\n",
      "        [0.0436],\n",
      "        [0.0898],\n",
      "        [0.0906],\n",
      "        [0.0477],\n",
      "        [0.0545],\n",
      "        [0.1046],\n",
      "        [0.1058],\n",
      "        [0.0795],\n",
      "        [0.1061],\n",
      "        [0.0906],\n",
      "        [0.0819],\n",
      "        [0.0901],\n",
      "        [0.1376],\n",
      "        [0.1544],\n",
      "        [0.0820],\n",
      "        [0.1066],\n",
      "        [0.1261],\n",
      "        [0.2000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.47190237045288\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 70\n",
      "剩餘X 資料 torch.Size([37, 18])\n",
      "剩餘Y 資料 torch.Size([37, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.056595370173454285, 0)\n",
      "The second_loss value of k: (0.1635180413722992, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.8355])\n",
      "目前模型的Data狀態 torch.Size([70, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9053],\n",
      "        [0.9143],\n",
      "        [0.8786],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8774],\n",
      "        [0.8648],\n",
      "        [0.8989],\n",
      "        [0.9230],\n",
      "        [0.9223],\n",
      "        [0.9189],\n",
      "        [0.9050],\n",
      "        [0.8758],\n",
      "        [0.8784],\n",
      "        [0.8665],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.9518],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.9727],\n",
      "        [0.8916],\n",
      "        [0.9073],\n",
      "        [0.9053],\n",
      "        [0.9240],\n",
      "        [0.9073],\n",
      "        [0.9512],\n",
      "        [0.9700],\n",
      "        [0.9062],\n",
      "        [0.9237],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.9357],\n",
      "        [0.9255],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.9177],\n",
      "        [0.8624],\n",
      "        [0.8849],\n",
      "        [0.8972],\n",
      "        [0.9026],\n",
      "        [0.8624],\n",
      "        [0.8624],\n",
      "        [0.9653],\n",
      "        [0.9682],\n",
      "        [1.0005],\n",
      "        [1.0356],\n",
      "        [1.0734]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0071],\n",
      "        [0.0140],\n",
      "        [0.0351],\n",
      "        [0.0584],\n",
      "        [0.0488],\n",
      "        [0.0353],\n",
      "        [0.0201],\n",
      "        [0.0300],\n",
      "        [0.0341],\n",
      "        [0.0082],\n",
      "        [0.0178],\n",
      "        [0.0109],\n",
      "        [0.0224],\n",
      "        [0.0237],\n",
      "        [0.0210],\n",
      "        [0.0695],\n",
      "        [0.0558],\n",
      "        [0.0308],\n",
      "        [0.0587],\n",
      "        [0.0249],\n",
      "        [0.0012],\n",
      "        [0.0581],\n",
      "        [0.0198],\n",
      "        [0.0436],\n",
      "        [0.0529],\n",
      "        [0.0328],\n",
      "        [0.0327],\n",
      "        [0.0191],\n",
      "        [0.0161],\n",
      "        [0.0132],\n",
      "        [0.0128],\n",
      "        [0.0100],\n",
      "        [0.0424],\n",
      "        [0.0051],\n",
      "        [0.0223],\n",
      "        [0.0211],\n",
      "        [0.0479],\n",
      "        [0.0269],\n",
      "        [0.0302],\n",
      "        [0.0355],\n",
      "        [0.0395],\n",
      "        [0.0472],\n",
      "        [0.0267],\n",
      "        [0.0284],\n",
      "        [0.0281],\n",
      "        [0.0499],\n",
      "        [0.0354],\n",
      "        [0.0129],\n",
      "        [0.0309],\n",
      "        [0.0047],\n",
      "        [0.0376],\n",
      "        [0.0436],\n",
      "        [0.0898],\n",
      "        [0.0906],\n",
      "        [0.0477],\n",
      "        [0.0545],\n",
      "        [0.1046],\n",
      "        [0.1058],\n",
      "        [0.0795],\n",
      "        [0.1061],\n",
      "        [0.0906],\n",
      "        [0.0819],\n",
      "        [0.0901],\n",
      "        [0.1376],\n",
      "        [0.1544],\n",
      "        [0.0820],\n",
      "        [0.1066],\n",
      "        [0.1261],\n",
      "        [0.2000],\n",
      "        [0.2379]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.2\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 53\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0018],\n",
      "        [    0.0209],\n",
      "        [    0.0350],\n",
      "        [    0.0584],\n",
      "        [    0.0506],\n",
      "        [    0.0345],\n",
      "        [    0.0218],\n",
      "        [    0.0341],\n",
      "        [    0.0266],\n",
      "        [    0.0000],\n",
      "        [    0.0259],\n",
      "        [    0.0164],\n",
      "        [    0.0221],\n",
      "        [    0.0226],\n",
      "        [    0.0217],\n",
      "        [    0.0694],\n",
      "        [    0.0558],\n",
      "        [    0.0308],\n",
      "        [    0.0587],\n",
      "        [    0.0368],\n",
      "        [    0.0012],\n",
      "        [    0.0580],\n",
      "        [    0.0198],\n",
      "        [    0.0436],\n",
      "        [    0.0529],\n",
      "        [    0.0328],\n",
      "        [    0.0327],\n",
      "        [    0.0190],\n",
      "        [    0.0161],\n",
      "        [    0.0131],\n",
      "        [    0.0127],\n",
      "        [    0.0099],\n",
      "        [    0.0423],\n",
      "        [    0.0051],\n",
      "        [    0.0223],\n",
      "        [    0.0212],\n",
      "        [    0.0479],\n",
      "        [    0.0269],\n",
      "        [    0.0303],\n",
      "        [    0.0355],\n",
      "        [    0.0395],\n",
      "        [    0.0473],\n",
      "        [    0.0427],\n",
      "        [    0.0336],\n",
      "        [    0.0359],\n",
      "        [    0.0578],\n",
      "        [    0.0463],\n",
      "        [    0.0215],\n",
      "        [    0.0445],\n",
      "        [    0.0211],\n",
      "        [    0.0417],\n",
      "        [    0.0510],\n",
      "        [    0.0898],\n",
      "        [    0.0907],\n",
      "        [    0.0564],\n",
      "        [    0.0615],\n",
      "        [    0.1046],\n",
      "        [    0.1059],\n",
      "        [    0.0852],\n",
      "        [    0.1062],\n",
      "        [    0.0902],\n",
      "        [    0.0833],\n",
      "        [    0.0926],\n",
      "        [    0.1377],\n",
      "        [    0.1544],\n",
      "        [    0.0626],\n",
      "        [    0.0870],\n",
      "        [    0.1004],\n",
      "        [    0.1671],\n",
      "        [    0.1977]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.19584802]\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 25\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0048],\n",
      "        [    0.0180],\n",
      "        [    0.0380],\n",
      "        [    0.0596],\n",
      "        [    0.0536],\n",
      "        [    0.0375],\n",
      "        [    0.0247],\n",
      "        [    0.0313],\n",
      "        [    0.0295],\n",
      "        [    0.0029],\n",
      "        [    0.0230],\n",
      "        [    0.0135],\n",
      "        [    0.0250],\n",
      "        [    0.0256],\n",
      "        [    0.0246],\n",
      "        [    0.0706],\n",
      "        [    0.0570],\n",
      "        [    0.0320],\n",
      "        [    0.0599],\n",
      "        [    0.0340],\n",
      "        [    0.0000],\n",
      "        [    0.0592],\n",
      "        [    0.0210],\n",
      "        [    0.0424],\n",
      "        [    0.0541],\n",
      "        [    0.0340],\n",
      "        [    0.0339],\n",
      "        [    0.0202],\n",
      "        [    0.0172],\n",
      "        [    0.0143],\n",
      "        [    0.0139],\n",
      "        [    0.0111],\n",
      "        [    0.0435],\n",
      "        [    0.0039],\n",
      "        [    0.0235],\n",
      "        [    0.0200],\n",
      "        [    0.0491],\n",
      "        [    0.0257],\n",
      "        [    0.0291],\n",
      "        [    0.0343],\n",
      "        [    0.0383],\n",
      "        [    0.0461],\n",
      "        [    0.0400],\n",
      "        [    0.0308],\n",
      "        [    0.0331],\n",
      "        [    0.0550],\n",
      "        [    0.0437],\n",
      "        [    0.0187],\n",
      "        [    0.0418],\n",
      "        [    0.0185],\n",
      "        [    0.0387],\n",
      "        [    0.0480],\n",
      "        [    0.0886],\n",
      "        [    0.0895],\n",
      "        [    0.0534],\n",
      "        [    0.0585],\n",
      "        [    0.1034],\n",
      "        [    0.1047],\n",
      "        [    0.0822],\n",
      "        [    0.1050],\n",
      "        [    0.0871],\n",
      "        [    0.0802],\n",
      "        [    0.0896],\n",
      "        [    0.1365],\n",
      "        [    0.1556],\n",
      "        [    0.0653],\n",
      "        [    0.0896],\n",
      "        [    0.1029],\n",
      "        [    0.1695],\n",
      "        [    0.1998]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.685428857803345\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 71\n",
      "剩餘X 資料 torch.Size([36, 18])\n",
      "剩餘Y 資料 torch.Size([36, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.11731831729412079, 0)\n",
      "The second_loss value of k: (0.13462844491004944, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.7936])\n",
      "目前模型的Data狀態 torch.Size([71, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9029],\n",
      "        [0.9104],\n",
      "        [0.8815],\n",
      "        [0.8635],\n",
      "        [0.8672],\n",
      "        [0.8796],\n",
      "        [0.8694],\n",
      "        [0.8976],\n",
      "        [0.9184],\n",
      "        [0.9170],\n",
      "        [0.9137],\n",
      "        [0.9024],\n",
      "        [0.8784],\n",
      "        [0.8803],\n",
      "        [0.8700],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.9427],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.9594],\n",
      "        [0.8892],\n",
      "        [0.9023],\n",
      "        [0.9002],\n",
      "        [0.9157],\n",
      "        [0.9016],\n",
      "        [0.9403],\n",
      "        [0.9563],\n",
      "        [0.9051],\n",
      "        [0.9193],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.9299],\n",
      "        [0.9215],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.9151],\n",
      "        [0.8635],\n",
      "        [0.8885],\n",
      "        [0.8988],\n",
      "        [0.9032],\n",
      "        [0.8635],\n",
      "        [0.8635],\n",
      "        [0.9486],\n",
      "        [0.9513],\n",
      "        [0.9773],\n",
      "        [1.0052],\n",
      "        [1.0353],\n",
      "        [1.1361]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0048],\n",
      "        [    0.0180],\n",
      "        [    0.0380],\n",
      "        [    0.0596],\n",
      "        [    0.0536],\n",
      "        [    0.0375],\n",
      "        [    0.0247],\n",
      "        [    0.0313],\n",
      "        [    0.0295],\n",
      "        [    0.0029],\n",
      "        [    0.0230],\n",
      "        [    0.0135],\n",
      "        [    0.0250],\n",
      "        [    0.0256],\n",
      "        [    0.0246],\n",
      "        [    0.0706],\n",
      "        [    0.0570],\n",
      "        [    0.0320],\n",
      "        [    0.0599],\n",
      "        [    0.0340],\n",
      "        [    0.0000],\n",
      "        [    0.0592],\n",
      "        [    0.0210],\n",
      "        [    0.0424],\n",
      "        [    0.0541],\n",
      "        [    0.0340],\n",
      "        [    0.0339],\n",
      "        [    0.0202],\n",
      "        [    0.0172],\n",
      "        [    0.0143],\n",
      "        [    0.0139],\n",
      "        [    0.0111],\n",
      "        [    0.0435],\n",
      "        [    0.0039],\n",
      "        [    0.0235],\n",
      "        [    0.0200],\n",
      "        [    0.0491],\n",
      "        [    0.0257],\n",
      "        [    0.0291],\n",
      "        [    0.0343],\n",
      "        [    0.0383],\n",
      "        [    0.0461],\n",
      "        [    0.0400],\n",
      "        [    0.0308],\n",
      "        [    0.0331],\n",
      "        [    0.0550],\n",
      "        [    0.0437],\n",
      "        [    0.0187],\n",
      "        [    0.0418],\n",
      "        [    0.0185],\n",
      "        [    0.0387],\n",
      "        [    0.0480],\n",
      "        [    0.0886],\n",
      "        [    0.0895],\n",
      "        [    0.0534],\n",
      "        [    0.0585],\n",
      "        [    0.1034],\n",
      "        [    0.1047],\n",
      "        [    0.0822],\n",
      "        [    0.1050],\n",
      "        [    0.0871],\n",
      "        [    0.0802],\n",
      "        [    0.0896],\n",
      "        [    0.1365],\n",
      "        [    0.1556],\n",
      "        [    0.0653],\n",
      "        [    0.0896],\n",
      "        [    0.1029],\n",
      "        [    0.1695],\n",
      "        [    0.1998],\n",
      "        [    0.3425]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.2\n",
      "Matching finished - the network is acceptable\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 12\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0020],\n",
      "        [0.0291],\n",
      "        [0.0436],\n",
      "        [0.0706],\n",
      "        [0.0664],\n",
      "        [0.0431],\n",
      "        [0.0358],\n",
      "        [0.0361],\n",
      "        [0.0143],\n",
      "        [0.0123],\n",
      "        [0.0371],\n",
      "        [0.0211],\n",
      "        [0.0310],\n",
      "        [0.0303],\n",
      "        [0.0346],\n",
      "        [0.0771],\n",
      "        [0.0654],\n",
      "        [0.0442],\n",
      "        [0.0671],\n",
      "        [0.0621],\n",
      "        [0.0059],\n",
      "        [0.0651],\n",
      "        [0.0269],\n",
      "        [0.0307],\n",
      "        [0.0600],\n",
      "        [0.0399],\n",
      "        [0.0398],\n",
      "        [0.0261],\n",
      "        [0.0232],\n",
      "        [0.0202],\n",
      "        [0.0198],\n",
      "        [0.0170],\n",
      "        [0.0494],\n",
      "        [0.0020],\n",
      "        [0.0294],\n",
      "        [0.0141],\n",
      "        [0.0550],\n",
      "        [0.0198],\n",
      "        [0.0232],\n",
      "        [0.0284],\n",
      "        [0.0324],\n",
      "        [0.0402],\n",
      "        [0.0783],\n",
      "        [0.0333],\n",
      "        [0.0430],\n",
      "        [0.0641],\n",
      "        [0.0615],\n",
      "        [0.0287],\n",
      "        [0.0711],\n",
      "        [0.0561],\n",
      "        [0.0457],\n",
      "        [0.0633],\n",
      "        [0.0827],\n",
      "        [0.0836],\n",
      "        [0.0739],\n",
      "        [0.0741],\n",
      "        [0.0975],\n",
      "        [0.0988],\n",
      "        [0.0945],\n",
      "        [0.0991],\n",
      "        [0.0833],\n",
      "        [0.0825],\n",
      "        [0.0944],\n",
      "        [0.1306],\n",
      "        [0.1615],\n",
      "        [0.0280],\n",
      "        [0.0515],\n",
      "        [0.0495],\n",
      "        [0.0991],\n",
      "        [0.1111],\n",
      "        [0.1942]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.19584802]\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0024],\n",
      "        [0.0261],\n",
      "        [0.0509],\n",
      "        [0.0816],\n",
      "        [0.0755],\n",
      "        [0.0502],\n",
      "        [0.0435],\n",
      "        [0.0329],\n",
      "        [0.0162],\n",
      "        [0.0104],\n",
      "        [0.0349],\n",
      "        [0.0174],\n",
      "        [0.0384],\n",
      "        [0.0373],\n",
      "        [0.0429],\n",
      "        [0.0884],\n",
      "        [0.0751],\n",
      "        [0.0522],\n",
      "        [0.0767],\n",
      "        [0.0644],\n",
      "        [0.0143],\n",
      "        [0.0659],\n",
      "        [0.0315],\n",
      "        [0.0210],\n",
      "        [0.0666],\n",
      "        [0.0384],\n",
      "        [0.0349],\n",
      "        [0.0229],\n",
      "        [0.0149],\n",
      "        [0.0267],\n",
      "        [0.0122],\n",
      "        [0.0196],\n",
      "        [0.0568],\n",
      "        [0.0031],\n",
      "        [0.0379],\n",
      "        [0.0103],\n",
      "        [0.0640],\n",
      "        [0.0213],\n",
      "        [0.0196],\n",
      "        [0.0229],\n",
      "        [0.0334],\n",
      "        [0.0390],\n",
      "        [0.0839],\n",
      "        [0.0282],\n",
      "        [0.0399],\n",
      "        [0.0604],\n",
      "        [0.0604],\n",
      "        [0.0249],\n",
      "        [0.0747],\n",
      "        [0.0616],\n",
      "        [0.0414],\n",
      "        [0.0613],\n",
      "        [0.0888],\n",
      "        [0.0742],\n",
      "        [0.0733],\n",
      "        [0.0719],\n",
      "        [0.0947],\n",
      "        [0.1002],\n",
      "        [0.0919],\n",
      "        [0.0915],\n",
      "        [0.0762],\n",
      "        [0.0769],\n",
      "        [0.0896],\n",
      "        [0.1221],\n",
      "        [0.1553],\n",
      "        [0.0247],\n",
      "        [0.0480],\n",
      "        [0.0415],\n",
      "        [0.0860],\n",
      "        [0.0927],\n",
      "        [0.1595]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 14.08678126335144\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 72\n",
      "剩餘X 資料 torch.Size([35, 18])\n",
      "剩餘Y 資料 torch.Size([35, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.02208602987229824, 0)\n",
      "The second_loss value of k: (0.050978872925043106, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.8166])\n",
      "目前模型的Data狀態 torch.Size([72, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9005],\n",
      "        [0.9022],\n",
      "        [0.8944],\n",
      "        [0.8856],\n",
      "        [0.8891],\n",
      "        [0.8923],\n",
      "        [0.8882],\n",
      "        [0.8960],\n",
      "        [0.9052],\n",
      "        [0.9037],\n",
      "        [0.9017],\n",
      "        [0.8985],\n",
      "        [0.8917],\n",
      "        [0.8921],\n",
      "        [0.8883],\n",
      "        [0.8812],\n",
      "        [0.8816],\n",
      "        [0.8837],\n",
      "        [0.8803],\n",
      "        [0.9123],\n",
      "        [0.8778],\n",
      "        [0.8702],\n",
      "        [0.8741],\n",
      "        [0.8849],\n",
      "        [0.8761],\n",
      "        [0.8679],\n",
      "        [0.8646],\n",
      "        [0.8662],\n",
      "        [0.8612],\n",
      "        [0.8759],\n",
      "        [0.8618],\n",
      "        [0.8720],\n",
      "        [0.8767],\n",
      "        [0.8705],\n",
      "        [0.8779],\n",
      "        [0.8732],\n",
      "        [0.8785],\n",
      "        [0.8680],\n",
      "        [0.8730],\n",
      "        [0.8749],\n",
      "        [0.8685],\n",
      "        [0.8705],\n",
      "        [0.9155],\n",
      "        [0.8918],\n",
      "        [0.8956],\n",
      "        [0.8949],\n",
      "        [0.8990],\n",
      "        [0.8954],\n",
      "        [0.9074],\n",
      "        [0.9131],\n",
      "        [0.9024],\n",
      "        [0.9061],\n",
      "        [0.8633],\n",
      "        [0.8788],\n",
      "        [0.9101],\n",
      "        [0.9081],\n",
      "        [0.8722],\n",
      "        [0.8680],\n",
      "        [0.9053],\n",
      "        [0.8770],\n",
      "        [0.8994],\n",
      "        [0.9022],\n",
      "        [0.9031],\n",
      "        [0.8779],\n",
      "        [0.8632],\n",
      "        [0.9080],\n",
      "        [0.9096],\n",
      "        [0.9158],\n",
      "        [0.9217],\n",
      "        [0.9282],\n",
      "        [0.9531],\n",
      "        [0.9653]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0024],\n",
      "        [0.0261],\n",
      "        [0.0509],\n",
      "        [0.0816],\n",
      "        [0.0755],\n",
      "        [0.0502],\n",
      "        [0.0435],\n",
      "        [0.0329],\n",
      "        [0.0162],\n",
      "        [0.0104],\n",
      "        [0.0349],\n",
      "        [0.0174],\n",
      "        [0.0384],\n",
      "        [0.0373],\n",
      "        [0.0429],\n",
      "        [0.0884],\n",
      "        [0.0751],\n",
      "        [0.0522],\n",
      "        [0.0767],\n",
      "        [0.0644],\n",
      "        [0.0143],\n",
      "        [0.0659],\n",
      "        [0.0315],\n",
      "        [0.0210],\n",
      "        [0.0666],\n",
      "        [0.0384],\n",
      "        [0.0349],\n",
      "        [0.0229],\n",
      "        [0.0149],\n",
      "        [0.0267],\n",
      "        [0.0122],\n",
      "        [0.0196],\n",
      "        [0.0568],\n",
      "        [0.0031],\n",
      "        [0.0379],\n",
      "        [0.0103],\n",
      "        [0.0640],\n",
      "        [0.0213],\n",
      "        [0.0196],\n",
      "        [0.0229],\n",
      "        [0.0334],\n",
      "        [0.0390],\n",
      "        [0.0839],\n",
      "        [0.0282],\n",
      "        [0.0399],\n",
      "        [0.0604],\n",
      "        [0.0604],\n",
      "        [0.0249],\n",
      "        [0.0747],\n",
      "        [0.0616],\n",
      "        [0.0414],\n",
      "        [0.0613],\n",
      "        [0.0888],\n",
      "        [0.0742],\n",
      "        [0.0733],\n",
      "        [0.0719],\n",
      "        [0.0947],\n",
      "        [0.1002],\n",
      "        [0.0919],\n",
      "        [0.0915],\n",
      "        [0.0762],\n",
      "        [0.0769],\n",
      "        [0.0896],\n",
      "        [0.1221],\n",
      "        [0.1553],\n",
      "        [0.0247],\n",
      "        [0.0480],\n",
      "        [0.0415],\n",
      "        [0.0860],\n",
      "        [0.0927],\n",
      "        [0.1595],\n",
      "        [0.1486]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0013],\n",
      "        [0.0304],\n",
      "        [0.0490],\n",
      "        [0.0819],\n",
      "        [0.0749],\n",
      "        [0.0484],\n",
      "        [0.0426],\n",
      "        [0.0362],\n",
      "        [0.0113],\n",
      "        [0.0151],\n",
      "        [0.0393],\n",
      "        [0.0209],\n",
      "        [0.0369],\n",
      "        [0.0356],\n",
      "        [0.0421],\n",
      "        [0.0894],\n",
      "        [0.0756],\n",
      "        [0.0521],\n",
      "        [0.0774],\n",
      "        [0.0715],\n",
      "        [0.0156],\n",
      "        [0.0695],\n",
      "        [0.0339],\n",
      "        [0.0210],\n",
      "        [0.0685],\n",
      "        [0.0429],\n",
      "        [0.0411],\n",
      "        [0.0288],\n",
      "        [0.0168],\n",
      "        [0.0287],\n",
      "        [0.0185],\n",
      "        [0.0231],\n",
      "        [0.0582],\n",
      "        [0.0076],\n",
      "        [0.0389],\n",
      "        [0.0068],\n",
      "        [0.0650],\n",
      "        [0.0165],\n",
      "        [0.0158],\n",
      "        [0.0202],\n",
      "        [0.0277],\n",
      "        [0.0344],\n",
      "        [0.0923],\n",
      "        [0.0303],\n",
      "        [0.0431],\n",
      "        [0.0633],\n",
      "        [0.0647],\n",
      "        [0.0279],\n",
      "        [0.0813],\n",
      "        [0.0696],\n",
      "        [0.0453],\n",
      "        [0.0663],\n",
      "        [0.0814],\n",
      "        [0.0732],\n",
      "        [0.0794],\n",
      "        [0.0773],\n",
      "        [0.0902],\n",
      "        [0.0948],\n",
      "        [0.0968],\n",
      "        [0.0892],\n",
      "        [0.0789],\n",
      "        [0.0805],\n",
      "        [0.0936],\n",
      "        [0.1204],\n",
      "        [0.1626],\n",
      "        [0.0180],\n",
      "        [0.0409],\n",
      "        [0.0324],\n",
      "        [0.0748],\n",
      "        [0.0792],\n",
      "        [0.1381],\n",
      "        [0.1234]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 14.320340394973755\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 73\n",
      "剩餘X 資料 torch.Size([34, 18])\n",
      "剩餘Y 資料 torch.Size([34, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0384601429104805, 5)\n",
      "The second_loss value of k: (0.03905768319964409, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引5，y= tensor([0.7606])\n",
      "目前模型的Data狀態 torch.Size([73, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8969],\n",
      "        [0.8980],\n",
      "        [0.8925],\n",
      "        [0.8859],\n",
      "        [0.8884],\n",
      "        [0.8906],\n",
      "        [0.8873],\n",
      "        [0.8928],\n",
      "        [0.9002],\n",
      "        [0.8990],\n",
      "        [0.8974],\n",
      "        [0.8950],\n",
      "        [0.8902],\n",
      "        [0.8904],\n",
      "        [0.8875],\n",
      "        [0.8823],\n",
      "        [0.8822],\n",
      "        [0.8836],\n",
      "        [0.8811],\n",
      "        [0.9052],\n",
      "        [0.8792],\n",
      "        [0.8738],\n",
      "        [0.8764],\n",
      "        [0.8850],\n",
      "        [0.8779],\n",
      "        [0.8724],\n",
      "        [0.8707],\n",
      "        [0.8721],\n",
      "        [0.8630],\n",
      "        [0.8779],\n",
      "        [0.8680],\n",
      "        [0.8755],\n",
      "        [0.8782],\n",
      "        [0.8750],\n",
      "        [0.8789],\n",
      "        [0.8766],\n",
      "        [0.8795],\n",
      "        [0.8727],\n",
      "        [0.8768],\n",
      "        [0.8777],\n",
      "        [0.8742],\n",
      "        [0.8752],\n",
      "        [0.9071],\n",
      "        [0.8897],\n",
      "        [0.8924],\n",
      "        [0.8919],\n",
      "        [0.8947],\n",
      "        [0.8924],\n",
      "        [0.9008],\n",
      "        [0.9051],\n",
      "        [0.8984],\n",
      "        [0.9010],\n",
      "        [0.8707],\n",
      "        [0.8798],\n",
      "        [0.9040],\n",
      "        [0.9027],\n",
      "        [0.8767],\n",
      "        [0.8733],\n",
      "        [0.9005],\n",
      "        [0.8792],\n",
      "        [0.8966],\n",
      "        [0.8985],\n",
      "        [0.8992],\n",
      "        [0.8796],\n",
      "        [0.8705],\n",
      "        [0.9013],\n",
      "        [0.9026],\n",
      "        [0.9068],\n",
      "        [0.9105],\n",
      "        [0.9147],\n",
      "        [0.9317],\n",
      "        [0.9401],\n",
      "        [0.9567]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0013],\n",
      "        [0.0304],\n",
      "        [0.0490],\n",
      "        [0.0819],\n",
      "        [0.0749],\n",
      "        [0.0484],\n",
      "        [0.0426],\n",
      "        [0.0362],\n",
      "        [0.0113],\n",
      "        [0.0151],\n",
      "        [0.0393],\n",
      "        [0.0209],\n",
      "        [0.0369],\n",
      "        [0.0356],\n",
      "        [0.0421],\n",
      "        [0.0894],\n",
      "        [0.0756],\n",
      "        [0.0521],\n",
      "        [0.0774],\n",
      "        [0.0715],\n",
      "        [0.0156],\n",
      "        [0.0695],\n",
      "        [0.0339],\n",
      "        [0.0210],\n",
      "        [0.0685],\n",
      "        [0.0429],\n",
      "        [0.0411],\n",
      "        [0.0288],\n",
      "        [0.0168],\n",
      "        [0.0287],\n",
      "        [0.0185],\n",
      "        [0.0231],\n",
      "        [0.0582],\n",
      "        [0.0076],\n",
      "        [0.0389],\n",
      "        [0.0068],\n",
      "        [0.0650],\n",
      "        [0.0165],\n",
      "        [0.0158],\n",
      "        [0.0202],\n",
      "        [0.0277],\n",
      "        [0.0344],\n",
      "        [0.0923],\n",
      "        [0.0303],\n",
      "        [0.0431],\n",
      "        [0.0633],\n",
      "        [0.0647],\n",
      "        [0.0279],\n",
      "        [0.0813],\n",
      "        [0.0696],\n",
      "        [0.0453],\n",
      "        [0.0663],\n",
      "        [0.0814],\n",
      "        [0.0732],\n",
      "        [0.0794],\n",
      "        [0.0773],\n",
      "        [0.0902],\n",
      "        [0.0948],\n",
      "        [0.0968],\n",
      "        [0.0892],\n",
      "        [0.0789],\n",
      "        [0.0805],\n",
      "        [0.0936],\n",
      "        [0.1204],\n",
      "        [0.1626],\n",
      "        [0.0180],\n",
      "        [0.0409],\n",
      "        [0.0324],\n",
      "        [0.0748],\n",
      "        [0.0792],\n",
      "        [0.1381],\n",
      "        [0.1234],\n",
      "        [0.1961]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0070],\n",
      "        [0.0367],\n",
      "        [0.0459],\n",
      "        [0.0827],\n",
      "        [0.0741],\n",
      "        [0.0464],\n",
      "        [0.0425],\n",
      "        [0.0396],\n",
      "        [0.0036],\n",
      "        [0.0221],\n",
      "        [0.0454],\n",
      "        [0.0256],\n",
      "        [0.0350],\n",
      "        [0.0337],\n",
      "        [0.0418],\n",
      "        [0.0922],\n",
      "        [0.0784],\n",
      "        [0.0540],\n",
      "        [0.0809],\n",
      "        [0.0821],\n",
      "        [0.0202],\n",
      "        [0.0773],\n",
      "        [0.0400],\n",
      "        [0.0197],\n",
      "        [0.0738],\n",
      "        [0.0515],\n",
      "        [0.0508],\n",
      "        [0.0378],\n",
      "        [0.0311],\n",
      "        [0.0340],\n",
      "        [0.0297],\n",
      "        [0.0299],\n",
      "        [0.0633],\n",
      "        [0.0148],\n",
      "        [0.0435],\n",
      "        [0.0006],\n",
      "        [0.0693],\n",
      "        [0.0080],\n",
      "        [0.0096],\n",
      "        [0.0146],\n",
      "        [0.0198],\n",
      "        [0.0273],\n",
      "        [0.1042],\n",
      "        [0.0319],\n",
      "        [0.0463],\n",
      "        [0.0663],\n",
      "        [0.0693],\n",
      "        [0.0311],\n",
      "        [0.0895],\n",
      "        [0.0804],\n",
      "        [0.0519],\n",
      "        [0.0744],\n",
      "        [0.0715],\n",
      "        [0.0691],\n",
      "        [0.0892],\n",
      "        [0.0864],\n",
      "        [0.0839],\n",
      "        [0.0866],\n",
      "        [0.1046],\n",
      "        [0.0846],\n",
      "        [0.0843],\n",
      "        [0.0871],\n",
      "        [0.1006],\n",
      "        [0.1161],\n",
      "        [0.1727],\n",
      "        [0.0095],\n",
      "        [0.0317],\n",
      "        [0.0206],\n",
      "        [0.0607],\n",
      "        [0.0625],\n",
      "        [0.1111],\n",
      "        [0.0914],\n",
      "        [0.1538]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 14.55471134185791\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 74\n",
      "剩餘X 資料 torch.Size([33, 18])\n",
      "剩餘Y 資料 torch.Size([33, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.024439232423901558, 6)\n",
      "The second_loss value of k: (0.02663111500442028, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.7586])\n",
      "目前模型的Data狀態 torch.Size([74, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8912],\n",
      "        [0.8916],\n",
      "        [0.8894],\n",
      "        [0.8867],\n",
      "        [0.8877],\n",
      "        [0.8886],\n",
      "        [0.8872],\n",
      "        [0.8894],\n",
      "        [0.8925],\n",
      "        [0.8920],\n",
      "        [0.8913],\n",
      "        [0.8903],\n",
      "        [0.8884],\n",
      "        [0.8885],\n",
      "        [0.8873],\n",
      "        [0.8851],\n",
      "        [0.8850],\n",
      "        [0.8855],\n",
      "        [0.8845],\n",
      "        [0.8946],\n",
      "        [0.8837],\n",
      "        [0.8815],\n",
      "        [0.8826],\n",
      "        [0.8862],\n",
      "        [0.8832],\n",
      "        [0.8810],\n",
      "        [0.8805],\n",
      "        [0.8811],\n",
      "        [0.8773],\n",
      "        [0.8832],\n",
      "        [0.8792],\n",
      "        [0.8823],\n",
      "        [0.8833],\n",
      "        [0.8822],\n",
      "        [0.8835],\n",
      "        [0.8828],\n",
      "        [0.8838],\n",
      "        [0.8812],\n",
      "        [0.8830],\n",
      "        [0.8832],\n",
      "        [0.8820],\n",
      "        [0.8823],\n",
      "        [0.8952],\n",
      "        [0.8880],\n",
      "        [0.8891],\n",
      "        [0.8890],\n",
      "        [0.8901],\n",
      "        [0.8892],\n",
      "        [0.8926],\n",
      "        [0.8944],\n",
      "        [0.8919],\n",
      "        [0.8929],\n",
      "        [0.8807],\n",
      "        [0.8839],\n",
      "        [0.8941],\n",
      "        [0.8936],\n",
      "        [0.8830],\n",
      "        [0.8816],\n",
      "        [0.8927],\n",
      "        [0.8838],\n",
      "        [0.8912],\n",
      "        [0.8920],\n",
      "        [0.8922],\n",
      "        [0.8839],\n",
      "        [0.8806],\n",
      "        [0.8928],\n",
      "        [0.8933],\n",
      "        [0.8950],\n",
      "        [0.8964],\n",
      "        [0.8980],\n",
      "        [0.9047],\n",
      "        [0.9081],\n",
      "        [0.9144],\n",
      "        [0.9149]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0070],\n",
      "        [0.0367],\n",
      "        [0.0459],\n",
      "        [0.0827],\n",
      "        [0.0741],\n",
      "        [0.0464],\n",
      "        [0.0425],\n",
      "        [0.0396],\n",
      "        [0.0036],\n",
      "        [0.0221],\n",
      "        [0.0454],\n",
      "        [0.0256],\n",
      "        [0.0350],\n",
      "        [0.0337],\n",
      "        [0.0418],\n",
      "        [0.0922],\n",
      "        [0.0784],\n",
      "        [0.0540],\n",
      "        [0.0809],\n",
      "        [0.0821],\n",
      "        [0.0202],\n",
      "        [0.0773],\n",
      "        [0.0400],\n",
      "        [0.0197],\n",
      "        [0.0738],\n",
      "        [0.0515],\n",
      "        [0.0508],\n",
      "        [0.0378],\n",
      "        [0.0311],\n",
      "        [0.0340],\n",
      "        [0.0297],\n",
      "        [0.0299],\n",
      "        [0.0633],\n",
      "        [0.0148],\n",
      "        [0.0435],\n",
      "        [0.0006],\n",
      "        [0.0693],\n",
      "        [0.0080],\n",
      "        [0.0096],\n",
      "        [0.0146],\n",
      "        [0.0198],\n",
      "        [0.0273],\n",
      "        [0.1042],\n",
      "        [0.0319],\n",
      "        [0.0463],\n",
      "        [0.0663],\n",
      "        [0.0693],\n",
      "        [0.0311],\n",
      "        [0.0895],\n",
      "        [0.0804],\n",
      "        [0.0519],\n",
      "        [0.0744],\n",
      "        [0.0715],\n",
      "        [0.0691],\n",
      "        [0.0892],\n",
      "        [0.0864],\n",
      "        [0.0839],\n",
      "        [0.0866],\n",
      "        [0.1046],\n",
      "        [0.0846],\n",
      "        [0.0843],\n",
      "        [0.0871],\n",
      "        [0.1006],\n",
      "        [0.1161],\n",
      "        [0.1727],\n",
      "        [0.0095],\n",
      "        [0.0317],\n",
      "        [0.0206],\n",
      "        [0.0607],\n",
      "        [0.0625],\n",
      "        [0.1111],\n",
      "        [0.0914],\n",
      "        [0.1538],\n",
      "        [0.1563]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0122],\n",
      "        [0.0424],\n",
      "        [0.0425],\n",
      "        [0.0821],\n",
      "        [0.0725],\n",
      "        [0.0439],\n",
      "        [0.0414],\n",
      "        [0.0430],\n",
      "        [0.0030],\n",
      "        [0.0282],\n",
      "        [0.0507],\n",
      "        [0.0299],\n",
      "        [0.0327],\n",
      "        [0.0313],\n",
      "        [0.0406],\n",
      "        [0.0933],\n",
      "        [0.0796],\n",
      "        [0.0546],\n",
      "        [0.0825],\n",
      "        [0.0909],\n",
      "        [0.0227],\n",
      "        [0.0820],\n",
      "        [0.0437],\n",
      "        [0.0198],\n",
      "        [0.0768],\n",
      "        [0.0567],\n",
      "        [0.0566],\n",
      "        [0.0430],\n",
      "        [0.0401],\n",
      "        [0.0370],\n",
      "        [0.0367],\n",
      "        [0.0338],\n",
      "        [0.0662],\n",
      "        [0.0188],\n",
      "        [0.0462],\n",
      "        [0.0027],\n",
      "        [0.0717],\n",
      "        [0.0030],\n",
      "        [0.0064],\n",
      "        [0.0116],\n",
      "        [0.0156],\n",
      "        [0.0234],\n",
      "        [0.1136],\n",
      "        [0.0339],\n",
      "        [0.0494],\n",
      "        [0.0692],\n",
      "        [0.0734],\n",
      "        [0.0343],\n",
      "        [0.0962],\n",
      "        [0.0889],\n",
      "        [0.0579],\n",
      "        [0.0814],\n",
      "        [0.0658],\n",
      "        [0.0668],\n",
      "        [0.0975],\n",
      "        [0.0942],\n",
      "        [0.0807],\n",
      "        [0.0819],\n",
      "        [0.1114],\n",
      "        [0.0823],\n",
      "        [0.0896],\n",
      "        [0.0931],\n",
      "        [0.1068],\n",
      "        [0.1138],\n",
      "        [0.1784],\n",
      "        [0.0026],\n",
      "        [0.0242],\n",
      "        [0.0115],\n",
      "        [0.0501],\n",
      "        [0.0502],\n",
      "        [0.0919],\n",
      "        [0.0688],\n",
      "        [0.1246],\n",
      "        [0.1266]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 14.79326343536377\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 75\n",
      "剩餘X 資料 torch.Size([32, 18])\n",
      "剩餘Y 資料 torch.Size([32, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.01928403228521347, 5)\n",
      "The second_loss value of k: (0.019383186474442482, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引5，y= tensor([0.7463])\n",
      "目前模型的Data狀態 torch.Size([75, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8859],\n",
      "        [0.8859],\n",
      "        [0.8860],\n",
      "        [0.8861],\n",
      "        [0.8861],\n",
      "        [0.8860],\n",
      "        [0.8861],\n",
      "        [0.8860],\n",
      "        [0.8859],\n",
      "        [0.8859],\n",
      "        [0.8859],\n",
      "        [0.8860],\n",
      "        [0.8860],\n",
      "        [0.8860],\n",
      "        [0.8861],\n",
      "        [0.8861],\n",
      "        [0.8862],\n",
      "        [0.8861],\n",
      "        [0.8862],\n",
      "        [0.8858],\n",
      "        [0.8862],\n",
      "        [0.8863],\n",
      "        [0.8862],\n",
      "        [0.8861],\n",
      "        [0.8862],\n",
      "        [0.8863],\n",
      "        [0.8863],\n",
      "        [0.8863],\n",
      "        [0.8864],\n",
      "        [0.8862],\n",
      "        [0.8863],\n",
      "        [0.8862],\n",
      "        [0.8862],\n",
      "        [0.8862],\n",
      "        [0.8862],\n",
      "        [0.8862],\n",
      "        [0.8862],\n",
      "        [0.8863],\n",
      "        [0.8862],\n",
      "        [0.8862],\n",
      "        [0.8862],\n",
      "        [0.8862],\n",
      "        [0.8858],\n",
      "        [0.8861],\n",
      "        [0.8860],\n",
      "        [0.8860],\n",
      "        [0.8860],\n",
      "        [0.8860],\n",
      "        [0.8859],\n",
      "        [0.8858],\n",
      "        [0.8859],\n",
      "        [0.8859],\n",
      "        [0.8863],\n",
      "        [0.8862],\n",
      "        [0.8859],\n",
      "        [0.8859],\n",
      "        [0.8862],\n",
      "        [0.8863],\n",
      "        [0.8859],\n",
      "        [0.8862],\n",
      "        [0.8859],\n",
      "        [0.8859],\n",
      "        [0.8859],\n",
      "        [0.8862],\n",
      "        [0.8863],\n",
      "        [0.8859],\n",
      "        [0.8859],\n",
      "        [0.8858],\n",
      "        [0.8858],\n",
      "        [0.8857],\n",
      "        [0.8855],\n",
      "        [0.8854],\n",
      "        [0.8852],\n",
      "        [0.8852],\n",
      "        [0.8852]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0122],\n",
      "        [0.0424],\n",
      "        [0.0425],\n",
      "        [0.0821],\n",
      "        [0.0725],\n",
      "        [0.0439],\n",
      "        [0.0414],\n",
      "        [0.0430],\n",
      "        [0.0030],\n",
      "        [0.0282],\n",
      "        [0.0507],\n",
      "        [0.0299],\n",
      "        [0.0327],\n",
      "        [0.0313],\n",
      "        [0.0406],\n",
      "        [0.0933],\n",
      "        [0.0796],\n",
      "        [0.0546],\n",
      "        [0.0825],\n",
      "        [0.0909],\n",
      "        [0.0227],\n",
      "        [0.0820],\n",
      "        [0.0437],\n",
      "        [0.0198],\n",
      "        [0.0768],\n",
      "        [0.0567],\n",
      "        [0.0566],\n",
      "        [0.0430],\n",
      "        [0.0401],\n",
      "        [0.0370],\n",
      "        [0.0367],\n",
      "        [0.0338],\n",
      "        [0.0662],\n",
      "        [0.0188],\n",
      "        [0.0462],\n",
      "        [0.0027],\n",
      "        [0.0717],\n",
      "        [0.0030],\n",
      "        [0.0064],\n",
      "        [0.0116],\n",
      "        [0.0156],\n",
      "        [0.0234],\n",
      "        [0.1136],\n",
      "        [0.0339],\n",
      "        [0.0494],\n",
      "        [0.0692],\n",
      "        [0.0734],\n",
      "        [0.0343],\n",
      "        [0.0962],\n",
      "        [0.0889],\n",
      "        [0.0579],\n",
      "        [0.0814],\n",
      "        [0.0658],\n",
      "        [0.0668],\n",
      "        [0.0975],\n",
      "        [0.0942],\n",
      "        [0.0807],\n",
      "        [0.0819],\n",
      "        [0.1114],\n",
      "        [0.0823],\n",
      "        [0.0896],\n",
      "        [0.0931],\n",
      "        [0.1068],\n",
      "        [0.1138],\n",
      "        [0.1784],\n",
      "        [0.0026],\n",
      "        [0.0242],\n",
      "        [0.0115],\n",
      "        [0.0501],\n",
      "        [0.0502],\n",
      "        [0.0919],\n",
      "        [0.0688],\n",
      "        [0.1246],\n",
      "        [0.1266],\n",
      "        [0.1389]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0152],\n",
      "        [0.0457],\n",
      "        [0.0411],\n",
      "        [0.0831],\n",
      "        [0.0725],\n",
      "        [0.0432],\n",
      "        [0.0418],\n",
      "        [0.0444],\n",
      "        [0.0072],\n",
      "        [0.0319],\n",
      "        [0.0538],\n",
      "        [0.0322],\n",
      "        [0.0321],\n",
      "        [0.0306],\n",
      "        [0.0410],\n",
      "        [0.0955],\n",
      "        [0.0819],\n",
      "        [0.0564],\n",
      "        [0.0852],\n",
      "        [0.0968],\n",
      "        [0.0260],\n",
      "        [0.0873],\n",
      "        [0.0481],\n",
      "        [0.0185],\n",
      "        [0.0806],\n",
      "        [0.0625],\n",
      "        [0.0629],\n",
      "        [0.0488],\n",
      "        [0.0491],\n",
      "        [0.0408],\n",
      "        [0.0440],\n",
      "        [0.0385],\n",
      "        [0.0700],\n",
      "        [0.0236],\n",
      "        [0.0497],\n",
      "        [0.0070],\n",
      "        [0.0750],\n",
      "        [0.0027],\n",
      "        [0.0022],\n",
      "        [0.0078],\n",
      "        [0.0106],\n",
      "        [0.0187],\n",
      "        [0.1202],\n",
      "        [0.0343],\n",
      "        [0.0508],\n",
      "        [0.0704],\n",
      "        [0.0755],\n",
      "        [0.0356],\n",
      "        [0.1005],\n",
      "        [0.0947],\n",
      "        [0.0614],\n",
      "        [0.0859],\n",
      "        [0.0596],\n",
      "        [0.0637],\n",
      "        [0.1030],\n",
      "        [0.0992],\n",
      "        [0.0766],\n",
      "        [0.0766],\n",
      "        [0.1156],\n",
      "        [0.0790],\n",
      "        [0.0925],\n",
      "        [0.0967],\n",
      "        [0.1107],\n",
      "        [0.1106],\n",
      "        [0.1847],\n",
      "        [0.0019],\n",
      "        [0.0193],\n",
      "        [0.0051],\n",
      "        [0.0425],\n",
      "        [0.0411],\n",
      "        [0.0768],\n",
      "        [0.0508],\n",
      "        [0.1009],\n",
      "        [0.1025],\n",
      "        [0.1142]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.0284264087677\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 76\n",
      "剩餘X 資料 torch.Size([31, 18])\n",
      "剩餘Y 資料 torch.Size([31, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.014277695678174496, 4)\n",
      "The second_loss value of k: (0.01429948303848505, 15)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([0.7455])\n",
      "目前模型的Data狀態 torch.Size([76, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8830],\n",
      "        [0.8826],\n",
      "        [0.8846],\n",
      "        [0.8870],\n",
      "        [0.8861],\n",
      "        [0.8853],\n",
      "        [0.8865],\n",
      "        [0.8845],\n",
      "        [0.8817],\n",
      "        [0.8822],\n",
      "        [0.8828],\n",
      "        [0.8837],\n",
      "        [0.8854],\n",
      "        [0.8854],\n",
      "        [0.8864],\n",
      "        [0.8884],\n",
      "        [0.8884],\n",
      "        [0.8879],\n",
      "        [0.8889],\n",
      "        [0.8799],\n",
      "        [0.8896],\n",
      "        [0.8915],\n",
      "        [0.8906],\n",
      "        [0.8874],\n",
      "        [0.8900],\n",
      "        [0.8920],\n",
      "        [0.8926],\n",
      "        [0.8921],\n",
      "        [0.8954],\n",
      "        [0.8900],\n",
      "        [0.8936],\n",
      "        [0.8909],\n",
      "        [0.8899],\n",
      "        [0.8910],\n",
      "        [0.8897],\n",
      "        [0.8904],\n",
      "        [0.8895],\n",
      "        [0.8919],\n",
      "        [0.8903],\n",
      "        [0.8901],\n",
      "        [0.8912],\n",
      "        [0.8909],\n",
      "        [0.8793],\n",
      "        [0.8857],\n",
      "        [0.8847],\n",
      "        [0.8848],\n",
      "        [0.8838],\n",
      "        [0.8847],\n",
      "        [0.8816],\n",
      "        [0.8800],\n",
      "        [0.8824],\n",
      "        [0.8814],\n",
      "        [0.8925],\n",
      "        [0.8893],\n",
      "        [0.8803],\n",
      "        [0.8808],\n",
      "        [0.8903],\n",
      "        [0.8916],\n",
      "        [0.8816],\n",
      "        [0.8895],\n",
      "        [0.8830],\n",
      "        [0.8823],\n",
      "        [0.8821],\n",
      "        [0.8894],\n",
      "        [0.8926],\n",
      "        [0.8814],\n",
      "        [0.8809],\n",
      "        [0.8794],\n",
      "        [0.8781],\n",
      "        [0.8766],\n",
      "        [0.8705],\n",
      "        [0.8674],\n",
      "        [0.8615],\n",
      "        [0.8611],\n",
      "        [0.8605],\n",
      "        [0.8650]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0152],\n",
      "        [0.0457],\n",
      "        [0.0411],\n",
      "        [0.0831],\n",
      "        [0.0725],\n",
      "        [0.0432],\n",
      "        [0.0418],\n",
      "        [0.0444],\n",
      "        [0.0072],\n",
      "        [0.0319],\n",
      "        [0.0538],\n",
      "        [0.0322],\n",
      "        [0.0321],\n",
      "        [0.0306],\n",
      "        [0.0410],\n",
      "        [0.0955],\n",
      "        [0.0819],\n",
      "        [0.0564],\n",
      "        [0.0852],\n",
      "        [0.0968],\n",
      "        [0.0260],\n",
      "        [0.0873],\n",
      "        [0.0481],\n",
      "        [0.0185],\n",
      "        [0.0806],\n",
      "        [0.0625],\n",
      "        [0.0629],\n",
      "        [0.0488],\n",
      "        [0.0491],\n",
      "        [0.0408],\n",
      "        [0.0440],\n",
      "        [0.0385],\n",
      "        [0.0700],\n",
      "        [0.0236],\n",
      "        [0.0497],\n",
      "        [0.0070],\n",
      "        [0.0750],\n",
      "        [0.0027],\n",
      "        [0.0022],\n",
      "        [0.0078],\n",
      "        [0.0106],\n",
      "        [0.0187],\n",
      "        [0.1202],\n",
      "        [0.0343],\n",
      "        [0.0508],\n",
      "        [0.0704],\n",
      "        [0.0755],\n",
      "        [0.0356],\n",
      "        [0.1005],\n",
      "        [0.0947],\n",
      "        [0.0614],\n",
      "        [0.0859],\n",
      "        [0.0596],\n",
      "        [0.0637],\n",
      "        [0.1030],\n",
      "        [0.0992],\n",
      "        [0.0766],\n",
      "        [0.0766],\n",
      "        [0.1156],\n",
      "        [0.0790],\n",
      "        [0.0925],\n",
      "        [0.0967],\n",
      "        [0.1107],\n",
      "        [0.1106],\n",
      "        [0.1847],\n",
      "        [0.0019],\n",
      "        [0.0193],\n",
      "        [0.0051],\n",
      "        [0.0425],\n",
      "        [0.0411],\n",
      "        [0.0768],\n",
      "        [0.0508],\n",
      "        [0.1009],\n",
      "        [0.1025],\n",
      "        [0.1142],\n",
      "        [0.1195]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0500],\n",
      "        [0.0383],\n",
      "        [0.0820],\n",
      "        [0.0708],\n",
      "        [0.0408],\n",
      "        [0.0402],\n",
      "        [0.0476],\n",
      "        [0.0121],\n",
      "        [0.0365],\n",
      "        [0.0581],\n",
      "        [0.0359],\n",
      "        [0.0298],\n",
      "        [0.0283],\n",
      "        [0.0394],\n",
      "        [0.0952],\n",
      "        [0.0815],\n",
      "        [0.0555],\n",
      "        [0.0850],\n",
      "        [0.1031],\n",
      "        [0.0263],\n",
      "        [0.0890],\n",
      "        [0.0490],\n",
      "        [0.0196],\n",
      "        [0.0812],\n",
      "        [0.0647],\n",
      "        [0.0659],\n",
      "        [0.0515],\n",
      "        [0.0531],\n",
      "        [0.0415],\n",
      "        [0.0475],\n",
      "        [0.0399],\n",
      "        [0.0704],\n",
      "        [0.0254],\n",
      "        [0.0498],\n",
      "        [0.0082],\n",
      "        [0.0751],\n",
      "        [0.0049],\n",
      "        [0.0009],\n",
      "        [0.0069],\n",
      "        [0.0083],\n",
      "        [0.0168],\n",
      "        [0.1271],\n",
      "        [0.0367],\n",
      "        [0.0540],\n",
      "        [0.0735],\n",
      "        [0.0794],\n",
      "        [0.0388],\n",
      "        [0.1060],\n",
      "        [0.1013],\n",
      "        [0.0657],\n",
      "        [0.0909],\n",
      "        [0.0563],\n",
      "        [0.0637],\n",
      "        [0.1088],\n",
      "        [0.1046],\n",
      "        [0.0751],\n",
      "        [0.0743],\n",
      "        [0.1205],\n",
      "        [0.0785],\n",
      "        [0.0961],\n",
      "        [0.1010],\n",
      "        [0.1151],\n",
      "        [0.1104],\n",
      "        [0.1880],\n",
      "        [0.0075],\n",
      "        [0.0134],\n",
      "        [0.0020],\n",
      "        [0.0341],\n",
      "        [0.0314],\n",
      "        [0.0621],\n",
      "        [0.0336],\n",
      "        [0.0784],\n",
      "        [0.0797],\n",
      "        [0.0909],\n",
      "        [0.0997]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.264198780059814\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 77\n",
      "剩餘X 資料 torch.Size([30, 18])\n",
      "剩餘Y 資料 torch.Size([30, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008454188704490662, 14)\n",
      "The second_loss value of k: (0.008709714747965336, 15)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引14，y= tensor([0.7355])\n",
      "目前模型的Data狀態 torch.Size([77, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8791],\n",
      "        [0.8783],\n",
      "        [0.8818],\n",
      "        [0.8860],\n",
      "        [0.8844],\n",
      "        [0.8829],\n",
      "        [0.8849],\n",
      "        [0.8813],\n",
      "        [0.8769],\n",
      "        [0.8776],\n",
      "        [0.8786],\n",
      "        [0.8801],\n",
      "        [0.8831],\n",
      "        [0.8830],\n",
      "        [0.8848],\n",
      "        [0.8881],\n",
      "        [0.8880],\n",
      "        [0.8871],\n",
      "        [0.8886],\n",
      "        [0.8736],\n",
      "        [0.8898],\n",
      "        [0.8933],\n",
      "        [0.8915],\n",
      "        [0.8864],\n",
      "        [0.8906],\n",
      "        [0.8942],\n",
      "        [0.8956],\n",
      "        [0.8948],\n",
      "        [0.8994],\n",
      "        [0.8907],\n",
      "        [0.8971],\n",
      "        [0.8923],\n",
      "        [0.8904],\n",
      "        [0.8928],\n",
      "        [0.8898],\n",
      "        [0.8917],\n",
      "        [0.8895],\n",
      "        [0.8941],\n",
      "        [0.8917],\n",
      "        [0.8909],\n",
      "        [0.8936],\n",
      "        [0.8928],\n",
      "        [0.8723],\n",
      "        [0.8833],\n",
      "        [0.8815],\n",
      "        [0.8818],\n",
      "        [0.8800],\n",
      "        [0.8815],\n",
      "        [0.8762],\n",
      "        [0.8735],\n",
      "        [0.8781],\n",
      "        [0.8764],\n",
      "        [0.8959],\n",
      "        [0.8893],\n",
      "        [0.8745],\n",
      "        [0.8754],\n",
      "        [0.8919],\n",
      "        [0.8939],\n",
      "        [0.8767],\n",
      "        [0.8899],\n",
      "        [0.8794],\n",
      "        [0.8781],\n",
      "        [0.8777],\n",
      "        [0.8896],\n",
      "        [0.8960],\n",
      "        [0.8758],\n",
      "        [0.8751],\n",
      "        [0.8723],\n",
      "        [0.8698],\n",
      "        [0.8669],\n",
      "        [0.8557],\n",
      "        [0.8502],\n",
      "        [0.8389],\n",
      "        [0.8383],\n",
      "        [0.8372],\n",
      "        [0.8452],\n",
      "        [0.8274]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0191],\n",
      "        [0.0500],\n",
      "        [0.0383],\n",
      "        [0.0820],\n",
      "        [0.0708],\n",
      "        [0.0408],\n",
      "        [0.0402],\n",
      "        [0.0476],\n",
      "        [0.0121],\n",
      "        [0.0365],\n",
      "        [0.0581],\n",
      "        [0.0359],\n",
      "        [0.0298],\n",
      "        [0.0283],\n",
      "        [0.0394],\n",
      "        [0.0952],\n",
      "        [0.0815],\n",
      "        [0.0555],\n",
      "        [0.0850],\n",
      "        [0.1031],\n",
      "        [0.0263],\n",
      "        [0.0890],\n",
      "        [0.0490],\n",
      "        [0.0196],\n",
      "        [0.0812],\n",
      "        [0.0647],\n",
      "        [0.0659],\n",
      "        [0.0515],\n",
      "        [0.0531],\n",
      "        [0.0415],\n",
      "        [0.0475],\n",
      "        [0.0399],\n",
      "        [0.0704],\n",
      "        [0.0254],\n",
      "        [0.0498],\n",
      "        [0.0082],\n",
      "        [0.0751],\n",
      "        [0.0049],\n",
      "        [0.0009],\n",
      "        [0.0069],\n",
      "        [0.0083],\n",
      "        [0.0168],\n",
      "        [0.1271],\n",
      "        [0.0367],\n",
      "        [0.0540],\n",
      "        [0.0735],\n",
      "        [0.0794],\n",
      "        [0.0388],\n",
      "        [0.1060],\n",
      "        [0.1013],\n",
      "        [0.0657],\n",
      "        [0.0909],\n",
      "        [0.0563],\n",
      "        [0.0637],\n",
      "        [0.1088],\n",
      "        [0.1046],\n",
      "        [0.0751],\n",
      "        [0.0743],\n",
      "        [0.1205],\n",
      "        [0.0785],\n",
      "        [0.0961],\n",
      "        [0.1010],\n",
      "        [0.1151],\n",
      "        [0.1104],\n",
      "        [0.1880],\n",
      "        [0.0075],\n",
      "        [0.0134],\n",
      "        [0.0020],\n",
      "        [0.0341],\n",
      "        [0.0314],\n",
      "        [0.0621],\n",
      "        [0.0336],\n",
      "        [0.0784],\n",
      "        [0.0797],\n",
      "        [0.0909],\n",
      "        [0.0997],\n",
      "        [0.0919]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0054],\n",
      "        [0.0355],\n",
      "        [0.0493],\n",
      "        [0.0888],\n",
      "        [0.0792],\n",
      "        [0.0506],\n",
      "        [0.0481],\n",
      "        [0.0362],\n",
      "        [0.0038],\n",
      "        [0.0213],\n",
      "        [0.0439],\n",
      "        [0.0231],\n",
      "        [0.0394],\n",
      "        [0.0380],\n",
      "        [0.0473],\n",
      "        [0.0999],\n",
      "        [0.0862],\n",
      "        [0.0613],\n",
      "        [0.0891],\n",
      "        [0.0839],\n",
      "        [0.0293],\n",
      "        [0.0885],\n",
      "        [0.0502],\n",
      "        [0.0131],\n",
      "        [0.0833],\n",
      "        [0.0633],\n",
      "        [0.0631],\n",
      "        [0.0495],\n",
      "        [0.0465],\n",
      "        [0.0436],\n",
      "        [0.0432],\n",
      "        [0.0404],\n",
      "        [0.0728],\n",
      "        [0.0254],\n",
      "        [0.0528],\n",
      "        [0.0093],\n",
      "        [0.0783],\n",
      "        [0.0036],\n",
      "        [0.0002],\n",
      "        [0.0051],\n",
      "        [0.0091],\n",
      "        [0.0168],\n",
      "        [0.1074],\n",
      "        [0.0272],\n",
      "        [0.0427],\n",
      "        [0.0625],\n",
      "        [0.0666],\n",
      "        [0.0275],\n",
      "        [0.0893],\n",
      "        [0.0820],\n",
      "        [0.0510],\n",
      "        [0.0745],\n",
      "        [0.0594],\n",
      "        [0.0602],\n",
      "        [0.0906],\n",
      "        [0.0872],\n",
      "        [0.0742],\n",
      "        [0.0754],\n",
      "        [0.1045],\n",
      "        [0.0757],\n",
      "        [0.0827],\n",
      "        [0.0863],\n",
      "        [0.1000],\n",
      "        [0.1072],\n",
      "        [0.1849],\n",
      "        [0.0095],\n",
      "        [0.0311],\n",
      "        [0.0146],\n",
      "        [0.0414],\n",
      "        [0.0289],\n",
      "        [0.0297],\n",
      "        [0.0121],\n",
      "        [0.0059],\n",
      "        [0.0030],\n",
      "        [0.0038],\n",
      "        [0.0299],\n",
      "        [0.0206]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.499439001083374\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 78\n",
      "剩餘X 資料 torch.Size([29, 18])\n",
      "剩餘Y 資料 torch.Size([29, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (4.0811984945321456e-05, 13)\n",
      "The second_loss value of k: (0.00017524340364616364, 15)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引13，y= tensor([0.7168])\n",
      "目前模型的Data狀態 torch.Size([78, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8920],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8928],\n",
      "        [0.8889],\n",
      "        [0.8771],\n",
      "        [0.8644],\n",
      "        [0.8233],\n",
      "        [0.8046],\n",
      "        [0.7547],\n",
      "        [0.7556],\n",
      "        [0.7501],\n",
      "        [0.7755],\n",
      "        [0.7149],\n",
      "        [0.7104]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0054],\n",
      "        [0.0355],\n",
      "        [0.0493],\n",
      "        [0.0888],\n",
      "        [0.0792],\n",
      "        [0.0506],\n",
      "        [0.0481],\n",
      "        [0.0362],\n",
      "        [0.0038],\n",
      "        [0.0213],\n",
      "        [0.0439],\n",
      "        [0.0231],\n",
      "        [0.0394],\n",
      "        [0.0380],\n",
      "        [0.0473],\n",
      "        [0.0999],\n",
      "        [0.0862],\n",
      "        [0.0613],\n",
      "        [0.0891],\n",
      "        [0.0839],\n",
      "        [0.0293],\n",
      "        [0.0885],\n",
      "        [0.0502],\n",
      "        [0.0131],\n",
      "        [0.0833],\n",
      "        [0.0633],\n",
      "        [0.0631],\n",
      "        [0.0495],\n",
      "        [0.0465],\n",
      "        [0.0436],\n",
      "        [0.0432],\n",
      "        [0.0404],\n",
      "        [0.0728],\n",
      "        [0.0254],\n",
      "        [0.0528],\n",
      "        [0.0093],\n",
      "        [0.0783],\n",
      "        [0.0036],\n",
      "        [0.0002],\n",
      "        [0.0051],\n",
      "        [0.0091],\n",
      "        [0.0168],\n",
      "        [0.1074],\n",
      "        [0.0272],\n",
      "        [0.0427],\n",
      "        [0.0625],\n",
      "        [0.0666],\n",
      "        [0.0275],\n",
      "        [0.0893],\n",
      "        [0.0820],\n",
      "        [0.0510],\n",
      "        [0.0745],\n",
      "        [0.0594],\n",
      "        [0.0602],\n",
      "        [0.0906],\n",
      "        [0.0872],\n",
      "        [0.0742],\n",
      "        [0.0754],\n",
      "        [0.1045],\n",
      "        [0.0757],\n",
      "        [0.0827],\n",
      "        [0.0863],\n",
      "        [0.1000],\n",
      "        [0.1072],\n",
      "        [0.1849],\n",
      "        [0.0095],\n",
      "        [0.0311],\n",
      "        [0.0146],\n",
      "        [0.0414],\n",
      "        [0.0289],\n",
      "        [0.0297],\n",
      "        [0.0121],\n",
      "        [0.0059],\n",
      "        [0.0030],\n",
      "        [0.0038],\n",
      "        [0.0299],\n",
      "        [0.0206],\n",
      "        [0.0064]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 72\n",
      "Number of shrink: 28\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0217],\n",
      "        [    0.0442],\n",
      "        [    0.0235],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0400],\n",
      "        [    0.0725],\n",
      "        [    0.0250],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1075],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0148],\n",
      "        [    0.0416],\n",
      "        [    0.0290],\n",
      "        [    0.0296],\n",
      "        [    0.0122],\n",
      "        [    0.0062],\n",
      "        [    0.0033],\n",
      "        [    0.0035],\n",
      "        [    0.0297],\n",
      "        [    0.0210],\n",
      "        [    0.0068]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.736706256866455\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 79\n",
      "剩餘X 資料 torch.Size([28, 18])\n",
      "剩餘Y 資料 torch.Size([28, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0001647149329073727, 14)\n",
      "The second_loss value of k: (0.0004023702349513769, 13)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引14，y= tensor([0.7118])\n",
      "目前模型的Data狀態 torch.Size([79, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8924],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8892],\n",
      "        [0.8773],\n",
      "        [0.8645],\n",
      "        [0.8233],\n",
      "        [0.8045],\n",
      "        [0.7544],\n",
      "        [0.7553],\n",
      "        [0.7498],\n",
      "        [0.7752],\n",
      "        [0.7145],\n",
      "        [0.7099],\n",
      "        [0.7246]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0217],\n",
      "        [    0.0442],\n",
      "        [    0.0235],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0400],\n",
      "        [    0.0725],\n",
      "        [    0.0250],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1075],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0148],\n",
      "        [    0.0416],\n",
      "        [    0.0290],\n",
      "        [    0.0296],\n",
      "        [    0.0122],\n",
      "        [    0.0062],\n",
      "        [    0.0033],\n",
      "        [    0.0035],\n",
      "        [    0.0297],\n",
      "        [    0.0210],\n",
      "        [    0.0068],\n",
      "        [    0.0128]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 70\n",
      "Number of shrink: 30\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0217],\n",
      "        [    0.0442],\n",
      "        [    0.0235],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0843],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0432],\n",
      "        [    0.0429],\n",
      "        [    0.0400],\n",
      "        [    0.0725],\n",
      "        [    0.0250],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0172],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0606],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1076],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0147],\n",
      "        [    0.0414],\n",
      "        [    0.0287],\n",
      "        [    0.0289],\n",
      "        [    0.0131],\n",
      "        [    0.0076],\n",
      "        [    0.0046],\n",
      "        [    0.0021],\n",
      "        [    0.0285],\n",
      "        [    0.0227],\n",
      "        [    0.0086],\n",
      "        [    0.0112]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 15.978827476501465\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 80\n",
      "剩餘X 資料 torch.Size([27, 18])\n",
      "剩餘Y 資料 torch.Size([27, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00037210984737612307, 17)\n",
      "The second_loss value of k: (0.0004754341207444668, 13)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.7161])\n",
      "目前模型的Data狀態 torch.Size([80, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8891],\n",
      "        [0.8771],\n",
      "        [0.8642],\n",
      "        [0.8225],\n",
      "        [0.8035],\n",
      "        [0.7530],\n",
      "        [0.7540],\n",
      "        [0.7484],\n",
      "        [0.7740],\n",
      "        [0.7127],\n",
      "        [0.7081],\n",
      "        [0.7229],\n",
      "        [0.7354]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0217],\n",
      "        [    0.0442],\n",
      "        [    0.0235],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0843],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0432],\n",
      "        [    0.0429],\n",
      "        [    0.0400],\n",
      "        [    0.0725],\n",
      "        [    0.0250],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0172],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0606],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1076],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0147],\n",
      "        [    0.0414],\n",
      "        [    0.0287],\n",
      "        [    0.0289],\n",
      "        [    0.0131],\n",
      "        [    0.0076],\n",
      "        [    0.0046],\n",
      "        [    0.0021],\n",
      "        [    0.0285],\n",
      "        [    0.0227],\n",
      "        [    0.0086],\n",
      "        [    0.0112],\n",
      "        [    0.0193]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 62\n",
      "Number of shrink: 38\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0490],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0216],\n",
      "        [    0.0442],\n",
      "        [    0.0234],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0134],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0725],\n",
      "        [    0.0251],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1069],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0896],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1075],\n",
      "        [    0.1846],\n",
      "        [    0.0092],\n",
      "        [    0.0308],\n",
      "        [    0.0146],\n",
      "        [    0.0412],\n",
      "        [    0.0282],\n",
      "        [    0.0279],\n",
      "        [    0.0144],\n",
      "        [    0.0096],\n",
      "        [    0.0067],\n",
      "        [    0.0000],\n",
      "        [    0.0267],\n",
      "        [    0.0253],\n",
      "        [    0.0113],\n",
      "        [    0.0087],\n",
      "        [    0.0170]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 16.228487730026245\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 81\n",
      "剩餘X 資料 torch.Size([26, 18])\n",
      "剩餘Y 資料 torch.Size([26, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0004763235046993941, 4)\n",
      "The second_loss value of k: (0.0005948916077613831, 13)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引4，y= tensor([0.7218])\n",
      "目前模型的Data狀態 torch.Size([81, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8890],\n",
      "        [0.8768],\n",
      "        [0.8637],\n",
      "        [0.8215],\n",
      "        [0.8022],\n",
      "        [0.7510],\n",
      "        [0.7519],\n",
      "        [0.7463],\n",
      "        [0.7723],\n",
      "        [0.7102],\n",
      "        [0.7055],\n",
      "        [0.7205],\n",
      "        [0.7331],\n",
      "        [0.7436]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0490],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0216],\n",
      "        [    0.0442],\n",
      "        [    0.0234],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0134],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0725],\n",
      "        [    0.0251],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1069],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0896],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1075],\n",
      "        [    0.1846],\n",
      "        [    0.0092],\n",
      "        [    0.0308],\n",
      "        [    0.0146],\n",
      "        [    0.0412],\n",
      "        [    0.0282],\n",
      "        [    0.0279],\n",
      "        [    0.0144],\n",
      "        [    0.0096],\n",
      "        [    0.0067],\n",
      "        [    0.0000],\n",
      "        [    0.0267],\n",
      "        [    0.0253],\n",
      "        [    0.0113],\n",
      "        [    0.0087],\n",
      "        [    0.0170],\n",
      "        [    0.0218]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 70\n",
      "Number of shrink: 30\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0217],\n",
      "        [    0.0442],\n",
      "        [    0.0235],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0432],\n",
      "        [    0.0429],\n",
      "        [    0.0400],\n",
      "        [    0.0725],\n",
      "        [    0.0250],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1076],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0145],\n",
      "        [    0.0409],\n",
      "        [    0.0278],\n",
      "        [    0.0269],\n",
      "        [    0.0156],\n",
      "        [    0.0114],\n",
      "        [    0.0085],\n",
      "        [    0.0019],\n",
      "        [    0.0252],\n",
      "        [    0.0276],\n",
      "        [    0.0136],\n",
      "        [    0.0065],\n",
      "        [    0.0150],\n",
      "        [    0.0199]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 16.466862440109253\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 82\n",
      "剩餘X 資料 torch.Size([25, 18])\n",
      "剩餘Y 資料 torch.Size([25, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.000617733399849385, 13)\n",
      "The second_loss value of k: (0.0007130852318368852, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引13，y= tensor([0.7034])\n",
      "目前模型的Data狀態 torch.Size([82, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8889],\n",
      "        [0.8766],\n",
      "        [0.8633],\n",
      "        [0.8205],\n",
      "        [0.8010],\n",
      "        [0.7492],\n",
      "        [0.7501],\n",
      "        [0.7444],\n",
      "        [0.7707],\n",
      "        [0.7079],\n",
      "        [0.7031],\n",
      "        [0.7183],\n",
      "        [0.7311],\n",
      "        [0.7417],\n",
      "        [0.7282]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0217],\n",
      "        [    0.0442],\n",
      "        [    0.0235],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0432],\n",
      "        [    0.0429],\n",
      "        [    0.0400],\n",
      "        [    0.0725],\n",
      "        [    0.0250],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1076],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0145],\n",
      "        [    0.0409],\n",
      "        [    0.0278],\n",
      "        [    0.0269],\n",
      "        [    0.0156],\n",
      "        [    0.0114],\n",
      "        [    0.0085],\n",
      "        [    0.0019],\n",
      "        [    0.0252],\n",
      "        [    0.0276],\n",
      "        [    0.0136],\n",
      "        [    0.0065],\n",
      "        [    0.0150],\n",
      "        [    0.0199],\n",
      "        [    0.0249]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 69\n",
      "Number of shrink: 31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0056],\n",
      "        [    0.0358],\n",
      "        [    0.0490],\n",
      "        [    0.0886],\n",
      "        [    0.0790],\n",
      "        [    0.0504],\n",
      "        [    0.0478],\n",
      "        [    0.0364],\n",
      "        [    0.0036],\n",
      "        [    0.0216],\n",
      "        [    0.0441],\n",
      "        [    0.0234],\n",
      "        [    0.0392],\n",
      "        [    0.0378],\n",
      "        [    0.0471],\n",
      "        [    0.0997],\n",
      "        [    0.0860],\n",
      "        [    0.0610],\n",
      "        [    0.0889],\n",
      "        [    0.0842],\n",
      "        [    0.0290],\n",
      "        [    0.0883],\n",
      "        [    0.0500],\n",
      "        [    0.0134],\n",
      "        [    0.0831],\n",
      "        [    0.0630],\n",
      "        [    0.0629],\n",
      "        [    0.0493],\n",
      "        [    0.0463],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0726],\n",
      "        [    0.0251],\n",
      "        [    0.0525],\n",
      "        [    0.0091],\n",
      "        [    0.0781],\n",
      "        [    0.0033],\n",
      "        [    0.0000],\n",
      "        [    0.0053],\n",
      "        [    0.0093],\n",
      "        [    0.0171],\n",
      "        [    0.1069],\n",
      "        [    0.0274],\n",
      "        [    0.0429],\n",
      "        [    0.0627],\n",
      "        [    0.0668],\n",
      "        [    0.0278],\n",
      "        [    0.0896],\n",
      "        [    0.0822],\n",
      "        [    0.0513],\n",
      "        [    0.0748],\n",
      "        [    0.0596],\n",
      "        [    0.0605],\n",
      "        [    0.0908],\n",
      "        [    0.0875],\n",
      "        [    0.0744],\n",
      "        [    0.0756],\n",
      "        [    0.1047],\n",
      "        [    0.0759],\n",
      "        [    0.0830],\n",
      "        [    0.0865],\n",
      "        [    0.1002],\n",
      "        [    0.1075],\n",
      "        [    0.1846],\n",
      "        [    0.0092],\n",
      "        [    0.0309],\n",
      "        [    0.0145],\n",
      "        [    0.0407],\n",
      "        [    0.0273],\n",
      "        [    0.0257],\n",
      "        [    0.0172],\n",
      "        [    0.0138],\n",
      "        [    0.0109],\n",
      "        [    0.0044],\n",
      "        [    0.0231],\n",
      "        [    0.0307],\n",
      "        [    0.0168],\n",
      "        [    0.0036],\n",
      "        [    0.0123],\n",
      "        [    0.0174],\n",
      "        [    0.0221]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 16.704106092453003\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 83\n",
      "剩餘X 資料 torch.Size([24, 18])\n",
      "剩餘Y 資料 torch.Size([24, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0005916279624216259, 14)\n",
      "The second_loss value of k: (0.0008880611858330667, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引14，y= tensor([0.7056])\n",
      "目前模型的Data狀態 torch.Size([83, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8888],\n",
      "        [0.8763],\n",
      "        [0.8628],\n",
      "        [0.8193],\n",
      "        [0.7995],\n",
      "        [0.7468],\n",
      "        [0.7477],\n",
      "        [0.7419],\n",
      "        [0.7686],\n",
      "        [0.7048],\n",
      "        [0.7000],\n",
      "        [0.7154],\n",
      "        [0.7283],\n",
      "        [0.7391],\n",
      "        [0.7255],\n",
      "        [0.7300]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0056],\n",
      "        [    0.0358],\n",
      "        [    0.0490],\n",
      "        [    0.0886],\n",
      "        [    0.0790],\n",
      "        [    0.0504],\n",
      "        [    0.0478],\n",
      "        [    0.0364],\n",
      "        [    0.0036],\n",
      "        [    0.0216],\n",
      "        [    0.0441],\n",
      "        [    0.0234],\n",
      "        [    0.0392],\n",
      "        [    0.0378],\n",
      "        [    0.0471],\n",
      "        [    0.0997],\n",
      "        [    0.0860],\n",
      "        [    0.0610],\n",
      "        [    0.0889],\n",
      "        [    0.0842],\n",
      "        [    0.0290],\n",
      "        [    0.0883],\n",
      "        [    0.0500],\n",
      "        [    0.0134],\n",
      "        [    0.0831],\n",
      "        [    0.0630],\n",
      "        [    0.0629],\n",
      "        [    0.0493],\n",
      "        [    0.0463],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0726],\n",
      "        [    0.0251],\n",
      "        [    0.0525],\n",
      "        [    0.0091],\n",
      "        [    0.0781],\n",
      "        [    0.0033],\n",
      "        [    0.0000],\n",
      "        [    0.0053],\n",
      "        [    0.0093],\n",
      "        [    0.0171],\n",
      "        [    0.1069],\n",
      "        [    0.0274],\n",
      "        [    0.0429],\n",
      "        [    0.0627],\n",
      "        [    0.0668],\n",
      "        [    0.0278],\n",
      "        [    0.0896],\n",
      "        [    0.0822],\n",
      "        [    0.0513],\n",
      "        [    0.0748],\n",
      "        [    0.0596],\n",
      "        [    0.0605],\n",
      "        [    0.0908],\n",
      "        [    0.0875],\n",
      "        [    0.0744],\n",
      "        [    0.0756],\n",
      "        [    0.1047],\n",
      "        [    0.0759],\n",
      "        [    0.0830],\n",
      "        [    0.0865],\n",
      "        [    0.1002],\n",
      "        [    0.1075],\n",
      "        [    0.1846],\n",
      "        [    0.0092],\n",
      "        [    0.0309],\n",
      "        [    0.0145],\n",
      "        [    0.0407],\n",
      "        [    0.0273],\n",
      "        [    0.0257],\n",
      "        [    0.0172],\n",
      "        [    0.0138],\n",
      "        [    0.0109],\n",
      "        [    0.0044],\n",
      "        [    0.0231],\n",
      "        [    0.0307],\n",
      "        [    0.0168],\n",
      "        [    0.0036],\n",
      "        [    0.0123],\n",
      "        [    0.0174],\n",
      "        [    0.0221],\n",
      "        [    0.0243]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 67\n",
      "Number of shrink: 33\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0056],\n",
      "        [    0.0358],\n",
      "        [    0.0490],\n",
      "        [    0.0886],\n",
      "        [    0.0790],\n",
      "        [    0.0504],\n",
      "        [    0.0478],\n",
      "        [    0.0364],\n",
      "        [    0.0036],\n",
      "        [    0.0216],\n",
      "        [    0.0441],\n",
      "        [    0.0234],\n",
      "        [    0.0392],\n",
      "        [    0.0378],\n",
      "        [    0.0471],\n",
      "        [    0.0997],\n",
      "        [    0.0860],\n",
      "        [    0.0610],\n",
      "        [    0.0889],\n",
      "        [    0.0842],\n",
      "        [    0.0290],\n",
      "        [    0.0883],\n",
      "        [    0.0500],\n",
      "        [    0.0134],\n",
      "        [    0.0831],\n",
      "        [    0.0630],\n",
      "        [    0.0629],\n",
      "        [    0.0493],\n",
      "        [    0.0463],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0726],\n",
      "        [    0.0251],\n",
      "        [    0.0525],\n",
      "        [    0.0091],\n",
      "        [    0.0781],\n",
      "        [    0.0033],\n",
      "        [    0.0000],\n",
      "        [    0.0053],\n",
      "        [    0.0093],\n",
      "        [    0.0171],\n",
      "        [    0.1069],\n",
      "        [    0.0274],\n",
      "        [    0.0429],\n",
      "        [    0.0627],\n",
      "        [    0.0668],\n",
      "        [    0.0278],\n",
      "        [    0.0896],\n",
      "        [    0.0822],\n",
      "        [    0.0513],\n",
      "        [    0.0748],\n",
      "        [    0.0596],\n",
      "        [    0.0605],\n",
      "        [    0.0908],\n",
      "        [    0.0875],\n",
      "        [    0.0744],\n",
      "        [    0.0756],\n",
      "        [    0.1047],\n",
      "        [    0.0759],\n",
      "        [    0.0830],\n",
      "        [    0.0865],\n",
      "        [    0.1002],\n",
      "        [    0.1075],\n",
      "        [    0.1846],\n",
      "        [    0.0092],\n",
      "        [    0.0309],\n",
      "        [    0.0144],\n",
      "        [    0.0404],\n",
      "        [    0.0269],\n",
      "        [    0.0247],\n",
      "        [    0.0184],\n",
      "        [    0.0156],\n",
      "        [    0.0127],\n",
      "        [    0.0063],\n",
      "        [    0.0216],\n",
      "        [    0.0330],\n",
      "        [    0.0191],\n",
      "        [    0.0015],\n",
      "        [    0.0102],\n",
      "        [    0.0155],\n",
      "        [    0.0200],\n",
      "        [    0.0223]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 16.941256046295166\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 84\n",
      "剩餘X 資料 torch.Size([23, 18])\n",
      "剩餘Y 資料 torch.Size([23, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0010292292572557926, 12)\n",
      "The second_loss value of k: (0.0011482337722554803, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([0.7342])\n",
      "目前模型的Data狀態 torch.Size([84, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8887],\n",
      "        [0.8760],\n",
      "        [0.8624],\n",
      "        [0.8184],\n",
      "        [0.7983],\n",
      "        [0.7450],\n",
      "        [0.7459],\n",
      "        [0.7400],\n",
      "        [0.7671],\n",
      "        [0.7025],\n",
      "        [0.6976],\n",
      "        [0.7132],\n",
      "        [0.7263],\n",
      "        [0.7373],\n",
      "        [0.7234],\n",
      "        [0.7280],\n",
      "        [0.7022]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0056],\n",
      "        [    0.0358],\n",
      "        [    0.0490],\n",
      "        [    0.0886],\n",
      "        [    0.0790],\n",
      "        [    0.0504],\n",
      "        [    0.0478],\n",
      "        [    0.0364],\n",
      "        [    0.0036],\n",
      "        [    0.0216],\n",
      "        [    0.0441],\n",
      "        [    0.0234],\n",
      "        [    0.0392],\n",
      "        [    0.0378],\n",
      "        [    0.0471],\n",
      "        [    0.0997],\n",
      "        [    0.0860],\n",
      "        [    0.0610],\n",
      "        [    0.0889],\n",
      "        [    0.0842],\n",
      "        [    0.0290],\n",
      "        [    0.0883],\n",
      "        [    0.0500],\n",
      "        [    0.0134],\n",
      "        [    0.0831],\n",
      "        [    0.0630],\n",
      "        [    0.0629],\n",
      "        [    0.0493],\n",
      "        [    0.0463],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0726],\n",
      "        [    0.0251],\n",
      "        [    0.0525],\n",
      "        [    0.0091],\n",
      "        [    0.0781],\n",
      "        [    0.0033],\n",
      "        [    0.0000],\n",
      "        [    0.0053],\n",
      "        [    0.0093],\n",
      "        [    0.0171],\n",
      "        [    0.1069],\n",
      "        [    0.0274],\n",
      "        [    0.0429],\n",
      "        [    0.0627],\n",
      "        [    0.0668],\n",
      "        [    0.0278],\n",
      "        [    0.0896],\n",
      "        [    0.0822],\n",
      "        [    0.0513],\n",
      "        [    0.0748],\n",
      "        [    0.0596],\n",
      "        [    0.0605],\n",
      "        [    0.0908],\n",
      "        [    0.0875],\n",
      "        [    0.0744],\n",
      "        [    0.0756],\n",
      "        [    0.1047],\n",
      "        [    0.0759],\n",
      "        [    0.0830],\n",
      "        [    0.0865],\n",
      "        [    0.1002],\n",
      "        [    0.1075],\n",
      "        [    0.1846],\n",
      "        [    0.0092],\n",
      "        [    0.0309],\n",
      "        [    0.0144],\n",
      "        [    0.0404],\n",
      "        [    0.0269],\n",
      "        [    0.0247],\n",
      "        [    0.0184],\n",
      "        [    0.0156],\n",
      "        [    0.0127],\n",
      "        [    0.0063],\n",
      "        [    0.0216],\n",
      "        [    0.0330],\n",
      "        [    0.0191],\n",
      "        [    0.0015],\n",
      "        [    0.0102],\n",
      "        [    0.0155],\n",
      "        [    0.0200],\n",
      "        [    0.0223],\n",
      "        [    0.0321]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 70\n",
      "Number of shrink: 30\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0056],\n",
      "        [    0.0357],\n",
      "        [    0.0491],\n",
      "        [    0.0886],\n",
      "        [    0.0790],\n",
      "        [    0.0504],\n",
      "        [    0.0479],\n",
      "        [    0.0364],\n",
      "        [    0.0036],\n",
      "        [    0.0215],\n",
      "        [    0.0441],\n",
      "        [    0.0233],\n",
      "        [    0.0392],\n",
      "        [    0.0378],\n",
      "        [    0.0471],\n",
      "        [    0.0997],\n",
      "        [    0.0860],\n",
      "        [    0.0611],\n",
      "        [    0.0889],\n",
      "        [    0.0841],\n",
      "        [    0.0291],\n",
      "        [    0.0883],\n",
      "        [    0.0500],\n",
      "        [    0.0133],\n",
      "        [    0.0831],\n",
      "        [    0.0631],\n",
      "        [    0.0629],\n",
      "        [    0.0493],\n",
      "        [    0.0463],\n",
      "        [    0.0434],\n",
      "        [    0.0430],\n",
      "        [    0.0402],\n",
      "        [    0.0726],\n",
      "        [    0.0252],\n",
      "        [    0.0526],\n",
      "        [    0.0091],\n",
      "        [    0.0781],\n",
      "        [    0.0034],\n",
      "        [    0.0000],\n",
      "        [    0.0053],\n",
      "        [    0.0093],\n",
      "        [    0.0170],\n",
      "        [    0.1068],\n",
      "        [    0.0274],\n",
      "        [    0.0429],\n",
      "        [    0.0627],\n",
      "        [    0.0668],\n",
      "        [    0.0277],\n",
      "        [    0.0895],\n",
      "        [    0.0821],\n",
      "        [    0.0512],\n",
      "        [    0.0747],\n",
      "        [    0.0595],\n",
      "        [    0.0604],\n",
      "        [    0.0908],\n",
      "        [    0.0874],\n",
      "        [    0.0744],\n",
      "        [    0.0756],\n",
      "        [    0.1047],\n",
      "        [    0.0759],\n",
      "        [    0.0829],\n",
      "        [    0.0865],\n",
      "        [    0.1002],\n",
      "        [    0.1074],\n",
      "        [    0.1847],\n",
      "        [    0.0093],\n",
      "        [    0.0309],\n",
      "        [    0.0144],\n",
      "        [    0.0406],\n",
      "        [    0.0273],\n",
      "        [    0.0258],\n",
      "        [    0.0171],\n",
      "        [    0.0136],\n",
      "        [    0.0106],\n",
      "        [    0.0041],\n",
      "        [    0.0233],\n",
      "        [    0.0303],\n",
      "        [    0.0164],\n",
      "        [    0.0040],\n",
      "        [    0.0125],\n",
      "        [    0.0176],\n",
      "        [    0.0224],\n",
      "        [    0.0246],\n",
      "        [    0.0294]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 17.178491353988647\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 85\n",
      "剩餘X 資料 torch.Size([22, 18])\n",
      "剩餘Y 資料 torch.Size([22, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0012551170075312257, 3)\n",
      "The second_loss value of k: (0.0015444871969521046, 13)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.7461])\n",
      "目前模型的Data狀態 torch.Size([85, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8926],\n",
      "        [0.8888],\n",
      "        [0.8763],\n",
      "        [0.8628],\n",
      "        [0.8194],\n",
      "        [0.7996],\n",
      "        [0.7470],\n",
      "        [0.7480],\n",
      "        [0.7421],\n",
      "        [0.7688],\n",
      "        [0.7051],\n",
      "        [0.7003],\n",
      "        [0.7157],\n",
      "        [0.7286],\n",
      "        [0.7394],\n",
      "        [0.7258],\n",
      "        [0.7302],\n",
      "        [0.7048],\n",
      "        [0.7816]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0056],\n",
      "        [    0.0357],\n",
      "        [    0.0491],\n",
      "        [    0.0886],\n",
      "        [    0.0790],\n",
      "        [    0.0504],\n",
      "        [    0.0479],\n",
      "        [    0.0364],\n",
      "        [    0.0036],\n",
      "        [    0.0215],\n",
      "        [    0.0441],\n",
      "        [    0.0233],\n",
      "        [    0.0392],\n",
      "        [    0.0378],\n",
      "        [    0.0471],\n",
      "        [    0.0997],\n",
      "        [    0.0860],\n",
      "        [    0.0611],\n",
      "        [    0.0889],\n",
      "        [    0.0841],\n",
      "        [    0.0291],\n",
      "        [    0.0883],\n",
      "        [    0.0500],\n",
      "        [    0.0133],\n",
      "        [    0.0831],\n",
      "        [    0.0631],\n",
      "        [    0.0629],\n",
      "        [    0.0493],\n",
      "        [    0.0463],\n",
      "        [    0.0434],\n",
      "        [    0.0430],\n",
      "        [    0.0402],\n",
      "        [    0.0726],\n",
      "        [    0.0252],\n",
      "        [    0.0526],\n",
      "        [    0.0091],\n",
      "        [    0.0781],\n",
      "        [    0.0034],\n",
      "        [    0.0000],\n",
      "        [    0.0053],\n",
      "        [    0.0093],\n",
      "        [    0.0170],\n",
      "        [    0.1068],\n",
      "        [    0.0274],\n",
      "        [    0.0429],\n",
      "        [    0.0627],\n",
      "        [    0.0668],\n",
      "        [    0.0277],\n",
      "        [    0.0895],\n",
      "        [    0.0821],\n",
      "        [    0.0512],\n",
      "        [    0.0747],\n",
      "        [    0.0595],\n",
      "        [    0.0604],\n",
      "        [    0.0908],\n",
      "        [    0.0874],\n",
      "        [    0.0744],\n",
      "        [    0.0756],\n",
      "        [    0.1047],\n",
      "        [    0.0759],\n",
      "        [    0.0829],\n",
      "        [    0.0865],\n",
      "        [    0.1002],\n",
      "        [    0.1074],\n",
      "        [    0.1847],\n",
      "        [    0.0093],\n",
      "        [    0.0309],\n",
      "        [    0.0144],\n",
      "        [    0.0406],\n",
      "        [    0.0273],\n",
      "        [    0.0258],\n",
      "        [    0.0171],\n",
      "        [    0.0136],\n",
      "        [    0.0106],\n",
      "        [    0.0041],\n",
      "        [    0.0233],\n",
      "        [    0.0303],\n",
      "        [    0.0164],\n",
      "        [    0.0040],\n",
      "        [    0.0125],\n",
      "        [    0.0176],\n",
      "        [    0.0224],\n",
      "        [    0.0246],\n",
      "        [    0.0294],\n",
      "        [    0.0354]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 72\n",
      "Number of shrink: 28\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0359],\n",
      "        [0.0489],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0477],\n",
      "        [0.0366],\n",
      "        [0.0034],\n",
      "        [0.0217],\n",
      "        [0.0443],\n",
      "        [0.0235],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0995],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0843],\n",
      "        [0.0288],\n",
      "        [0.0881],\n",
      "        [0.0498],\n",
      "        [0.0135],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0432],\n",
      "        [0.0428],\n",
      "        [0.0400],\n",
      "        [0.0724],\n",
      "        [0.0250],\n",
      "        [0.0523],\n",
      "        [0.0089],\n",
      "        [0.0779],\n",
      "        [0.0031],\n",
      "        [0.0002],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0172],\n",
      "        [0.1070],\n",
      "        [0.0276],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0670],\n",
      "        [0.0279],\n",
      "        [0.0897],\n",
      "        [0.0824],\n",
      "        [0.0514],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0606],\n",
      "        [0.0910],\n",
      "        [0.0877],\n",
      "        [0.0746],\n",
      "        [0.0758],\n",
      "        [0.1049],\n",
      "        [0.0761],\n",
      "        [0.0831],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1076],\n",
      "        [0.1845],\n",
      "        [0.0091],\n",
      "        [0.0307],\n",
      "        [0.0141],\n",
      "        [0.0402],\n",
      "        [0.0268],\n",
      "        [0.0249],\n",
      "        [0.0181],\n",
      "        [0.0150],\n",
      "        [0.0120],\n",
      "        [0.0056],\n",
      "        [0.0221],\n",
      "        [0.0320],\n",
      "        [0.0181],\n",
      "        [0.0024],\n",
      "        [0.0110],\n",
      "        [0.0162],\n",
      "        [0.0209],\n",
      "        [0.0231],\n",
      "        [0.0311],\n",
      "        [0.0343]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 17.41352605819702\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 86\n",
      "剩餘X 資料 torch.Size([21, 18])\n",
      "剩餘Y 資料 torch.Size([21, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0014383015222847462, 12)\n",
      "The second_loss value of k: (0.0018304430413991213, 10)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([0.7078])\n",
      "目前模型的Data狀態 torch.Size([86, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8884],\n",
      "        [0.8758],\n",
      "        [0.8623],\n",
      "        [0.8185],\n",
      "        [0.7986],\n",
      "        [0.7456],\n",
      "        [0.7466],\n",
      "        [0.7407],\n",
      "        [0.7676],\n",
      "        [0.7035],\n",
      "        [0.6987],\n",
      "        [0.7141],\n",
      "        [0.7271],\n",
      "        [0.7380],\n",
      "        [0.7242],\n",
      "        [0.7287],\n",
      "        [0.7032],\n",
      "        [0.7804],\n",
      "        [0.7457]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0359],\n",
      "        [0.0489],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0477],\n",
      "        [0.0366],\n",
      "        [0.0034],\n",
      "        [0.0217],\n",
      "        [0.0443],\n",
      "        [0.0235],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0995],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0843],\n",
      "        [0.0288],\n",
      "        [0.0881],\n",
      "        [0.0498],\n",
      "        [0.0135],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0432],\n",
      "        [0.0428],\n",
      "        [0.0400],\n",
      "        [0.0724],\n",
      "        [0.0250],\n",
      "        [0.0523],\n",
      "        [0.0089],\n",
      "        [0.0779],\n",
      "        [0.0031],\n",
      "        [0.0002],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0172],\n",
      "        [0.1070],\n",
      "        [0.0276],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0670],\n",
      "        [0.0279],\n",
      "        [0.0897],\n",
      "        [0.0824],\n",
      "        [0.0514],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0606],\n",
      "        [0.0910],\n",
      "        [0.0877],\n",
      "        [0.0746],\n",
      "        [0.0758],\n",
      "        [0.1049],\n",
      "        [0.0761],\n",
      "        [0.0831],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1076],\n",
      "        [0.1845],\n",
      "        [0.0091],\n",
      "        [0.0307],\n",
      "        [0.0141],\n",
      "        [0.0402],\n",
      "        [0.0268],\n",
      "        [0.0249],\n",
      "        [0.0181],\n",
      "        [0.0150],\n",
      "        [0.0120],\n",
      "        [0.0056],\n",
      "        [0.0221],\n",
      "        [0.0320],\n",
      "        [0.0181],\n",
      "        [0.0024],\n",
      "        [0.0110],\n",
      "        [0.0162],\n",
      "        [0.0209],\n",
      "        [0.0231],\n",
      "        [0.0311],\n",
      "        [0.0343],\n",
      "        [0.0379]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0359],\n",
      "        [0.0489],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0477],\n",
      "        [0.0366],\n",
      "        [0.0034],\n",
      "        [0.0217],\n",
      "        [0.0443],\n",
      "        [0.0235],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0995],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0843],\n",
      "        [0.0288],\n",
      "        [0.0881],\n",
      "        [0.0498],\n",
      "        [0.0135],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0432],\n",
      "        [0.0428],\n",
      "        [0.0400],\n",
      "        [0.0724],\n",
      "        [0.0250],\n",
      "        [0.0523],\n",
      "        [0.0089],\n",
      "        [0.0779],\n",
      "        [0.0031],\n",
      "        [0.0002],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0172],\n",
      "        [0.1071],\n",
      "        [0.0276],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0670],\n",
      "        [0.0279],\n",
      "        [0.0897],\n",
      "        [0.0824],\n",
      "        [0.0514],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0606],\n",
      "        [0.0910],\n",
      "        [0.0876],\n",
      "        [0.0746],\n",
      "        [0.0758],\n",
      "        [0.1049],\n",
      "        [0.0761],\n",
      "        [0.0831],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1076],\n",
      "        [0.1845],\n",
      "        [0.0091],\n",
      "        [0.0307],\n",
      "        [0.0136],\n",
      "        [0.0396],\n",
      "        [0.0260],\n",
      "        [0.0234],\n",
      "        [0.0198],\n",
      "        [0.0173],\n",
      "        [0.0143],\n",
      "        [0.0079],\n",
      "        [0.0200],\n",
      "        [0.0347],\n",
      "        [0.0209],\n",
      "        [0.0003],\n",
      "        [0.0085],\n",
      "        [0.0138],\n",
      "        [0.0183],\n",
      "        [0.0206],\n",
      "        [0.0338],\n",
      "        [0.0323],\n",
      "        [0.0356]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 17.647225379943848\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 87\n",
      "剩餘X 資料 torch.Size([20, 18])\n",
      "剩餘Y 資料 torch.Size([20, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0016085676616057754, 10)\n",
      "The second_loss value of k: (0.0017040262464433908, 11)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引10，y= tensor([0.6611])\n",
      "目前模型的Data狀態 torch.Size([87, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8923],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8879],\n",
      "        [0.8752],\n",
      "        [0.8615],\n",
      "        [0.8171],\n",
      "        [0.7969],\n",
      "        [0.7433],\n",
      "        [0.7442],\n",
      "        [0.7384],\n",
      "        [0.7655],\n",
      "        [0.7008],\n",
      "        [0.6959],\n",
      "        [0.7115],\n",
      "        [0.7246],\n",
      "        [0.7356],\n",
      "        [0.7217],\n",
      "        [0.7262],\n",
      "        [0.7004],\n",
      "        [0.7784],\n",
      "        [0.7434],\n",
      "        [0.7012]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0359],\n",
      "        [0.0489],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0477],\n",
      "        [0.0366],\n",
      "        [0.0034],\n",
      "        [0.0217],\n",
      "        [0.0443],\n",
      "        [0.0235],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0995],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0843],\n",
      "        [0.0288],\n",
      "        [0.0881],\n",
      "        [0.0498],\n",
      "        [0.0135],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0432],\n",
      "        [0.0428],\n",
      "        [0.0400],\n",
      "        [0.0724],\n",
      "        [0.0250],\n",
      "        [0.0523],\n",
      "        [0.0089],\n",
      "        [0.0779],\n",
      "        [0.0031],\n",
      "        [0.0002],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0172],\n",
      "        [0.1071],\n",
      "        [0.0276],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0670],\n",
      "        [0.0279],\n",
      "        [0.0897],\n",
      "        [0.0824],\n",
      "        [0.0514],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0606],\n",
      "        [0.0910],\n",
      "        [0.0876],\n",
      "        [0.0746],\n",
      "        [0.0758],\n",
      "        [0.1049],\n",
      "        [0.0761],\n",
      "        [0.0831],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1076],\n",
      "        [0.1845],\n",
      "        [0.0091],\n",
      "        [0.0307],\n",
      "        [0.0136],\n",
      "        [0.0396],\n",
      "        [0.0260],\n",
      "        [0.0234],\n",
      "        [0.0198],\n",
      "        [0.0173],\n",
      "        [0.0143],\n",
      "        [0.0079],\n",
      "        [0.0200],\n",
      "        [0.0347],\n",
      "        [0.0209],\n",
      "        [0.0003],\n",
      "        [0.0085],\n",
      "        [0.0138],\n",
      "        [0.0183],\n",
      "        [0.0206],\n",
      "        [0.0338],\n",
      "        [0.0323],\n",
      "        [0.0356],\n",
      "        [0.0401]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 63\n",
      "Number of shrink: 37\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0216],\n",
      "        [    0.0442],\n",
      "        [    0.0234],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0725],\n",
      "        [    0.0251],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1069],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0896],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1075],\n",
      "        [    0.1846],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0136],\n",
      "        [    0.0394],\n",
      "        [    0.0255],\n",
      "        [    0.0222],\n",
      "        [    0.0214],\n",
      "        [    0.0198],\n",
      "        [    0.0169],\n",
      "        [    0.0106],\n",
      "        [    0.0179],\n",
      "        [    0.0379],\n",
      "        [    0.0242],\n",
      "        [    0.0033],\n",
      "        [    0.0056],\n",
      "        [    0.0111],\n",
      "        [    0.0154],\n",
      "        [    0.0178],\n",
      "        [    0.0370],\n",
      "        [    0.0303],\n",
      "        [    0.0331],\n",
      "        [    0.0369]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 17.883838176727295\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 88\n",
      "剩餘X 資料 torch.Size([19, 18])\n",
      "剩餘Y 資料 torch.Size([19, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0014875472988933325, 10)\n",
      "The second_loss value of k: (0.0017486223950982094, 8)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引10，y= tensor([0.6914])\n",
      "目前模型的Data狀態 torch.Size([88, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8879],\n",
      "        [0.8750],\n",
      "        [0.8610],\n",
      "        [0.8158],\n",
      "        [0.7952],\n",
      "        [0.7408],\n",
      "        [0.7417],\n",
      "        [0.7357],\n",
      "        [0.7634],\n",
      "        [0.6976],\n",
      "        [0.6926],\n",
      "        [0.7084],\n",
      "        [0.7217],\n",
      "        [0.7329],\n",
      "        [0.7188],\n",
      "        [0.7234],\n",
      "        [0.6972],\n",
      "        [0.7765],\n",
      "        [0.7409],\n",
      "        [0.6979],\n",
      "        [0.7300]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0216],\n",
      "        [    0.0442],\n",
      "        [    0.0234],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0725],\n",
      "        [    0.0251],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1069],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0896],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1075],\n",
      "        [    0.1846],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0136],\n",
      "        [    0.0394],\n",
      "        [    0.0255],\n",
      "        [    0.0222],\n",
      "        [    0.0214],\n",
      "        [    0.0198],\n",
      "        [    0.0169],\n",
      "        [    0.0106],\n",
      "        [    0.0179],\n",
      "        [    0.0379],\n",
      "        [    0.0242],\n",
      "        [    0.0033],\n",
      "        [    0.0056],\n",
      "        [    0.0111],\n",
      "        [    0.0154],\n",
      "        [    0.0178],\n",
      "        [    0.0370],\n",
      "        [    0.0303],\n",
      "        [    0.0331],\n",
      "        [    0.0369],\n",
      "        [    0.0386]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 68\n",
      "Number of shrink: 32\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0216],\n",
      "        [    0.0442],\n",
      "        [    0.0234],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0725],\n",
      "        [    0.0251],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1075],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0134],\n",
      "        [    0.0391],\n",
      "        [    0.0251],\n",
      "        [    0.0211],\n",
      "        [    0.0227],\n",
      "        [    0.0218],\n",
      "        [    0.0189],\n",
      "        [    0.0126],\n",
      "        [    0.0161],\n",
      "        [    0.0405],\n",
      "        [    0.0268],\n",
      "        [    0.0058],\n",
      "        [    0.0034],\n",
      "        [    0.0090],\n",
      "        [    0.0131],\n",
      "        [    0.0155],\n",
      "        [    0.0396],\n",
      "        [    0.0287],\n",
      "        [    0.0311],\n",
      "        [    0.0343],\n",
      "        [    0.0364]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 18.117974042892456\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 89\n",
      "剩餘X 資料 torch.Size([18, 18])\n",
      "剩餘Y 資料 torch.Size([18, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0015413265209645033, 8)\n",
      "The second_loss value of k: (0.00265470240265131, 10)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引8，y= tensor([0.6553])\n",
      "目前模型的Data狀態 torch.Size([89, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8878],\n",
      "        [0.8747],\n",
      "        [0.8606],\n",
      "        [0.8147],\n",
      "        [0.7939],\n",
      "        [0.7388],\n",
      "        [0.7397],\n",
      "        [0.7337],\n",
      "        [0.7616],\n",
      "        [0.6950],\n",
      "        [0.6900],\n",
      "        [0.7060],\n",
      "        [0.7195],\n",
      "        [0.7308],\n",
      "        [0.7165],\n",
      "        [0.7212],\n",
      "        [0.6946],\n",
      "        [0.7749],\n",
      "        [0.7389],\n",
      "        [0.6954],\n",
      "        [0.7278],\n",
      "        [0.6946]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0216],\n",
      "        [    0.0442],\n",
      "        [    0.0234],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0725],\n",
      "        [    0.0251],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1075],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0134],\n",
      "        [    0.0391],\n",
      "        [    0.0251],\n",
      "        [    0.0211],\n",
      "        [    0.0227],\n",
      "        [    0.0218],\n",
      "        [    0.0189],\n",
      "        [    0.0126],\n",
      "        [    0.0161],\n",
      "        [    0.0405],\n",
      "        [    0.0268],\n",
      "        [    0.0058],\n",
      "        [    0.0034],\n",
      "        [    0.0090],\n",
      "        [    0.0131],\n",
      "        [    0.0155],\n",
      "        [    0.0396],\n",
      "        [    0.0287],\n",
      "        [    0.0311],\n",
      "        [    0.0343],\n",
      "        [    0.0364],\n",
      "        [    0.0393]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 67\n",
      "Number of shrink: 33\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0056],\n",
      "        [    0.0358],\n",
      "        [    0.0490],\n",
      "        [    0.0886],\n",
      "        [    0.0790],\n",
      "        [    0.0504],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0036],\n",
      "        [    0.0216],\n",
      "        [    0.0442],\n",
      "        [    0.0234],\n",
      "        [    0.0392],\n",
      "        [    0.0378],\n",
      "        [    0.0471],\n",
      "        [    0.0996],\n",
      "        [    0.0860],\n",
      "        [    0.0610],\n",
      "        [    0.0889],\n",
      "        [    0.0842],\n",
      "        [    0.0290],\n",
      "        [    0.0882],\n",
      "        [    0.0500],\n",
      "        [    0.0134],\n",
      "        [    0.0831],\n",
      "        [    0.0630],\n",
      "        [    0.0629],\n",
      "        [    0.0492],\n",
      "        [    0.0463],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0725],\n",
      "        [    0.0251],\n",
      "        [    0.0525],\n",
      "        [    0.0090],\n",
      "        [    0.0781],\n",
      "        [    0.0033],\n",
      "        [    0.0001],\n",
      "        [    0.0053],\n",
      "        [    0.0093],\n",
      "        [    0.0171],\n",
      "        [    0.1069],\n",
      "        [    0.0275],\n",
      "        [    0.0429],\n",
      "        [    0.0627],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0896],\n",
      "        [    0.0822],\n",
      "        [    0.0513],\n",
      "        [    0.0748],\n",
      "        [    0.0596],\n",
      "        [    0.0605],\n",
      "        [    0.0908],\n",
      "        [    0.0875],\n",
      "        [    0.0744],\n",
      "        [    0.0757],\n",
      "        [    0.1047],\n",
      "        [    0.0760],\n",
      "        [    0.0830],\n",
      "        [    0.0865],\n",
      "        [    0.1002],\n",
      "        [    0.1075],\n",
      "        [    0.1846],\n",
      "        [    0.0092],\n",
      "        [    0.0309],\n",
      "        [    0.0134],\n",
      "        [    0.0388],\n",
      "        [    0.0246],\n",
      "        [    0.0200],\n",
      "        [    0.0241],\n",
      "        [    0.0240],\n",
      "        [    0.0210],\n",
      "        [    0.0149],\n",
      "        [    0.0143],\n",
      "        [    0.0432],\n",
      "        [    0.0296],\n",
      "        [    0.0084],\n",
      "        [    0.0009],\n",
      "        [    0.0067],\n",
      "        [    0.0107],\n",
      "        [    0.0131],\n",
      "        [    0.0424],\n",
      "        [    0.0271],\n",
      "        [    0.0289],\n",
      "        [    0.0316],\n",
      "        [    0.0341],\n",
      "        [    0.0365]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 18.348536014556885\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 90\n",
      "剩餘X 資料 torch.Size([17, 18])\n",
      "剩餘Y 資料 torch.Size([17, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0024607873056083918, 9)\n",
      "The second_loss value of k: (0.0029859980568289757, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引9，y= tensor([0.7050])\n",
      "目前模型的Data狀態 torch.Size([90, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8877],\n",
      "        [0.8745],\n",
      "        [0.8601],\n",
      "        [0.8136],\n",
      "        [0.7925],\n",
      "        [0.7366],\n",
      "        [0.7376],\n",
      "        [0.7314],\n",
      "        [0.7598],\n",
      "        [0.6922],\n",
      "        [0.6871],\n",
      "        [0.7034],\n",
      "        [0.7170],\n",
      "        [0.7285],\n",
      "        [0.7140],\n",
      "        [0.7187],\n",
      "        [0.6919],\n",
      "        [0.7732],\n",
      "        [0.7367],\n",
      "        [0.6926],\n",
      "        [0.7255],\n",
      "        [0.6918],\n",
      "        [0.7546]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0056],\n",
      "        [    0.0358],\n",
      "        [    0.0490],\n",
      "        [    0.0886],\n",
      "        [    0.0790],\n",
      "        [    0.0504],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0036],\n",
      "        [    0.0216],\n",
      "        [    0.0442],\n",
      "        [    0.0234],\n",
      "        [    0.0392],\n",
      "        [    0.0378],\n",
      "        [    0.0471],\n",
      "        [    0.0996],\n",
      "        [    0.0860],\n",
      "        [    0.0610],\n",
      "        [    0.0889],\n",
      "        [    0.0842],\n",
      "        [    0.0290],\n",
      "        [    0.0882],\n",
      "        [    0.0500],\n",
      "        [    0.0134],\n",
      "        [    0.0831],\n",
      "        [    0.0630],\n",
      "        [    0.0629],\n",
      "        [    0.0492],\n",
      "        [    0.0463],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0725],\n",
      "        [    0.0251],\n",
      "        [    0.0525],\n",
      "        [    0.0090],\n",
      "        [    0.0781],\n",
      "        [    0.0033],\n",
      "        [    0.0001],\n",
      "        [    0.0053],\n",
      "        [    0.0093],\n",
      "        [    0.0171],\n",
      "        [    0.1069],\n",
      "        [    0.0275],\n",
      "        [    0.0429],\n",
      "        [    0.0627],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0896],\n",
      "        [    0.0822],\n",
      "        [    0.0513],\n",
      "        [    0.0748],\n",
      "        [    0.0596],\n",
      "        [    0.0605],\n",
      "        [    0.0908],\n",
      "        [    0.0875],\n",
      "        [    0.0744],\n",
      "        [    0.0757],\n",
      "        [    0.1047],\n",
      "        [    0.0760],\n",
      "        [    0.0830],\n",
      "        [    0.0865],\n",
      "        [    0.1002],\n",
      "        [    0.1075],\n",
      "        [    0.1846],\n",
      "        [    0.0092],\n",
      "        [    0.0309],\n",
      "        [    0.0134],\n",
      "        [    0.0388],\n",
      "        [    0.0246],\n",
      "        [    0.0200],\n",
      "        [    0.0241],\n",
      "        [    0.0240],\n",
      "        [    0.0210],\n",
      "        [    0.0149],\n",
      "        [    0.0143],\n",
      "        [    0.0432],\n",
      "        [    0.0296],\n",
      "        [    0.0084],\n",
      "        [    0.0009],\n",
      "        [    0.0067],\n",
      "        [    0.0107],\n",
      "        [    0.0131],\n",
      "        [    0.0424],\n",
      "        [    0.0271],\n",
      "        [    0.0289],\n",
      "        [    0.0316],\n",
      "        [    0.0341],\n",
      "        [    0.0365],\n",
      "        [    0.0496]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 67\n",
      "Number of shrink: 33\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0217],\n",
      "        [    0.0442],\n",
      "        [    0.0235],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0432],\n",
      "        [    0.0429],\n",
      "        [    0.0400],\n",
      "        [    0.0725],\n",
      "        [    0.0250],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0172],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1076],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0132],\n",
      "        [    0.0385],\n",
      "        [    0.0241],\n",
      "        [    0.0189],\n",
      "        [    0.0255],\n",
      "        [    0.0261],\n",
      "        [    0.0231],\n",
      "        [    0.0170],\n",
      "        [    0.0125],\n",
      "        [    0.0459],\n",
      "        [    0.0323],\n",
      "        [    0.0109],\n",
      "        [    0.0014],\n",
      "        [    0.0045],\n",
      "        [    0.0083],\n",
      "        [    0.0108],\n",
      "        [    0.0450],\n",
      "        [    0.0254],\n",
      "        [    0.0268],\n",
      "        [    0.0290],\n",
      "        [    0.0319],\n",
      "        [    0.0339],\n",
      "        [    0.0477]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 18.581178188323975\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 91\n",
      "剩餘X 資料 torch.Size([16, 18])\n",
      "剩餘Y 資料 torch.Size([16, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.002738705137744546, 3)\n",
      "The second_loss value of k: (0.004378986544907093, 9)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.6630])\n",
      "目前模型的Data狀態 torch.Size([91, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8875],\n",
      "        [0.8741],\n",
      "        [0.8596],\n",
      "        [0.8125],\n",
      "        [0.7911],\n",
      "        [0.7345],\n",
      "        [0.7355],\n",
      "        [0.7293],\n",
      "        [0.7580],\n",
      "        [0.6896],\n",
      "        [0.6844],\n",
      "        [0.7009],\n",
      "        [0.7147],\n",
      "        [0.7263],\n",
      "        [0.7117],\n",
      "        [0.7164],\n",
      "        [0.6892],\n",
      "        [0.7716],\n",
      "        [0.7346],\n",
      "        [0.6900],\n",
      "        [0.7233],\n",
      "        [0.6892],\n",
      "        [0.7528],\n",
      "        [0.7154]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0217],\n",
      "        [    0.0442],\n",
      "        [    0.0235],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0432],\n",
      "        [    0.0429],\n",
      "        [    0.0400],\n",
      "        [    0.0725],\n",
      "        [    0.0250],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0172],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1076],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0132],\n",
      "        [    0.0385],\n",
      "        [    0.0241],\n",
      "        [    0.0189],\n",
      "        [    0.0255],\n",
      "        [    0.0261],\n",
      "        [    0.0231],\n",
      "        [    0.0170],\n",
      "        [    0.0125],\n",
      "        [    0.0459],\n",
      "        [    0.0323],\n",
      "        [    0.0109],\n",
      "        [    0.0014],\n",
      "        [    0.0045],\n",
      "        [    0.0083],\n",
      "        [    0.0108],\n",
      "        [    0.0450],\n",
      "        [    0.0254],\n",
      "        [    0.0268],\n",
      "        [    0.0290],\n",
      "        [    0.0319],\n",
      "        [    0.0339],\n",
      "        [    0.0477],\n",
      "        [    0.0523]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 69\n",
      "Number of shrink: 31\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0216],\n",
      "        [    0.0442],\n",
      "        [    0.0234],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0725],\n",
      "        [    0.0251],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1075],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0130],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0176],\n",
      "        [    0.0271],\n",
      "        [    0.0285],\n",
      "        [    0.0255],\n",
      "        [    0.0195],\n",
      "        [    0.0104],\n",
      "        [    0.0489],\n",
      "        [    0.0355],\n",
      "        [    0.0138],\n",
      "        [    0.0041],\n",
      "        [    0.0020],\n",
      "        [    0.0056],\n",
      "        [    0.0081],\n",
      "        [    0.0481],\n",
      "        [    0.0235],\n",
      "        [    0.0244],\n",
      "        [    0.0259],\n",
      "        [    0.0293],\n",
      "        [    0.0308],\n",
      "        [    0.0456],\n",
      "        [    0.0496]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 18.83855700492859\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 92\n",
      "剩餘X 資料 torch.Size([15, 18])\n",
      "剩餘Y 資料 torch.Size([15, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004115724004805088, 8)\n",
      "The second_loss value of k: (0.004543890245258808, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引8，y= tensor([0.6950])\n",
      "目前模型的Data狀態 torch.Size([92, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8925],\n",
      "        [0.8874],\n",
      "        [0.8738],\n",
      "        [0.8590],\n",
      "        [0.8113],\n",
      "        [0.7896],\n",
      "        [0.7321],\n",
      "        [0.7331],\n",
      "        [0.7268],\n",
      "        [0.7559],\n",
      "        [0.6866],\n",
      "        [0.6813],\n",
      "        [0.6980],\n",
      "        [0.7120],\n",
      "        [0.7238],\n",
      "        [0.7089],\n",
      "        [0.7138],\n",
      "        [0.6862],\n",
      "        [0.7697],\n",
      "        [0.7322],\n",
      "        [0.6870],\n",
      "        [0.7207],\n",
      "        [0.6861],\n",
      "        [0.7506],\n",
      "        [0.7127],\n",
      "        [0.7592]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0057],\n",
      "        [    0.0359],\n",
      "        [    0.0489],\n",
      "        [    0.0885],\n",
      "        [    0.0789],\n",
      "        [    0.0503],\n",
      "        [    0.0478],\n",
      "        [    0.0365],\n",
      "        [    0.0035],\n",
      "        [    0.0216],\n",
      "        [    0.0442],\n",
      "        [    0.0234],\n",
      "        [    0.0391],\n",
      "        [    0.0377],\n",
      "        [    0.0470],\n",
      "        [    0.0996],\n",
      "        [    0.0859],\n",
      "        [    0.0609],\n",
      "        [    0.0888],\n",
      "        [    0.0842],\n",
      "        [    0.0289],\n",
      "        [    0.0882],\n",
      "        [    0.0499],\n",
      "        [    0.0135],\n",
      "        [    0.0830],\n",
      "        [    0.0629],\n",
      "        [    0.0628],\n",
      "        [    0.0492],\n",
      "        [    0.0462],\n",
      "        [    0.0433],\n",
      "        [    0.0429],\n",
      "        [    0.0401],\n",
      "        [    0.0725],\n",
      "        [    0.0251],\n",
      "        [    0.0524],\n",
      "        [    0.0090],\n",
      "        [    0.0780],\n",
      "        [    0.0032],\n",
      "        [    0.0001],\n",
      "        [    0.0054],\n",
      "        [    0.0094],\n",
      "        [    0.0171],\n",
      "        [    0.1070],\n",
      "        [    0.0275],\n",
      "        [    0.0430],\n",
      "        [    0.0628],\n",
      "        [    0.0669],\n",
      "        [    0.0278],\n",
      "        [    0.0897],\n",
      "        [    0.0823],\n",
      "        [    0.0513],\n",
      "        [    0.0749],\n",
      "        [    0.0597],\n",
      "        [    0.0605],\n",
      "        [    0.0909],\n",
      "        [    0.0876],\n",
      "        [    0.0745],\n",
      "        [    0.0757],\n",
      "        [    0.1048],\n",
      "        [    0.0760],\n",
      "        [    0.0831],\n",
      "        [    0.0866],\n",
      "        [    0.1003],\n",
      "        [    0.1075],\n",
      "        [    0.1845],\n",
      "        [    0.0091],\n",
      "        [    0.0308],\n",
      "        [    0.0130],\n",
      "        [    0.0381],\n",
      "        [    0.0235],\n",
      "        [    0.0176],\n",
      "        [    0.0271],\n",
      "        [    0.0285],\n",
      "        [    0.0255],\n",
      "        [    0.0195],\n",
      "        [    0.0104],\n",
      "        [    0.0489],\n",
      "        [    0.0355],\n",
      "        [    0.0138],\n",
      "        [    0.0041],\n",
      "        [    0.0020],\n",
      "        [    0.0056],\n",
      "        [    0.0081],\n",
      "        [    0.0481],\n",
      "        [    0.0235],\n",
      "        [    0.0244],\n",
      "        [    0.0259],\n",
      "        [    0.0293],\n",
      "        [    0.0308],\n",
      "        [    0.0456],\n",
      "        [    0.0496],\n",
      "        [    0.0642]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 72\n",
      "Number of shrink: 28\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0360],\n",
      "        [0.0488],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0476],\n",
      "        [0.0367],\n",
      "        [0.0034],\n",
      "        [0.0218],\n",
      "        [0.0443],\n",
      "        [0.0236],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0994],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0844],\n",
      "        [0.0288],\n",
      "        [0.0880],\n",
      "        [0.0498],\n",
      "        [0.0136],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0490],\n",
      "        [0.0461],\n",
      "        [0.0431],\n",
      "        [0.0427],\n",
      "        [0.0399],\n",
      "        [0.0723],\n",
      "        [0.0249],\n",
      "        [0.0523],\n",
      "        [0.0088],\n",
      "        [0.0779],\n",
      "        [0.0031],\n",
      "        [0.0003],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0173],\n",
      "        [0.1071],\n",
      "        [0.0277],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0671],\n",
      "        [0.0280],\n",
      "        [0.0898],\n",
      "        [0.0824],\n",
      "        [0.0515],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0607],\n",
      "        [0.0910],\n",
      "        [0.0877],\n",
      "        [0.0746],\n",
      "        [0.0759],\n",
      "        [0.1049],\n",
      "        [0.0762],\n",
      "        [0.0832],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1077],\n",
      "        [0.1844],\n",
      "        [0.0090],\n",
      "        [0.0307],\n",
      "        [0.0127],\n",
      "        [0.0377],\n",
      "        [0.0229],\n",
      "        [0.0164],\n",
      "        [0.0286],\n",
      "        [0.0308],\n",
      "        [0.0278],\n",
      "        [0.0219],\n",
      "        [0.0084],\n",
      "        [0.0518],\n",
      "        [0.0384],\n",
      "        [0.0165],\n",
      "        [0.0067],\n",
      "        [0.0004],\n",
      "        [0.0030],\n",
      "        [0.0056],\n",
      "        [0.0509],\n",
      "        [0.0217],\n",
      "        [0.0221],\n",
      "        [0.0231],\n",
      "        [0.0268],\n",
      "        [0.0280],\n",
      "        [0.0435],\n",
      "        [0.0471],\n",
      "        [0.0622]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 19.081505298614502\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 93\n",
      "剩餘X 資料 torch.Size([14, 18])\n",
      "剩餘Y 資料 torch.Size([14, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004306579474359751, 0)\n",
      "The second_loss value of k: (0.0047414363361895084, 7)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.7038])\n",
      "目前模型的Data狀態 torch.Size([93, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8871],\n",
      "        [0.8733],\n",
      "        [0.8584],\n",
      "        [0.8100],\n",
      "        [0.7880],\n",
      "        [0.7298],\n",
      "        [0.7308],\n",
      "        [0.7244],\n",
      "        [0.7539],\n",
      "        [0.6837],\n",
      "        [0.6784],\n",
      "        [0.6953],\n",
      "        [0.7094],\n",
      "        [0.7214],\n",
      "        [0.7063],\n",
      "        [0.7112],\n",
      "        [0.6833],\n",
      "        [0.7678],\n",
      "        [0.7299],\n",
      "        [0.6841],\n",
      "        [0.7183],\n",
      "        [0.6833],\n",
      "        [0.7485],\n",
      "        [0.7101],\n",
      "        [0.7572],\n",
      "        [0.7695]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0360],\n",
      "        [0.0488],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0476],\n",
      "        [0.0367],\n",
      "        [0.0034],\n",
      "        [0.0218],\n",
      "        [0.0443],\n",
      "        [0.0236],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0994],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0844],\n",
      "        [0.0288],\n",
      "        [0.0880],\n",
      "        [0.0498],\n",
      "        [0.0136],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0490],\n",
      "        [0.0461],\n",
      "        [0.0431],\n",
      "        [0.0427],\n",
      "        [0.0399],\n",
      "        [0.0723],\n",
      "        [0.0249],\n",
      "        [0.0523],\n",
      "        [0.0088],\n",
      "        [0.0779],\n",
      "        [0.0031],\n",
      "        [0.0003],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0173],\n",
      "        [0.1071],\n",
      "        [0.0277],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0671],\n",
      "        [0.0280],\n",
      "        [0.0898],\n",
      "        [0.0824],\n",
      "        [0.0515],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0607],\n",
      "        [0.0910],\n",
      "        [0.0877],\n",
      "        [0.0746],\n",
      "        [0.0759],\n",
      "        [0.1049],\n",
      "        [0.0762],\n",
      "        [0.0832],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1077],\n",
      "        [0.1844],\n",
      "        [0.0090],\n",
      "        [0.0307],\n",
      "        [0.0127],\n",
      "        [0.0377],\n",
      "        [0.0229],\n",
      "        [0.0164],\n",
      "        [0.0286],\n",
      "        [0.0308],\n",
      "        [0.0278],\n",
      "        [0.0219],\n",
      "        [0.0084],\n",
      "        [0.0518],\n",
      "        [0.0384],\n",
      "        [0.0165],\n",
      "        [0.0067],\n",
      "        [0.0004],\n",
      "        [0.0030],\n",
      "        [0.0056],\n",
      "        [0.0509],\n",
      "        [0.0217],\n",
      "        [0.0221],\n",
      "        [0.0231],\n",
      "        [0.0268],\n",
      "        [0.0280],\n",
      "        [0.0435],\n",
      "        [0.0471],\n",
      "        [0.0622],\n",
      "        [0.0656]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0360],\n",
      "        [0.0488],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0476],\n",
      "        [0.0366],\n",
      "        [0.0034],\n",
      "        [0.0218],\n",
      "        [0.0443],\n",
      "        [0.0236],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0995],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0844],\n",
      "        [0.0288],\n",
      "        [0.0881],\n",
      "        [0.0498],\n",
      "        [0.0136],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0490],\n",
      "        [0.0461],\n",
      "        [0.0431],\n",
      "        [0.0427],\n",
      "        [0.0399],\n",
      "        [0.0724],\n",
      "        [0.0249],\n",
      "        [0.0523],\n",
      "        [0.0089],\n",
      "        [0.0779],\n",
      "        [0.0031],\n",
      "        [0.0002],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0173],\n",
      "        [0.1075],\n",
      "        [0.0276],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0671],\n",
      "        [0.0280],\n",
      "        [0.0898],\n",
      "        [0.0824],\n",
      "        [0.0515],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0607],\n",
      "        [0.0910],\n",
      "        [0.0877],\n",
      "        [0.0746],\n",
      "        [0.0758],\n",
      "        [0.1049],\n",
      "        [0.0761],\n",
      "        [0.0832],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1077],\n",
      "        [0.1844],\n",
      "        [0.0090],\n",
      "        [0.0307],\n",
      "        [0.0115],\n",
      "        [0.0364],\n",
      "        [0.0216],\n",
      "        [0.0146],\n",
      "        [0.0305],\n",
      "        [0.0327],\n",
      "        [0.0298],\n",
      "        [0.0238],\n",
      "        [0.0065],\n",
      "        [0.0536],\n",
      "        [0.0402],\n",
      "        [0.0185],\n",
      "        [0.0088],\n",
      "        [0.0024],\n",
      "        [0.0010],\n",
      "        [0.0036],\n",
      "        [0.0528],\n",
      "        [0.0197],\n",
      "        [0.0201],\n",
      "        [0.0212],\n",
      "        [0.0248],\n",
      "        [0.0262],\n",
      "        [0.0416],\n",
      "        [0.0450],\n",
      "        [0.0603],\n",
      "        [0.0637]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 19.322861671447754\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 94\n",
      "剩餘X 資料 torch.Size([13, 18])\n",
      "剩餘Y 資料 torch.Size([13, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004500248935073614, 6)\n",
      "The second_loss value of k: (0.0048477016389369965, 5)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引6，y= tensor([0.6236])\n",
      "目前模型的Data狀態 torch.Size([94, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8919],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8858],\n",
      "        [0.8721],\n",
      "        [0.8570],\n",
      "        [0.8083],\n",
      "        [0.7862],\n",
      "        [0.7279],\n",
      "        [0.7288],\n",
      "        [0.7225],\n",
      "        [0.7520],\n",
      "        [0.6819],\n",
      "        [0.6765],\n",
      "        [0.6933],\n",
      "        [0.7073],\n",
      "        [0.7194],\n",
      "        [0.7043],\n",
      "        [0.7092],\n",
      "        [0.6814],\n",
      "        [0.7658],\n",
      "        [0.7279],\n",
      "        [0.6823],\n",
      "        [0.7163],\n",
      "        [0.6815],\n",
      "        [0.7466],\n",
      "        [0.7081],\n",
      "        [0.7553],\n",
      "        [0.7676],\n",
      "        [0.6907]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0360],\n",
      "        [0.0488],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0476],\n",
      "        [0.0366],\n",
      "        [0.0034],\n",
      "        [0.0218],\n",
      "        [0.0443],\n",
      "        [0.0236],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0995],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0844],\n",
      "        [0.0288],\n",
      "        [0.0881],\n",
      "        [0.0498],\n",
      "        [0.0136],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0490],\n",
      "        [0.0461],\n",
      "        [0.0431],\n",
      "        [0.0427],\n",
      "        [0.0399],\n",
      "        [0.0724],\n",
      "        [0.0249],\n",
      "        [0.0523],\n",
      "        [0.0089],\n",
      "        [0.0779],\n",
      "        [0.0031],\n",
      "        [0.0002],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0173],\n",
      "        [0.1075],\n",
      "        [0.0276],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0671],\n",
      "        [0.0280],\n",
      "        [0.0898],\n",
      "        [0.0824],\n",
      "        [0.0515],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0607],\n",
      "        [0.0910],\n",
      "        [0.0877],\n",
      "        [0.0746],\n",
      "        [0.0758],\n",
      "        [0.1049],\n",
      "        [0.0761],\n",
      "        [0.0832],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1077],\n",
      "        [0.1844],\n",
      "        [0.0090],\n",
      "        [0.0307],\n",
      "        [0.0115],\n",
      "        [0.0364],\n",
      "        [0.0216],\n",
      "        [0.0146],\n",
      "        [0.0305],\n",
      "        [0.0327],\n",
      "        [0.0298],\n",
      "        [0.0238],\n",
      "        [0.0065],\n",
      "        [0.0536],\n",
      "        [0.0402],\n",
      "        [0.0185],\n",
      "        [0.0088],\n",
      "        [0.0024],\n",
      "        [0.0010],\n",
      "        [0.0036],\n",
      "        [0.0528],\n",
      "        [0.0197],\n",
      "        [0.0201],\n",
      "        [0.0212],\n",
      "        [0.0248],\n",
      "        [0.0262],\n",
      "        [0.0416],\n",
      "        [0.0450],\n",
      "        [0.0603],\n",
      "        [0.0637],\n",
      "        [0.0671]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 71\n",
      "Number of shrink: 29\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0059],\n",
      "        [    0.0360],\n",
      "        [    0.0488],\n",
      "        [    0.0883],\n",
      "        [    0.0787],\n",
      "        [    0.0501],\n",
      "        [    0.0476],\n",
      "        [    0.0367],\n",
      "        [    0.0033],\n",
      "        [    0.0218],\n",
      "        [    0.0444],\n",
      "        [    0.0236],\n",
      "        [    0.0389],\n",
      "        [    0.0375],\n",
      "        [    0.0468],\n",
      "        [    0.0994],\n",
      "        [    0.0857],\n",
      "        [    0.0608],\n",
      "        [    0.0886],\n",
      "        [    0.0844],\n",
      "        [    0.0288],\n",
      "        [    0.0880],\n",
      "        [    0.0497],\n",
      "        [    0.0136],\n",
      "        [    0.0828],\n",
      "        [    0.0628],\n",
      "        [    0.0626],\n",
      "        [    0.0490],\n",
      "        [    0.0460],\n",
      "        [    0.0431],\n",
      "        [    0.0427],\n",
      "        [    0.0399],\n",
      "        [    0.0723],\n",
      "        [    0.0249],\n",
      "        [    0.0523],\n",
      "        [    0.0088],\n",
      "        [    0.0778],\n",
      "        [    0.0031],\n",
      "        [    0.0003],\n",
      "        [    0.0056],\n",
      "        [    0.0096],\n",
      "        [    0.0173],\n",
      "        [    0.1071],\n",
      "        [    0.0277],\n",
      "        [    0.0432],\n",
      "        [    0.0630],\n",
      "        [    0.0671],\n",
      "        [    0.0280],\n",
      "        [    0.0898],\n",
      "        [    0.0824],\n",
      "        [    0.0515],\n",
      "        [    0.0750],\n",
      "        [    0.0598],\n",
      "        [    0.0607],\n",
      "        [    0.0911],\n",
      "        [    0.0877],\n",
      "        [    0.0747],\n",
      "        [    0.0759],\n",
      "        [    0.1050],\n",
      "        [    0.0762],\n",
      "        [    0.0832],\n",
      "        [    0.0868],\n",
      "        [    0.1005],\n",
      "        [    0.1077],\n",
      "        [    0.1844],\n",
      "        [    0.0090],\n",
      "        [    0.0306],\n",
      "        [    0.0115],\n",
      "        [    0.0361],\n",
      "        [    0.0210],\n",
      "        [    0.0130],\n",
      "        [    0.0326],\n",
      "        [    0.0360],\n",
      "        [    0.0330],\n",
      "        [    0.0272],\n",
      "        [    0.0037],\n",
      "        [    0.0577],\n",
      "        [    0.0445],\n",
      "        [    0.0224],\n",
      "        [    0.0125],\n",
      "        [    0.0058],\n",
      "        [    0.0028],\n",
      "        [    0.0001],\n",
      "        [    0.0570],\n",
      "        [    0.0171],\n",
      "        [    0.0168],\n",
      "        [    0.0171],\n",
      "        [    0.0213],\n",
      "        [    0.0220],\n",
      "        [    0.0387],\n",
      "        [    0.0414],\n",
      "        [    0.0575],\n",
      "        [    0.0613],\n",
      "        [    0.0631]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 19.590720891952515\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 95\n",
      "剩餘X 資料 torch.Size([12, 18])\n",
      "剩餘Y 資料 torch.Size([12, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004337151534855366, 5)\n",
      "The second_loss value of k: (0.005397472530603409, 6)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引5，y= tensor([0.6335])\n",
      "目前模型的Data狀態 torch.Size([95, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8858],\n",
      "        [0.8718],\n",
      "        [0.8565],\n",
      "        [0.8066],\n",
      "        [0.7841],\n",
      "        [0.7246],\n",
      "        [0.7256],\n",
      "        [0.7191],\n",
      "        [0.7492],\n",
      "        [0.6777],\n",
      "        [0.6723],\n",
      "        [0.6893],\n",
      "        [0.7036],\n",
      "        [0.7159],\n",
      "        [0.7006],\n",
      "        [0.7055],\n",
      "        [0.6773],\n",
      "        [0.7632],\n",
      "        [0.7246],\n",
      "        [0.6782],\n",
      "        [0.7128],\n",
      "        [0.6773],\n",
      "        [0.7437],\n",
      "        [0.7044],\n",
      "        [0.7526],\n",
      "        [0.7652],\n",
      "        [0.6867],\n",
      "        [0.6993]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0059],\n",
      "        [    0.0360],\n",
      "        [    0.0488],\n",
      "        [    0.0883],\n",
      "        [    0.0787],\n",
      "        [    0.0501],\n",
      "        [    0.0476],\n",
      "        [    0.0367],\n",
      "        [    0.0033],\n",
      "        [    0.0218],\n",
      "        [    0.0444],\n",
      "        [    0.0236],\n",
      "        [    0.0389],\n",
      "        [    0.0375],\n",
      "        [    0.0468],\n",
      "        [    0.0994],\n",
      "        [    0.0857],\n",
      "        [    0.0608],\n",
      "        [    0.0886],\n",
      "        [    0.0844],\n",
      "        [    0.0288],\n",
      "        [    0.0880],\n",
      "        [    0.0497],\n",
      "        [    0.0136],\n",
      "        [    0.0828],\n",
      "        [    0.0628],\n",
      "        [    0.0626],\n",
      "        [    0.0490],\n",
      "        [    0.0460],\n",
      "        [    0.0431],\n",
      "        [    0.0427],\n",
      "        [    0.0399],\n",
      "        [    0.0723],\n",
      "        [    0.0249],\n",
      "        [    0.0523],\n",
      "        [    0.0088],\n",
      "        [    0.0778],\n",
      "        [    0.0031],\n",
      "        [    0.0003],\n",
      "        [    0.0056],\n",
      "        [    0.0096],\n",
      "        [    0.0173],\n",
      "        [    0.1071],\n",
      "        [    0.0277],\n",
      "        [    0.0432],\n",
      "        [    0.0630],\n",
      "        [    0.0671],\n",
      "        [    0.0280],\n",
      "        [    0.0898],\n",
      "        [    0.0824],\n",
      "        [    0.0515],\n",
      "        [    0.0750],\n",
      "        [    0.0598],\n",
      "        [    0.0607],\n",
      "        [    0.0911],\n",
      "        [    0.0877],\n",
      "        [    0.0747],\n",
      "        [    0.0759],\n",
      "        [    0.1050],\n",
      "        [    0.0762],\n",
      "        [    0.0832],\n",
      "        [    0.0868],\n",
      "        [    0.1005],\n",
      "        [    0.1077],\n",
      "        [    0.1844],\n",
      "        [    0.0090],\n",
      "        [    0.0306],\n",
      "        [    0.0115],\n",
      "        [    0.0361],\n",
      "        [    0.0210],\n",
      "        [    0.0130],\n",
      "        [    0.0326],\n",
      "        [    0.0360],\n",
      "        [    0.0330],\n",
      "        [    0.0272],\n",
      "        [    0.0037],\n",
      "        [    0.0577],\n",
      "        [    0.0445],\n",
      "        [    0.0224],\n",
      "        [    0.0125],\n",
      "        [    0.0058],\n",
      "        [    0.0028],\n",
      "        [    0.0001],\n",
      "        [    0.0570],\n",
      "        [    0.0171],\n",
      "        [    0.0168],\n",
      "        [    0.0171],\n",
      "        [    0.0213],\n",
      "        [    0.0220],\n",
      "        [    0.0387],\n",
      "        [    0.0414],\n",
      "        [    0.0575],\n",
      "        [    0.0613],\n",
      "        [    0.0631],\n",
      "        [    0.0659]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 68\n",
      "Number of shrink: 32\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0360],\n",
      "        [0.0488],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0477],\n",
      "        [0.0366],\n",
      "        [0.0034],\n",
      "        [0.0217],\n",
      "        [0.0443],\n",
      "        [0.0236],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0995],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0843],\n",
      "        [0.0288],\n",
      "        [0.0881],\n",
      "        [0.0498],\n",
      "        [0.0136],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0432],\n",
      "        [0.0428],\n",
      "        [0.0399],\n",
      "        [0.0724],\n",
      "        [0.0249],\n",
      "        [0.0523],\n",
      "        [0.0089],\n",
      "        [0.0779],\n",
      "        [0.0031],\n",
      "        [0.0002],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0172],\n",
      "        [0.1071],\n",
      "        [0.0276],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0670],\n",
      "        [0.0279],\n",
      "        [0.0898],\n",
      "        [0.0824],\n",
      "        [0.0514],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0606],\n",
      "        [0.0910],\n",
      "        [0.0877],\n",
      "        [0.0746],\n",
      "        [0.0758],\n",
      "        [0.1049],\n",
      "        [0.0761],\n",
      "        [0.0832],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1076],\n",
      "        [0.1844],\n",
      "        [0.0090],\n",
      "        [0.0307],\n",
      "        [0.0113],\n",
      "        [0.0358],\n",
      "        [0.0204],\n",
      "        [0.0116],\n",
      "        [0.0343],\n",
      "        [0.0387],\n",
      "        [0.0357],\n",
      "        [0.0300],\n",
      "        [0.0014],\n",
      "        [0.0612],\n",
      "        [0.0480],\n",
      "        [0.0257],\n",
      "        [0.0155],\n",
      "        [0.0087],\n",
      "        [0.0058],\n",
      "        [0.0031],\n",
      "        [0.0604],\n",
      "        [0.0150],\n",
      "        [0.0141],\n",
      "        [0.0137],\n",
      "        [0.0185],\n",
      "        [0.0186],\n",
      "        [0.0363],\n",
      "        [0.0383],\n",
      "        [0.0553],\n",
      "        [0.0593],\n",
      "        [0.0598],\n",
      "        [0.0628]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 19.846912145614624\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 96\n",
      "剩餘X 資料 torch.Size([11, 18])\n",
      "剩餘Y 資料 torch.Size([11, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005078120157122612, 5)\n",
      "The second_loss value of k: (0.005409644450992346, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引5，y= tensor([0.6835])\n",
      "目前模型的Data狀態 torch.Size([96, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8857],\n",
      "        [0.8714],\n",
      "        [0.8559],\n",
      "        [0.8053],\n",
      "        [0.7823],\n",
      "        [0.7219],\n",
      "        [0.7229],\n",
      "        [0.7163],\n",
      "        [0.7469],\n",
      "        [0.6743],\n",
      "        [0.6688],\n",
      "        [0.6861],\n",
      "        [0.7006],\n",
      "        [0.7131],\n",
      "        [0.6975],\n",
      "        [0.7025],\n",
      "        [0.6739],\n",
      "        [0.7611],\n",
      "        [0.7219],\n",
      "        [0.6748],\n",
      "        [0.7099],\n",
      "        [0.6739],\n",
      "        [0.7413],\n",
      "        [0.7014],\n",
      "        [0.7503],\n",
      "        [0.7631],\n",
      "        [0.6834],\n",
      "        [0.6963],\n",
      "        [0.7548]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0360],\n",
      "        [0.0488],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0477],\n",
      "        [0.0366],\n",
      "        [0.0034],\n",
      "        [0.0217],\n",
      "        [0.0443],\n",
      "        [0.0236],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0995],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0843],\n",
      "        [0.0288],\n",
      "        [0.0881],\n",
      "        [0.0498],\n",
      "        [0.0136],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0432],\n",
      "        [0.0428],\n",
      "        [0.0399],\n",
      "        [0.0724],\n",
      "        [0.0249],\n",
      "        [0.0523],\n",
      "        [0.0089],\n",
      "        [0.0779],\n",
      "        [0.0031],\n",
      "        [0.0002],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0172],\n",
      "        [0.1071],\n",
      "        [0.0276],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0670],\n",
      "        [0.0279],\n",
      "        [0.0898],\n",
      "        [0.0824],\n",
      "        [0.0514],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0606],\n",
      "        [0.0910],\n",
      "        [0.0877],\n",
      "        [0.0746],\n",
      "        [0.0758],\n",
      "        [0.1049],\n",
      "        [0.0761],\n",
      "        [0.0832],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1076],\n",
      "        [0.1844],\n",
      "        [0.0090],\n",
      "        [0.0307],\n",
      "        [0.0113],\n",
      "        [0.0358],\n",
      "        [0.0204],\n",
      "        [0.0116],\n",
      "        [0.0343],\n",
      "        [0.0387],\n",
      "        [0.0357],\n",
      "        [0.0300],\n",
      "        [0.0014],\n",
      "        [0.0612],\n",
      "        [0.0480],\n",
      "        [0.0257],\n",
      "        [0.0155],\n",
      "        [0.0087],\n",
      "        [0.0058],\n",
      "        [0.0031],\n",
      "        [0.0604],\n",
      "        [0.0150],\n",
      "        [0.0141],\n",
      "        [0.0137],\n",
      "        [0.0185],\n",
      "        [0.0186],\n",
      "        [0.0363],\n",
      "        [0.0383],\n",
      "        [0.0553],\n",
      "        [0.0593],\n",
      "        [0.0598],\n",
      "        [0.0628],\n",
      "        [0.0713]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0063],\n",
      "        [0.0365],\n",
      "        [0.0483],\n",
      "        [0.0879],\n",
      "        [0.0783],\n",
      "        [0.0497],\n",
      "        [0.0472],\n",
      "        [0.0371],\n",
      "        [0.0029],\n",
      "        [0.0222],\n",
      "        [0.0448],\n",
      "        [0.0240],\n",
      "        [0.0385],\n",
      "        [0.0371],\n",
      "        [0.0464],\n",
      "        [0.0990],\n",
      "        [0.0853],\n",
      "        [0.0603],\n",
      "        [0.0882],\n",
      "        [0.0848],\n",
      "        [0.0283],\n",
      "        [0.0876],\n",
      "        [0.0493],\n",
      "        [0.0141],\n",
      "        [0.0824],\n",
      "        [0.0623],\n",
      "        [0.0622],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0427],\n",
      "        [0.0423],\n",
      "        [0.0395],\n",
      "        [0.0719],\n",
      "        [0.0244],\n",
      "        [0.0518],\n",
      "        [0.0084],\n",
      "        [0.0774],\n",
      "        [0.0026],\n",
      "        [0.0007],\n",
      "        [0.0060],\n",
      "        [0.0100],\n",
      "        [0.0177],\n",
      "        [0.1077],\n",
      "        [0.0281],\n",
      "        [0.0436],\n",
      "        [0.0634],\n",
      "        [0.0675],\n",
      "        [0.0284],\n",
      "        [0.0903],\n",
      "        [0.0829],\n",
      "        [0.0519],\n",
      "        [0.0755],\n",
      "        [0.0603],\n",
      "        [0.0611],\n",
      "        [0.0915],\n",
      "        [0.0882],\n",
      "        [0.0751],\n",
      "        [0.0763],\n",
      "        [0.1054],\n",
      "        [0.0766],\n",
      "        [0.0837],\n",
      "        [0.0872],\n",
      "        [0.1009],\n",
      "        [0.1081],\n",
      "        [0.1839],\n",
      "        [0.0085],\n",
      "        [0.0302],\n",
      "        [0.0100],\n",
      "        [0.0344],\n",
      "        [0.0188],\n",
      "        [0.0097],\n",
      "        [0.0364],\n",
      "        [0.0412],\n",
      "        [0.0383],\n",
      "        [0.0326],\n",
      "        [0.0011],\n",
      "        [0.0640],\n",
      "        [0.0509],\n",
      "        [0.0285],\n",
      "        [0.0184],\n",
      "        [0.0113],\n",
      "        [0.0087],\n",
      "        [0.0059],\n",
      "        [0.0632],\n",
      "        [0.0125],\n",
      "        [0.0114],\n",
      "        [0.0108],\n",
      "        [0.0157],\n",
      "        [0.0158],\n",
      "        [0.0336],\n",
      "        [0.0356],\n",
      "        [0.0526],\n",
      "        [0.0571],\n",
      "        [0.0570],\n",
      "        [0.0599],\n",
      "        [0.0686]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 20.106725454330444\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 97\n",
      "剩餘X 資料 torch.Size([10, 18])\n",
      "剩餘Y 資料 torch.Size([10, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005003327503800392, 3)\n",
      "The second_loss value of k: (0.005875162314623594, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.6213])\n",
      "目前模型的Data狀態 torch.Size([97, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8917],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8843],\n",
      "        [0.8700],\n",
      "        [0.8543],\n",
      "        [0.8033],\n",
      "        [0.7802],\n",
      "        [0.7194],\n",
      "        [0.7203],\n",
      "        [0.7137],\n",
      "        [0.7444],\n",
      "        [0.6715],\n",
      "        [0.6659],\n",
      "        [0.6832],\n",
      "        [0.6977],\n",
      "        [0.7105],\n",
      "        [0.6947],\n",
      "        [0.6997],\n",
      "        [0.6710],\n",
      "        [0.7586],\n",
      "        [0.7191],\n",
      "        [0.6719],\n",
      "        [0.7071],\n",
      "        [0.6711],\n",
      "        [0.7386],\n",
      "        [0.6986],\n",
      "        [0.7477],\n",
      "        [0.7609],\n",
      "        [0.6806],\n",
      "        [0.6934],\n",
      "        [0.7522],\n",
      "        [0.6921]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0063],\n",
      "        [0.0365],\n",
      "        [0.0483],\n",
      "        [0.0879],\n",
      "        [0.0783],\n",
      "        [0.0497],\n",
      "        [0.0472],\n",
      "        [0.0371],\n",
      "        [0.0029],\n",
      "        [0.0222],\n",
      "        [0.0448],\n",
      "        [0.0240],\n",
      "        [0.0385],\n",
      "        [0.0371],\n",
      "        [0.0464],\n",
      "        [0.0990],\n",
      "        [0.0853],\n",
      "        [0.0603],\n",
      "        [0.0882],\n",
      "        [0.0848],\n",
      "        [0.0283],\n",
      "        [0.0876],\n",
      "        [0.0493],\n",
      "        [0.0141],\n",
      "        [0.0824],\n",
      "        [0.0623],\n",
      "        [0.0622],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0427],\n",
      "        [0.0423],\n",
      "        [0.0395],\n",
      "        [0.0719],\n",
      "        [0.0244],\n",
      "        [0.0518],\n",
      "        [0.0084],\n",
      "        [0.0774],\n",
      "        [0.0026],\n",
      "        [0.0007],\n",
      "        [0.0060],\n",
      "        [0.0100],\n",
      "        [0.0177],\n",
      "        [0.1077],\n",
      "        [0.0281],\n",
      "        [0.0436],\n",
      "        [0.0634],\n",
      "        [0.0675],\n",
      "        [0.0284],\n",
      "        [0.0903],\n",
      "        [0.0829],\n",
      "        [0.0519],\n",
      "        [0.0755],\n",
      "        [0.0603],\n",
      "        [0.0611],\n",
      "        [0.0915],\n",
      "        [0.0882],\n",
      "        [0.0751],\n",
      "        [0.0763],\n",
      "        [0.1054],\n",
      "        [0.0766],\n",
      "        [0.0837],\n",
      "        [0.0872],\n",
      "        [0.1009],\n",
      "        [0.1081],\n",
      "        [0.1839],\n",
      "        [0.0085],\n",
      "        [0.0302],\n",
      "        [0.0100],\n",
      "        [0.0344],\n",
      "        [0.0188],\n",
      "        [0.0097],\n",
      "        [0.0364],\n",
      "        [0.0412],\n",
      "        [0.0383],\n",
      "        [0.0326],\n",
      "        [0.0011],\n",
      "        [0.0640],\n",
      "        [0.0509],\n",
      "        [0.0285],\n",
      "        [0.0184],\n",
      "        [0.0113],\n",
      "        [0.0087],\n",
      "        [0.0059],\n",
      "        [0.0632],\n",
      "        [0.0125],\n",
      "        [0.0114],\n",
      "        [0.0108],\n",
      "        [0.0157],\n",
      "        [0.0158],\n",
      "        [0.0336],\n",
      "        [0.0356],\n",
      "        [0.0526],\n",
      "        [0.0571],\n",
      "        [0.0570],\n",
      "        [0.0599],\n",
      "        [0.0686],\n",
      "        [0.0707]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 70\n",
      "Number of shrink: 30\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0059],\n",
      "        [0.0361],\n",
      "        [0.0487],\n",
      "        [0.0883],\n",
      "        [0.0787],\n",
      "        [0.0501],\n",
      "        [0.0476],\n",
      "        [0.0367],\n",
      "        [0.0033],\n",
      "        [0.0218],\n",
      "        [0.0444],\n",
      "        [0.0236],\n",
      "        [0.0389],\n",
      "        [0.0375],\n",
      "        [0.0468],\n",
      "        [0.0994],\n",
      "        [0.0857],\n",
      "        [0.0607],\n",
      "        [0.0886],\n",
      "        [0.0844],\n",
      "        [0.0287],\n",
      "        [0.0880],\n",
      "        [0.0497],\n",
      "        [0.0137],\n",
      "        [0.0828],\n",
      "        [0.0627],\n",
      "        [0.0626],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0431],\n",
      "        [0.0427],\n",
      "        [0.0399],\n",
      "        [0.0723],\n",
      "        [0.0249],\n",
      "        [0.0522],\n",
      "        [0.0088],\n",
      "        [0.0778],\n",
      "        [0.0030],\n",
      "        [0.0003],\n",
      "        [0.0056],\n",
      "        [0.0096],\n",
      "        [0.0173],\n",
      "        [0.1071],\n",
      "        [0.0277],\n",
      "        [0.0432],\n",
      "        [0.0630],\n",
      "        [0.0671],\n",
      "        [0.0280],\n",
      "        [0.0898],\n",
      "        [0.0825],\n",
      "        [0.0515],\n",
      "        [0.0751],\n",
      "        [0.0599],\n",
      "        [0.0607],\n",
      "        [0.0911],\n",
      "        [0.0878],\n",
      "        [0.0747],\n",
      "        [0.0759],\n",
      "        [0.1050],\n",
      "        [0.0762],\n",
      "        [0.0833],\n",
      "        [0.0868],\n",
      "        [0.1005],\n",
      "        [0.1077],\n",
      "        [0.1844],\n",
      "        [0.0089],\n",
      "        [0.0306],\n",
      "        [0.0103],\n",
      "        [0.0345],\n",
      "        [0.0187],\n",
      "        [0.0088],\n",
      "        [0.0377],\n",
      "        [0.0435],\n",
      "        [0.0405],\n",
      "        [0.0349],\n",
      "        [0.0030],\n",
      "        [0.0669],\n",
      "        [0.0539],\n",
      "        [0.0313],\n",
      "        [0.0210],\n",
      "        [0.0137],\n",
      "        [0.0113],\n",
      "        [0.0085],\n",
      "        [0.0662],\n",
      "        [0.0108],\n",
      "        [0.0091],\n",
      "        [0.0079],\n",
      "        [0.0132],\n",
      "        [0.0128],\n",
      "        [0.0316],\n",
      "        [0.0330],\n",
      "        [0.0508],\n",
      "        [0.0555],\n",
      "        [0.0542],\n",
      "        [0.0573],\n",
      "        [0.0668],\n",
      "        [0.0681]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 20.374308824539185\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 98\n",
      "剩餘X 資料 torch.Size([9, 18])\n",
      "剩餘Y 資料 torch.Size([9, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0054686544463038445, 3)\n",
      "The second_loss value of k: (0.0056700147688388824, 4)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.6143])\n",
      "目前模型的Data狀態 torch.Size([98, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8923],\n",
      "        [0.8847],\n",
      "        [0.8701],\n",
      "        [0.8542],\n",
      "        [0.8024],\n",
      "        [0.7790],\n",
      "        [0.7171],\n",
      "        [0.7181],\n",
      "        [0.7114],\n",
      "        [0.7425],\n",
      "        [0.6685],\n",
      "        [0.6628],\n",
      "        [0.6804],\n",
      "        [0.6951],\n",
      "        [0.7081],\n",
      "        [0.6921],\n",
      "        [0.6972],\n",
      "        [0.6680],\n",
      "        [0.7570],\n",
      "        [0.7169],\n",
      "        [0.6689],\n",
      "        [0.7047],\n",
      "        [0.6681],\n",
      "        [0.7367],\n",
      "        [0.6961],\n",
      "        [0.7458],\n",
      "        [0.7594],\n",
      "        [0.6778],\n",
      "        [0.6907],\n",
      "        [0.7504],\n",
      "        [0.6894],\n",
      "        [0.6883]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0059],\n",
      "        [0.0361],\n",
      "        [0.0487],\n",
      "        [0.0883],\n",
      "        [0.0787],\n",
      "        [0.0501],\n",
      "        [0.0476],\n",
      "        [0.0367],\n",
      "        [0.0033],\n",
      "        [0.0218],\n",
      "        [0.0444],\n",
      "        [0.0236],\n",
      "        [0.0389],\n",
      "        [0.0375],\n",
      "        [0.0468],\n",
      "        [0.0994],\n",
      "        [0.0857],\n",
      "        [0.0607],\n",
      "        [0.0886],\n",
      "        [0.0844],\n",
      "        [0.0287],\n",
      "        [0.0880],\n",
      "        [0.0497],\n",
      "        [0.0137],\n",
      "        [0.0828],\n",
      "        [0.0627],\n",
      "        [0.0626],\n",
      "        [0.0490],\n",
      "        [0.0460],\n",
      "        [0.0431],\n",
      "        [0.0427],\n",
      "        [0.0399],\n",
      "        [0.0723],\n",
      "        [0.0249],\n",
      "        [0.0522],\n",
      "        [0.0088],\n",
      "        [0.0778],\n",
      "        [0.0030],\n",
      "        [0.0003],\n",
      "        [0.0056],\n",
      "        [0.0096],\n",
      "        [0.0173],\n",
      "        [0.1071],\n",
      "        [0.0277],\n",
      "        [0.0432],\n",
      "        [0.0630],\n",
      "        [0.0671],\n",
      "        [0.0280],\n",
      "        [0.0898],\n",
      "        [0.0825],\n",
      "        [0.0515],\n",
      "        [0.0751],\n",
      "        [0.0599],\n",
      "        [0.0607],\n",
      "        [0.0911],\n",
      "        [0.0878],\n",
      "        [0.0747],\n",
      "        [0.0759],\n",
      "        [0.1050],\n",
      "        [0.0762],\n",
      "        [0.0833],\n",
      "        [0.0868],\n",
      "        [0.1005],\n",
      "        [0.1077],\n",
      "        [0.1844],\n",
      "        [0.0089],\n",
      "        [0.0306],\n",
      "        [0.0103],\n",
      "        [0.0345],\n",
      "        [0.0187],\n",
      "        [0.0088],\n",
      "        [0.0377],\n",
      "        [0.0435],\n",
      "        [0.0405],\n",
      "        [0.0349],\n",
      "        [0.0030],\n",
      "        [0.0669],\n",
      "        [0.0539],\n",
      "        [0.0313],\n",
      "        [0.0210],\n",
      "        [0.0137],\n",
      "        [0.0113],\n",
      "        [0.0085],\n",
      "        [0.0662],\n",
      "        [0.0108],\n",
      "        [0.0091],\n",
      "        [0.0079],\n",
      "        [0.0132],\n",
      "        [0.0128],\n",
      "        [0.0316],\n",
      "        [0.0330],\n",
      "        [0.0508],\n",
      "        [0.0555],\n",
      "        [0.0542],\n",
      "        [0.0573],\n",
      "        [0.0668],\n",
      "        [0.0681],\n",
      "        [0.0740]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 72\n",
      "Number of shrink: 28\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0359],\n",
      "        [0.0489],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0477],\n",
      "        [0.0366],\n",
      "        [0.0034],\n",
      "        [0.0217],\n",
      "        [0.0443],\n",
      "        [0.0235],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0995],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0843],\n",
      "        [0.0288],\n",
      "        [0.0881],\n",
      "        [0.0498],\n",
      "        [0.0135],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0432],\n",
      "        [0.0428],\n",
      "        [0.0400],\n",
      "        [0.0724],\n",
      "        [0.0250],\n",
      "        [0.0524],\n",
      "        [0.0089],\n",
      "        [0.0779],\n",
      "        [0.0032],\n",
      "        [0.0002],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0172],\n",
      "        [0.1070],\n",
      "        [0.0276],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0670],\n",
      "        [0.0279],\n",
      "        [0.0897],\n",
      "        [0.0824],\n",
      "        [0.0514],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0606],\n",
      "        [0.0910],\n",
      "        [0.0876],\n",
      "        [0.0746],\n",
      "        [0.0758],\n",
      "        [0.1049],\n",
      "        [0.0761],\n",
      "        [0.0831],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1076],\n",
      "        [0.1845],\n",
      "        [0.0091],\n",
      "        [0.0307],\n",
      "        [0.0102],\n",
      "        [0.0341],\n",
      "        [0.0181],\n",
      "        [0.0074],\n",
      "        [0.0395],\n",
      "        [0.0462],\n",
      "        [0.0433],\n",
      "        [0.0377],\n",
      "        [0.0054],\n",
      "        [0.0704],\n",
      "        [0.0575],\n",
      "        [0.0346],\n",
      "        [0.0241],\n",
      "        [0.0166],\n",
      "        [0.0144],\n",
      "        [0.0116],\n",
      "        [0.0697],\n",
      "        [0.0086],\n",
      "        [0.0063],\n",
      "        [0.0044],\n",
      "        [0.0103],\n",
      "        [0.0093],\n",
      "        [0.0291],\n",
      "        [0.0300],\n",
      "        [0.0484],\n",
      "        [0.0535],\n",
      "        [0.0508],\n",
      "        [0.0541],\n",
      "        [0.0645],\n",
      "        [0.0648],\n",
      "        [0.0707]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 20.64797830581665\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 99\n",
      "剩餘X 資料 torch.Size([8, 18])\n",
      "剩餘Y 資料 torch.Size([8, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0053329188376665115, 3)\n",
      "The second_loss value of k: (0.006077215541154146, 1)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引3，y= tensor([0.6772])\n",
      "目前模型的Data狀態 torch.Size([99, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8924],\n",
      "        [0.8845],\n",
      "        [0.8698],\n",
      "        [0.8536],\n",
      "        [0.8010],\n",
      "        [0.7772],\n",
      "        [0.7144],\n",
      "        [0.7153],\n",
      "        [0.7086],\n",
      "        [0.7401],\n",
      "        [0.6650],\n",
      "        [0.6592],\n",
      "        [0.6771],\n",
      "        [0.6920],\n",
      "        [0.7052],\n",
      "        [0.6889],\n",
      "        [0.6941],\n",
      "        [0.6645],\n",
      "        [0.7548],\n",
      "        [0.7141],\n",
      "        [0.6654],\n",
      "        [0.7017],\n",
      "        [0.6646],\n",
      "        [0.7342],\n",
      "        [0.6930],\n",
      "        [0.7435],\n",
      "        [0.7573],\n",
      "        [0.6744],\n",
      "        [0.6875],\n",
      "        [0.7481],\n",
      "        [0.6861],\n",
      "        [0.6850],\n",
      "        [0.7502]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0058],\n",
      "        [0.0359],\n",
      "        [0.0489],\n",
      "        [0.0884],\n",
      "        [0.0788],\n",
      "        [0.0502],\n",
      "        [0.0477],\n",
      "        [0.0366],\n",
      "        [0.0034],\n",
      "        [0.0217],\n",
      "        [0.0443],\n",
      "        [0.0235],\n",
      "        [0.0390],\n",
      "        [0.0376],\n",
      "        [0.0469],\n",
      "        [0.0995],\n",
      "        [0.0858],\n",
      "        [0.0608],\n",
      "        [0.0887],\n",
      "        [0.0843],\n",
      "        [0.0288],\n",
      "        [0.0881],\n",
      "        [0.0498],\n",
      "        [0.0135],\n",
      "        [0.0829],\n",
      "        [0.0628],\n",
      "        [0.0627],\n",
      "        [0.0491],\n",
      "        [0.0461],\n",
      "        [0.0432],\n",
      "        [0.0428],\n",
      "        [0.0400],\n",
      "        [0.0724],\n",
      "        [0.0250],\n",
      "        [0.0524],\n",
      "        [0.0089],\n",
      "        [0.0779],\n",
      "        [0.0032],\n",
      "        [0.0002],\n",
      "        [0.0055],\n",
      "        [0.0095],\n",
      "        [0.0172],\n",
      "        [0.1070],\n",
      "        [0.0276],\n",
      "        [0.0431],\n",
      "        [0.0629],\n",
      "        [0.0670],\n",
      "        [0.0279],\n",
      "        [0.0897],\n",
      "        [0.0824],\n",
      "        [0.0514],\n",
      "        [0.0750],\n",
      "        [0.0598],\n",
      "        [0.0606],\n",
      "        [0.0910],\n",
      "        [0.0876],\n",
      "        [0.0746],\n",
      "        [0.0758],\n",
      "        [0.1049],\n",
      "        [0.0761],\n",
      "        [0.0831],\n",
      "        [0.0867],\n",
      "        [0.1004],\n",
      "        [0.1076],\n",
      "        [0.1845],\n",
      "        [0.0091],\n",
      "        [0.0307],\n",
      "        [0.0102],\n",
      "        [0.0341],\n",
      "        [0.0181],\n",
      "        [0.0074],\n",
      "        [0.0395],\n",
      "        [0.0462],\n",
      "        [0.0433],\n",
      "        [0.0377],\n",
      "        [0.0054],\n",
      "        [0.0704],\n",
      "        [0.0575],\n",
      "        [0.0346],\n",
      "        [0.0241],\n",
      "        [0.0166],\n",
      "        [0.0144],\n",
      "        [0.0116],\n",
      "        [0.0697],\n",
      "        [0.0086],\n",
      "        [0.0063],\n",
      "        [0.0044],\n",
      "        [0.0103],\n",
      "        [0.0093],\n",
      "        [0.0291],\n",
      "        [0.0300],\n",
      "        [0.0484],\n",
      "        [0.0535],\n",
      "        [0.0508],\n",
      "        [0.0541],\n",
      "        [0.0645],\n",
      "        [0.0648],\n",
      "        [0.0707],\n",
      "        [0.0730]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 78\n",
      "Number of shrink: 22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0063],\n",
      "        [0.0364],\n",
      "        [0.0484],\n",
      "        [0.0879],\n",
      "        [0.0783],\n",
      "        [0.0497],\n",
      "        [0.0472],\n",
      "        [0.0371],\n",
      "        [0.0029],\n",
      "        [0.0222],\n",
      "        [0.0448],\n",
      "        [0.0240],\n",
      "        [0.0385],\n",
      "        [0.0371],\n",
      "        [0.0464],\n",
      "        [0.0990],\n",
      "        [0.0853],\n",
      "        [0.0603],\n",
      "        [0.0882],\n",
      "        [0.0848],\n",
      "        [0.0283],\n",
      "        [0.0876],\n",
      "        [0.0493],\n",
      "        [0.0140],\n",
      "        [0.0824],\n",
      "        [0.0623],\n",
      "        [0.0622],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0427],\n",
      "        [0.0423],\n",
      "        [0.0395],\n",
      "        [0.0719],\n",
      "        [0.0245],\n",
      "        [0.0518],\n",
      "        [0.0084],\n",
      "        [0.0774],\n",
      "        [0.0027],\n",
      "        [0.0007],\n",
      "        [0.0060],\n",
      "        [0.0100],\n",
      "        [0.0177],\n",
      "        [0.1076],\n",
      "        [0.0281],\n",
      "        [0.0436],\n",
      "        [0.0634],\n",
      "        [0.0675],\n",
      "        [0.0284],\n",
      "        [0.0902],\n",
      "        [0.0829],\n",
      "        [0.0519],\n",
      "        [0.0755],\n",
      "        [0.0603],\n",
      "        [0.0611],\n",
      "        [0.0915],\n",
      "        [0.0881],\n",
      "        [0.0751],\n",
      "        [0.0763],\n",
      "        [0.1054],\n",
      "        [0.0766],\n",
      "        [0.0836],\n",
      "        [0.0872],\n",
      "        [0.1009],\n",
      "        [0.1081],\n",
      "        [0.1840],\n",
      "        [0.0086],\n",
      "        [0.0302],\n",
      "        [0.0089],\n",
      "        [0.0328],\n",
      "        [0.0168],\n",
      "        [0.0058],\n",
      "        [0.0413],\n",
      "        [0.0484],\n",
      "        [0.0455],\n",
      "        [0.0399],\n",
      "        [0.0076],\n",
      "        [0.0730],\n",
      "        [0.0601],\n",
      "        [0.0372],\n",
      "        [0.0267],\n",
      "        [0.0188],\n",
      "        [0.0170],\n",
      "        [0.0141],\n",
      "        [0.0722],\n",
      "        [0.0063],\n",
      "        [0.0038],\n",
      "        [0.0018],\n",
      "        [0.0077],\n",
      "        [0.0068],\n",
      "        [0.0267],\n",
      "        [0.0276],\n",
      "        [0.0460],\n",
      "        [0.0516],\n",
      "        [0.0483],\n",
      "        [0.0515],\n",
      "        [0.0620],\n",
      "        [0.0621],\n",
      "        [0.0680],\n",
      "        [0.0706]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 20.891446828842163\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 100\n",
      "剩餘X 資料 torch.Size([7, 18])\n",
      "剩餘Y 資料 torch.Size([7, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005736752413213253, 1)\n",
      "The second_loss value of k: (0.009259588085114956, 0)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.6585])\n",
      "目前模型的Data狀態 torch.Size([100, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8918],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8833],\n",
      "        [0.8685],\n",
      "        [0.8523],\n",
      "        [0.7994],\n",
      "        [0.7754],\n",
      "        [0.7122],\n",
      "        [0.7131],\n",
      "        [0.7064],\n",
      "        [0.7379],\n",
      "        [0.6625],\n",
      "        [0.6566],\n",
      "        [0.6746],\n",
      "        [0.6894],\n",
      "        [0.7030],\n",
      "        [0.6864],\n",
      "        [0.6915],\n",
      "        [0.6620],\n",
      "        [0.7525],\n",
      "        [0.7116],\n",
      "        [0.6629],\n",
      "        [0.6992],\n",
      "        [0.6621],\n",
      "        [0.7317],\n",
      "        [0.6906],\n",
      "        [0.7410],\n",
      "        [0.7555],\n",
      "        [0.6719],\n",
      "        [0.6849],\n",
      "        [0.7456],\n",
      "        [0.6835],\n",
      "        [0.6823],\n",
      "        [0.7477],\n",
      "        [0.7342]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0063],\n",
      "        [0.0364],\n",
      "        [0.0484],\n",
      "        [0.0879],\n",
      "        [0.0783],\n",
      "        [0.0497],\n",
      "        [0.0472],\n",
      "        [0.0371],\n",
      "        [0.0029],\n",
      "        [0.0222],\n",
      "        [0.0448],\n",
      "        [0.0240],\n",
      "        [0.0385],\n",
      "        [0.0371],\n",
      "        [0.0464],\n",
      "        [0.0990],\n",
      "        [0.0853],\n",
      "        [0.0603],\n",
      "        [0.0882],\n",
      "        [0.0848],\n",
      "        [0.0283],\n",
      "        [0.0876],\n",
      "        [0.0493],\n",
      "        [0.0140],\n",
      "        [0.0824],\n",
      "        [0.0623],\n",
      "        [0.0622],\n",
      "        [0.0486],\n",
      "        [0.0456],\n",
      "        [0.0427],\n",
      "        [0.0423],\n",
      "        [0.0395],\n",
      "        [0.0719],\n",
      "        [0.0245],\n",
      "        [0.0518],\n",
      "        [0.0084],\n",
      "        [0.0774],\n",
      "        [0.0027],\n",
      "        [0.0007],\n",
      "        [0.0060],\n",
      "        [0.0100],\n",
      "        [0.0177],\n",
      "        [0.1076],\n",
      "        [0.0281],\n",
      "        [0.0436],\n",
      "        [0.0634],\n",
      "        [0.0675],\n",
      "        [0.0284],\n",
      "        [0.0902],\n",
      "        [0.0829],\n",
      "        [0.0519],\n",
      "        [0.0755],\n",
      "        [0.0603],\n",
      "        [0.0611],\n",
      "        [0.0915],\n",
      "        [0.0881],\n",
      "        [0.0751],\n",
      "        [0.0763],\n",
      "        [0.1054],\n",
      "        [0.0766],\n",
      "        [0.0836],\n",
      "        [0.0872],\n",
      "        [0.1009],\n",
      "        [0.1081],\n",
      "        [0.1840],\n",
      "        [0.0086],\n",
      "        [0.0302],\n",
      "        [0.0089],\n",
      "        [0.0328],\n",
      "        [0.0168],\n",
      "        [0.0058],\n",
      "        [0.0413],\n",
      "        [0.0484],\n",
      "        [0.0455],\n",
      "        [0.0399],\n",
      "        [0.0076],\n",
      "        [0.0730],\n",
      "        [0.0601],\n",
      "        [0.0372],\n",
      "        [0.0267],\n",
      "        [0.0188],\n",
      "        [0.0170],\n",
      "        [0.0141],\n",
      "        [0.0722],\n",
      "        [0.0063],\n",
      "        [0.0038],\n",
      "        [0.0018],\n",
      "        [0.0077],\n",
      "        [0.0068],\n",
      "        [0.0267],\n",
      "        [0.0276],\n",
      "        [0.0460],\n",
      "        [0.0516],\n",
      "        [0.0483],\n",
      "        [0.0515],\n",
      "        [0.0620],\n",
      "        [0.0621],\n",
      "        [0.0680],\n",
      "        [0.0706],\n",
      "        [0.0757]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0063],\n",
      "        [    0.0364],\n",
      "        [    0.0484],\n",
      "        [    0.0880],\n",
      "        [    0.0784],\n",
      "        [    0.0498],\n",
      "        [    0.0472],\n",
      "        [    0.0371],\n",
      "        [    0.0030],\n",
      "        [    0.0222],\n",
      "        [    0.0448],\n",
      "        [    0.0240],\n",
      "        [    0.0386],\n",
      "        [    0.0371],\n",
      "        [    0.0465],\n",
      "        [    0.0990],\n",
      "        [    0.0854],\n",
      "        [    0.0604],\n",
      "        [    0.0883],\n",
      "        [    0.0848],\n",
      "        [    0.0284],\n",
      "        [    0.0876],\n",
      "        [    0.0494],\n",
      "        [    0.0140],\n",
      "        [    0.0825],\n",
      "        [    0.0624],\n",
      "        [    0.0623],\n",
      "        [    0.0486],\n",
      "        [    0.0456],\n",
      "        [    0.0427],\n",
      "        [    0.0423],\n",
      "        [    0.0395],\n",
      "        [    0.0719],\n",
      "        [    0.0245],\n",
      "        [    0.0519],\n",
      "        [    0.0084],\n",
      "        [    0.0775],\n",
      "        [    0.0027],\n",
      "        [    0.0007],\n",
      "        [    0.0059],\n",
      "        [    0.0099],\n",
      "        [    0.0177],\n",
      "        [    0.1076],\n",
      "        [    0.0281],\n",
      "        [    0.0435],\n",
      "        [    0.0633],\n",
      "        [    0.0675],\n",
      "        [    0.0284],\n",
      "        [    0.0902],\n",
      "        [    0.0828],\n",
      "        [    0.0519],\n",
      "        [    0.0754],\n",
      "        [    0.0602],\n",
      "        [    0.0611],\n",
      "        [    0.0914],\n",
      "        [    0.0881],\n",
      "        [    0.0750],\n",
      "        [    0.0763],\n",
      "        [    0.1054],\n",
      "        [    0.0766],\n",
      "        [    0.0836],\n",
      "        [    0.0871],\n",
      "        [    0.1008],\n",
      "        [    0.1081],\n",
      "        [    0.1840],\n",
      "        [    0.0086],\n",
      "        [    0.0303],\n",
      "        [    0.0079],\n",
      "        [    0.0318],\n",
      "        [    0.0157],\n",
      "        [    0.0043],\n",
      "        [    0.0429],\n",
      "        [    0.0503],\n",
      "        [    0.0475],\n",
      "        [    0.0418],\n",
      "        [    0.0095],\n",
      "        [    0.0749],\n",
      "        [    0.0622],\n",
      "        [    0.0392],\n",
      "        [    0.0289],\n",
      "        [    0.0207],\n",
      "        [    0.0191],\n",
      "        [    0.0163],\n",
      "        [    0.0742],\n",
      "        [    0.0042],\n",
      "        [    0.0017],\n",
      "        [    0.0001],\n",
      "        [    0.0056],\n",
      "        [    0.0049],\n",
      "        [    0.0247],\n",
      "        [    0.0255],\n",
      "        [    0.0440],\n",
      "        [    0.0500],\n",
      "        [    0.0463],\n",
      "        [    0.0493],\n",
      "        [    0.0599],\n",
      "        [    0.0598],\n",
      "        [    0.0657],\n",
      "        [    0.0685],\n",
      "        [    0.0737]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 21.1222882270813\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 101\n",
      "剩餘X 資料 torch.Size([6, 18])\n",
      "剩餘Y 資料 torch.Size([6, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.008921308442950249, 0)\n",
      "The second_loss value of k: (0.009650609456002712, 2)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引0，y= tensor([0.6492])\n",
      "目前模型的Data狀態 torch.Size([101, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8918],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8919],\n",
      "        [0.8822],\n",
      "        [0.8674],\n",
      "        [0.8512],\n",
      "        [0.7979],\n",
      "        [0.7737],\n",
      "        [0.7103],\n",
      "        [0.7111],\n",
      "        [0.7045],\n",
      "        [0.7360],\n",
      "        [0.6606],\n",
      "        [0.6546],\n",
      "        [0.6725],\n",
      "        [0.6872],\n",
      "        [0.7010],\n",
      "        [0.6843],\n",
      "        [0.6894],\n",
      "        [0.6601],\n",
      "        [0.7504],\n",
      "        [0.7095],\n",
      "        [0.6609],\n",
      "        [0.6970],\n",
      "        [0.6602],\n",
      "        [0.7297],\n",
      "        [0.6886],\n",
      "        [0.7390],\n",
      "        [0.7538],\n",
      "        [0.6699],\n",
      "        [0.6828],\n",
      "        [0.7435],\n",
      "        [0.6811],\n",
      "        [0.6800],\n",
      "        [0.7457],\n",
      "        [0.7321],\n",
      "        [0.7437]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0063],\n",
      "        [    0.0364],\n",
      "        [    0.0484],\n",
      "        [    0.0880],\n",
      "        [    0.0784],\n",
      "        [    0.0498],\n",
      "        [    0.0472],\n",
      "        [    0.0371],\n",
      "        [    0.0030],\n",
      "        [    0.0222],\n",
      "        [    0.0448],\n",
      "        [    0.0240],\n",
      "        [    0.0386],\n",
      "        [    0.0371],\n",
      "        [    0.0465],\n",
      "        [    0.0990],\n",
      "        [    0.0854],\n",
      "        [    0.0604],\n",
      "        [    0.0883],\n",
      "        [    0.0848],\n",
      "        [    0.0284],\n",
      "        [    0.0876],\n",
      "        [    0.0494],\n",
      "        [    0.0140],\n",
      "        [    0.0825],\n",
      "        [    0.0624],\n",
      "        [    0.0623],\n",
      "        [    0.0486],\n",
      "        [    0.0456],\n",
      "        [    0.0427],\n",
      "        [    0.0423],\n",
      "        [    0.0395],\n",
      "        [    0.0719],\n",
      "        [    0.0245],\n",
      "        [    0.0519],\n",
      "        [    0.0084],\n",
      "        [    0.0775],\n",
      "        [    0.0027],\n",
      "        [    0.0007],\n",
      "        [    0.0059],\n",
      "        [    0.0099],\n",
      "        [    0.0177],\n",
      "        [    0.1076],\n",
      "        [    0.0281],\n",
      "        [    0.0435],\n",
      "        [    0.0633],\n",
      "        [    0.0675],\n",
      "        [    0.0284],\n",
      "        [    0.0902],\n",
      "        [    0.0828],\n",
      "        [    0.0519],\n",
      "        [    0.0754],\n",
      "        [    0.0602],\n",
      "        [    0.0611],\n",
      "        [    0.0914],\n",
      "        [    0.0881],\n",
      "        [    0.0750],\n",
      "        [    0.0763],\n",
      "        [    0.1054],\n",
      "        [    0.0766],\n",
      "        [    0.0836],\n",
      "        [    0.0871],\n",
      "        [    0.1008],\n",
      "        [    0.1081],\n",
      "        [    0.1840],\n",
      "        [    0.0086],\n",
      "        [    0.0303],\n",
      "        [    0.0079],\n",
      "        [    0.0318],\n",
      "        [    0.0157],\n",
      "        [    0.0043],\n",
      "        [    0.0429],\n",
      "        [    0.0503],\n",
      "        [    0.0475],\n",
      "        [    0.0418],\n",
      "        [    0.0095],\n",
      "        [    0.0749],\n",
      "        [    0.0622],\n",
      "        [    0.0392],\n",
      "        [    0.0289],\n",
      "        [    0.0207],\n",
      "        [    0.0191],\n",
      "        [    0.0163],\n",
      "        [    0.0742],\n",
      "        [    0.0042],\n",
      "        [    0.0017],\n",
      "        [    0.0001],\n",
      "        [    0.0056],\n",
      "        [    0.0049],\n",
      "        [    0.0247],\n",
      "        [    0.0255],\n",
      "        [    0.0440],\n",
      "        [    0.0500],\n",
      "        [    0.0463],\n",
      "        [    0.0493],\n",
      "        [    0.0599],\n",
      "        [    0.0598],\n",
      "        [    0.0657],\n",
      "        [    0.0685],\n",
      "        [    0.0737],\n",
      "        [    0.0945]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0064],\n",
      "        [0.0366],\n",
      "        [0.0482],\n",
      "        [0.0878],\n",
      "        [0.0782],\n",
      "        [0.0496],\n",
      "        [0.0470],\n",
      "        [0.0372],\n",
      "        [0.0028],\n",
      "        [0.0224],\n",
      "        [0.0449],\n",
      "        [0.0242],\n",
      "        [0.0384],\n",
      "        [0.0370],\n",
      "        [0.0463],\n",
      "        [0.0989],\n",
      "        [0.0852],\n",
      "        [0.0602],\n",
      "        [0.0881],\n",
      "        [0.0850],\n",
      "        [0.0282],\n",
      "        [0.0875],\n",
      "        [0.0492],\n",
      "        [0.0142],\n",
      "        [0.0823],\n",
      "        [0.0622],\n",
      "        [0.0621],\n",
      "        [0.0485],\n",
      "        [0.0455],\n",
      "        [0.0425],\n",
      "        [0.0422],\n",
      "        [0.0393],\n",
      "        [0.0718],\n",
      "        [0.0243],\n",
      "        [0.0517],\n",
      "        [0.0083],\n",
      "        [0.0773],\n",
      "        [0.0025],\n",
      "        [0.0008],\n",
      "        [0.0061],\n",
      "        [0.0101],\n",
      "        [0.0179],\n",
      "        [0.1087],\n",
      "        [0.0282],\n",
      "        [0.0437],\n",
      "        [0.0635],\n",
      "        [0.0676],\n",
      "        [0.0285],\n",
      "        [0.0904],\n",
      "        [0.0830],\n",
      "        [0.0520],\n",
      "        [0.0756],\n",
      "        [0.0604],\n",
      "        [0.0613],\n",
      "        [0.0916],\n",
      "        [0.0883],\n",
      "        [0.0752],\n",
      "        [0.0764],\n",
      "        [0.1055],\n",
      "        [0.0767],\n",
      "        [0.0838],\n",
      "        [0.0873],\n",
      "        [0.1010],\n",
      "        [0.1083],\n",
      "        [0.1838],\n",
      "        [0.0084],\n",
      "        [0.0301],\n",
      "        [0.0057],\n",
      "        [0.0298],\n",
      "        [0.0136],\n",
      "        [0.0019],\n",
      "        [0.0455],\n",
      "        [0.0528],\n",
      "        [0.0501],\n",
      "        [0.0443],\n",
      "        [0.0121],\n",
      "        [0.0773],\n",
      "        [0.0646],\n",
      "        [0.0417],\n",
      "        [0.0316],\n",
      "        [0.0233],\n",
      "        [0.0217],\n",
      "        [0.0189],\n",
      "        [0.0765],\n",
      "        [0.0013],\n",
      "        [0.0008],\n",
      "        [0.0025],\n",
      "        [0.0030],\n",
      "        [0.0027],\n",
      "        [0.0222],\n",
      "        [0.0229],\n",
      "        [0.0415],\n",
      "        [0.0474],\n",
      "        [0.0441],\n",
      "        [0.0469],\n",
      "        [0.0574],\n",
      "        [0.0569],\n",
      "        [0.0629],\n",
      "        [0.0661],\n",
      "        [0.0707],\n",
      "        [0.0917]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 21.351288080215454\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 102\n",
      "剩餘X 資料 torch.Size([5, 18])\n",
      "剩餘Y 資料 torch.Size([5, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.009174085222184658, 1)\n",
      "The second_loss value of k: (0.015517019666731358, 3)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引1，y= tensor([0.6597])\n",
      "目前模型的Data狀態 torch.Size([102, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8907],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8917],\n",
      "        [0.8801],\n",
      "        [0.8654],\n",
      "        [0.8491],\n",
      "        [0.7955],\n",
      "        [0.7711],\n",
      "        [0.7078],\n",
      "        [0.7085],\n",
      "        [0.7019],\n",
      "        [0.7335],\n",
      "        [0.6582],\n",
      "        [0.6522],\n",
      "        [0.6701],\n",
      "        [0.6845],\n",
      "        [0.6985],\n",
      "        [0.6817],\n",
      "        [0.6867],\n",
      "        [0.6578],\n",
      "        [0.7474],\n",
      "        [0.7069],\n",
      "        [0.6586],\n",
      "        [0.6944],\n",
      "        [0.6580],\n",
      "        [0.7273],\n",
      "        [0.6859],\n",
      "        [0.7366],\n",
      "        [0.7512],\n",
      "        [0.6676],\n",
      "        [0.6804],\n",
      "        [0.7410],\n",
      "        [0.6782],\n",
      "        [0.6773],\n",
      "        [0.7432],\n",
      "        [0.7292],\n",
      "        [0.7410],\n",
      "        [0.7555]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0064],\n",
      "        [0.0366],\n",
      "        [0.0482],\n",
      "        [0.0878],\n",
      "        [0.0782],\n",
      "        [0.0496],\n",
      "        [0.0470],\n",
      "        [0.0372],\n",
      "        [0.0028],\n",
      "        [0.0224],\n",
      "        [0.0449],\n",
      "        [0.0242],\n",
      "        [0.0384],\n",
      "        [0.0370],\n",
      "        [0.0463],\n",
      "        [0.0989],\n",
      "        [0.0852],\n",
      "        [0.0602],\n",
      "        [0.0881],\n",
      "        [0.0850],\n",
      "        [0.0282],\n",
      "        [0.0875],\n",
      "        [0.0492],\n",
      "        [0.0142],\n",
      "        [0.0823],\n",
      "        [0.0622],\n",
      "        [0.0621],\n",
      "        [0.0485],\n",
      "        [0.0455],\n",
      "        [0.0425],\n",
      "        [0.0422],\n",
      "        [0.0393],\n",
      "        [0.0718],\n",
      "        [0.0243],\n",
      "        [0.0517],\n",
      "        [0.0083],\n",
      "        [0.0773],\n",
      "        [0.0025],\n",
      "        [0.0008],\n",
      "        [0.0061],\n",
      "        [0.0101],\n",
      "        [0.0179],\n",
      "        [0.1087],\n",
      "        [0.0282],\n",
      "        [0.0437],\n",
      "        [0.0635],\n",
      "        [0.0676],\n",
      "        [0.0285],\n",
      "        [0.0904],\n",
      "        [0.0830],\n",
      "        [0.0520],\n",
      "        [0.0756],\n",
      "        [0.0604],\n",
      "        [0.0613],\n",
      "        [0.0916],\n",
      "        [0.0883],\n",
      "        [0.0752],\n",
      "        [0.0764],\n",
      "        [0.1055],\n",
      "        [0.0767],\n",
      "        [0.0838],\n",
      "        [0.0873],\n",
      "        [0.1010],\n",
      "        [0.1083],\n",
      "        [0.1838],\n",
      "        [0.0084],\n",
      "        [0.0301],\n",
      "        [0.0057],\n",
      "        [0.0298],\n",
      "        [0.0136],\n",
      "        [0.0019],\n",
      "        [0.0455],\n",
      "        [0.0528],\n",
      "        [0.0501],\n",
      "        [0.0443],\n",
      "        [0.0121],\n",
      "        [0.0773],\n",
      "        [0.0646],\n",
      "        [0.0417],\n",
      "        [0.0316],\n",
      "        [0.0233],\n",
      "        [0.0217],\n",
      "        [0.0189],\n",
      "        [0.0765],\n",
      "        [0.0013],\n",
      "        [0.0008],\n",
      "        [0.0025],\n",
      "        [0.0030],\n",
      "        [0.0027],\n",
      "        [0.0222],\n",
      "        [0.0229],\n",
      "        [0.0415],\n",
      "        [0.0474],\n",
      "        [0.0441],\n",
      "        [0.0469],\n",
      "        [0.0574],\n",
      "        [0.0569],\n",
      "        [0.0629],\n",
      "        [0.0661],\n",
      "        [0.0707],\n",
      "        [0.0917],\n",
      "        [0.0958]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.2\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.2\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 79\n",
      "Number of shrink: 21\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0062],\n",
      "        [0.0364],\n",
      "        [0.0484],\n",
      "        [0.0880],\n",
      "        [0.0784],\n",
      "        [0.0498],\n",
      "        [0.0472],\n",
      "        [0.0371],\n",
      "        [0.0030],\n",
      "        [0.0222],\n",
      "        [0.0448],\n",
      "        [0.0240],\n",
      "        [0.0386],\n",
      "        [0.0372],\n",
      "        [0.0465],\n",
      "        [0.0990],\n",
      "        [0.0854],\n",
      "        [0.0604],\n",
      "        [0.0883],\n",
      "        [0.0848],\n",
      "        [0.0284],\n",
      "        [0.0876],\n",
      "        [0.0494],\n",
      "        [0.0140],\n",
      "        [0.0825],\n",
      "        [0.0624],\n",
      "        [0.0623],\n",
      "        [0.0486],\n",
      "        [0.0457],\n",
      "        [0.0427],\n",
      "        [0.0423],\n",
      "        [0.0395],\n",
      "        [0.0719],\n",
      "        [0.0245],\n",
      "        [0.0519],\n",
      "        [0.0084],\n",
      "        [0.0775],\n",
      "        [0.0027],\n",
      "        [0.0007],\n",
      "        [0.0059],\n",
      "        [0.0099],\n",
      "        [0.0177],\n",
      "        [0.1084],\n",
      "        [0.0281],\n",
      "        [0.0435],\n",
      "        [0.0633],\n",
      "        [0.0675],\n",
      "        [0.0284],\n",
      "        [0.0902],\n",
      "        [0.0828],\n",
      "        [0.0519],\n",
      "        [0.0754],\n",
      "        [0.0602],\n",
      "        [0.0611],\n",
      "        [0.0914],\n",
      "        [0.0881],\n",
      "        [0.0750],\n",
      "        [0.0763],\n",
      "        [0.1053],\n",
      "        [0.0766],\n",
      "        [0.0836],\n",
      "        [0.0871],\n",
      "        [0.1008],\n",
      "        [0.1081],\n",
      "        [0.1840],\n",
      "        [0.0086],\n",
      "        [0.0303],\n",
      "        [0.0049],\n",
      "        [0.0290],\n",
      "        [0.0128],\n",
      "        [0.0008],\n",
      "        [0.0467],\n",
      "        [0.0540],\n",
      "        [0.0514],\n",
      "        [0.0456],\n",
      "        [0.0134],\n",
      "        [0.0784],\n",
      "        [0.0657],\n",
      "        [0.0429],\n",
      "        [0.0331],\n",
      "        [0.0246],\n",
      "        [0.0230],\n",
      "        [0.0204],\n",
      "        [0.0776],\n",
      "        [0.0004],\n",
      "        [0.0022],\n",
      "        [0.0036],\n",
      "        [0.0016],\n",
      "        [0.0017],\n",
      "        [0.0209],\n",
      "        [0.0216],\n",
      "        [0.0402],\n",
      "        [0.0462],\n",
      "        [0.0430],\n",
      "        [0.0456],\n",
      "        [0.0560],\n",
      "        [0.0554],\n",
      "        [0.0615],\n",
      "        [0.0646],\n",
      "        [0.0692],\n",
      "        [0.0904],\n",
      "        [0.0943]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.2\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 21.582093477249146\n",
      "------------------------------------------------------------------------------------------\n",
      "到第 1 個區塊累積花費時間(s) 21.58174777030945\n",
      "<<The performance of 1 block>>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluation_table_outlier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-1383cac25dd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;31m#     print(\"<<The performance of %d block>>\"%(len(splits)+i_block+1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0mevaluation_table_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation_table_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_step4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_step6_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_step6_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_block\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluation_table_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluation_table_outlier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluation_table_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mevaluation_table_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_table_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluation_table_outlier' is not defined"
     ]
    }
   ],
   "source": [
    "evaluation_table_train = pd.DataFrame(columns=[\"Window_index\",\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "evaluation_results_outlier = pd.DataFrame(columns=[\"Window_index\",\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "evaluation_table_test = pd.DataFrame(columns=[\"Window_index\",\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "    \n",
    "x_data, y_data= get_data(4)\n",
    "x_data = sc.fit_transform(x_data)\n",
    "y_data = sc.fit_transform(y_data[:,0].reshape(-1,1))\n",
    "threshold_for_error = 5000/(sc.data_max_-sc.data_min_)\n",
    "\n",
    "data = range(x_data.shape[0])\n",
    "# window_size => the length of training block\n",
    "window_size = 106\n",
    "# step_window => step size of each window\n",
    "step_window = 26\n",
    "# the split data\n",
    "splits = []\n",
    "\n",
    "## Moving window mechnism\n",
    "for i in range(window_size, len(data), step_window):\n",
    "    train = np.array(data[i-window_size:i])\n",
    "    test = np.array(data[i-window_size:i+step_window])\n",
    "#     test = np.array(data[i:i+step_window])\n",
    "    splits.append(('TRAIN:', train, 'TEST:', test))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i_block in range(len(splits)):\n",
    "# for i_block in range(-2,0,1):\n",
    "# for i_block in range(2):\n",
    "    block_start = time.time()\n",
    "    ## Record the number of each step\n",
    "    nb_step4 = 0\n",
    "    nb_step6_1 = 0\n",
    "    nb_step6_2 = 0\n",
    "    \n",
    "    print(\"The <<%d>> Block\" %(i_block+1))\n",
    "#     print(\"The <<%d>> Block\" %(len(splits)+i_block+1))\n",
    "#     print(\"The training block\\n\", y_data[splits[i_block][1]])\n",
    "#     print(\"The testing block\\n\", y_data[splits[i_block][3]])\n",
    "    \n",
    "    x_train = x_data[splits[i_block][1]]\n",
    "    x_test = x_data[splits[i_block][3]]\n",
    "    y_train = y_data[splits[i_block][1]]\n",
    "    y_test = y_data[splits[i_block][3]]\n",
    "    \n",
    "    x_train_scaled = torch.FloatTensor(x_train)\n",
    "    x_test_scaled = torch.FloatTensor(x_test)\n",
    "    y_train_scaled = torch.FloatTensor(y_train)\n",
    "    y_test = sc.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "#     if i_block == -2:\n",
    "    if i_block == 0:\n",
    "        lower = torch.mean(y_train_scaled)-torch.std(y_train_scaled)\n",
    "        upper = torch.mean(y_train_scaled)+torch.std(y_train_scaled)\n",
    "        nonoutlier_index = torch.nonzero((y_train_scaled[:,0]>lower)&(y_train_scaled[:,0]<upper)).reshape([-1])\n",
    "        \n",
    "        initial_x = x_train_scaled[nonoutlier_index[:19]]\n",
    "        initial_y = y_train_scaled[nonoutlier_index[:19]]\n",
    "        \n",
    "        x_train_scaled = np.delete(x_train_scaled, nonoutlier_index[:19], 0)\n",
    "        y_train_scaled = np.delete(y_train_scaled, nonoutlier_index[:19], 0)\n",
    "#         print(initial_x.shape[0])\n",
    "        \n",
    "        network = Network(1,initial_x,initial_y)\n",
    "        \n",
    "        network.nb_node_acceptable = torch.IntTensor([1 for _ in range(initial_x.shape[0])])\n",
    "        network.threshold_for_error = round(threshold_for_error[0],2)\n",
    "        \n",
    "        initializing(network, initial_x, initial_y)\n",
    "        \n",
    "        print(\"<<Initializing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(network.y-yo))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        remainder = int(window_size*0.9624) - initial_x.shape[0]\n",
    "    \n",
    "    else:\n",
    "#         print(\"新的Code待驗證\")\n",
    "#         print(network.state_dict())\n",
    "        sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "        restart_index = int(x_train_scaled.shape[0]*0.9624)-step_window\n",
    "        print(\"其他區塊剛開始選的資料索引：\",sorted_index[:restart_index])\n",
    "        init_x = x_train_scaled[sorted_index[:int(x_train_scaled.shape[0]*0.9624)-step_window]].reshape(-1,x_train_scaled.shape[1])\n",
    "        init_y = y_train_scaled[sorted_index[:int(x_train_scaled.shape[0]*0.9624)-step_window]].reshape(-1,1)\n",
    "#         print(\"取得的x\",init_x.shape)\n",
    "#         print(\"取得的y\",init_y.shape)\n",
    "#         print(\"前\")\n",
    "#         print(network.y.shape)\n",
    "        network.setData(init_x, init_y)\n",
    "#         print(\"後\")\n",
    "#         print(network.y.shape)\n",
    "        network.nb_node_acceptable = torch.IntTensor([network.linear1.bias.data.shape[0] for _ in range(init_x.shape[0])])\n",
    "        network.nb_node_pruned = 0\n",
    "        \n",
    "        print(\"<<其他區塊剛開始時看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(network.y-yo))\n",
    "        \n",
    "        remainder = int(window_size*0.9624) - init_x.shape[0]\n",
    "        x_train_scaled = np.delete(x_train_scaled, sorted_index[:restart_index], 0)\n",
    "        y_train_scaled = np.delete(y_train_scaled, sorted_index[:restart_index], 0)\n",
    "        \n",
    "#         print(\"X 資料\",x_train_scaled.shape)\n",
    "#         print(\"Y 資料\",y_train_scaled.shape)\n",
    "#     network.limit = network.linear1.bias.data.shape[0]\n",
    "#     print(\"Limit for node pruned:\",network.limit)\n",
    "    \n",
    "#     for i in range(int(x_train_scaled.shape[0]*0.9624)):\n",
    "#     for i in range(2):\n",
    "    for i in range(remainder):\n",
    "#         if i_block == -2:\n",
    "        if i_block == 0:\n",
    "            print(\"現在訓練到第幾筆資料: %d\"%(i+x_train_scaled.shape[1]+2))\n",
    "        \n",
    "        else:\n",
    "            print(\"現在訓練到第幾筆資料: %d\"%(restart_index+i+1))\n",
    "        \n",
    "        print(\"剩餘X 資料\",x_train_scaled.shape)\n",
    "        print(\"剩餘Y 資料\",y_train_scaled.shape)\n",
    "        \n",
    "        sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "        \n",
    "\n",
    "        ## Add new data for training\n",
    "        \n",
    "        print(\"現在要進去模型的數據，索引%d，y=\"%(sorted_index[0]),y_train_scaled[sorted_index[0]].data)        \n",
    "        network.addData(x_train_scaled[sorted_index[0]], y_train_scaled[sorted_index[0]])\n",
    "        print(\"目前模型的Data狀態\",network.y.shape)\n",
    "        x_train_scaled = np.delete(x_train_scaled, sorted_index[0], 0)\n",
    "        y_train_scaled = np.delete(y_train_scaled, sorted_index[0], 0)\n",
    "        \n",
    "        yo,loss = network.forward()\n",
    "        print(\"<<預測值>>\")\n",
    "        print(yo)\n",
    "        print(\"<<差異>>\")\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        print(\"Loss值\")\n",
    "        print(loss)\n",
    "\n",
    "        pre_network = copy.deepcopy(network)\n",
    "        \n",
    "        if not torch.all(torch.abs(network.y-yo)<=network.threshold_for_error):\n",
    "\n",
    "            network.acceptable = False\n",
    "            network = matching(network)\n",
    "            \n",
    "            print(\"<<Matching後看一下差異>>\")\n",
    "            yo,loss = network.forward()\n",
    "            print(torch.abs(yo-network.y))\n",
    "            print(\"threshold_for_error:\",threshold_for_error)\n",
    "            \n",
    "            if network.acceptable == False:\n",
    "                \n",
    "                network = copy.deepcopy(pre_network)\n",
    "                cramming(network)\n",
    "\n",
    "                if network.acceptable == False:\n",
    "                    sys.exit(0)  \n",
    "                \n",
    "                print(\"<<Cramming後看一下差異>>\")\n",
    "                yo,loss = network.forward()\n",
    "                print(torch.abs(yo-network.y))\n",
    "                print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "                nb_step6_2 += 1\n",
    "\n",
    "            else:\n",
    "                nb_step6_1 += 1\n",
    "\n",
    "        else:\n",
    "            nb_step4 += 1\n",
    "\n",
    "        network = reorganizing(network)\n",
    "        print(\"<<Reorganizing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        \n",
    "        network.nb_node_acceptable = torch.cat([network.nb_node_acceptable, torch.IntTensor([network.linear1.bias.data.shape[0]])],0)\n",
    "        print(\"看一下 hidden node\")\n",
    "        print(network.nb_node_acceptable)\n",
    "       \n",
    "        print(\"使用裝置\",(list(network.parameters())[0].device))\n",
    "        print(\"累計時間(s)\",time.time()-start)\n",
    "#         print(network.state_dict())\n",
    "        print(\"-\"*90)\n",
    "\n",
    "    \n",
    "    block_end = time.time()\n",
    "    print(\"到第 %d 個區塊累積花費時間(s)\"%(i_block+1),block_end-block_start)\n",
    "#     print(\"到第 %d 個區塊累積花費時間(s)\"%(len(splits)+i_block+1),block_end-block_start)\n",
    "    print(\"<<The performance of %d block>>\"%(i_block+1))\n",
    "#     print(\"<<The performance of %d block>>\"%(len(splits)+i_block+1))\n",
    "    \n",
    "    evaluation_table_train, evaluation_table_test = validation(network, nb_step4, nb_step6_1, nb_step6_2, x_train_scaled, y_train_scaled,x_test_scaled, y_test, block_start, block_end,i_block+1,evaluation_table_train,evaluation_table_outlier,evaluation_table_test)\n",
    "\n",
    "    evaluation_table_train.to_csv(\"evaluation_table_train.csv\",index=False)\n",
    "    evaluation_results_outlier.to_csv(\"evaluation_table_outlier.csv\",index=False)\n",
    "    evaluation_table_test.to_csv(\"evaluation_table_inferencing.csv\",index=False)\n",
    "#     validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test_scaled, y_test, block_start, block_end,(len(splits)+i_block+1))\n",
    "end = time.time()\n",
    "print(\"總計時間(s)\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<Training step>>\n",
      "The training time(s): 8.20255446434021\n",
      "<<The percentage of each step>>\n",
      "Step 4: 100.00%\n",
      "Step 6.1: 0.00%\n",
      "Step 6.2: 0.00%\n",
      "------------------------------------------------------------\n",
      "Total frequency of cramming occurrences: 0\n",
      "------------------------------------------------------------\n",
      "The amount of hidden node that be pruned: 0\n",
      "------------------------------------------------------------\n",
      "The amount of adopted hidden nodes: 1\n",
      "------------------------------------------------------------\n",
      "<<Accuracy in training step>>\n",
      "The MAE for l = 1: 795.97\n",
      "The MAPE for l = 1: 0.02%\n",
      "The RMSE for l = 1: 1027.73\n",
      "The accuracy(2000) for l = 1: 93.14%\n",
      "The accuracy(3000) for l = 1: 99.02%\n",
      "------------------------------------------------------------\n",
      "<<Accuracy in inferencing step>>\n",
      "The MAE for l = 1: 942.9\n",
      "The MAPE for l = 1: 0.0%\n",
      "The RMSE for l = 1: 1341.2\n",
      "The accuracy(2000) for l = 1: 88.8%\n",
      "The accuracy(3000) for l = 1: 96.3%\n",
      "------------------------------------------------------------\n",
      "0.9313725490196079\n",
      "<class 'float'>\n",
      "0.8878504672897196\n",
      "<class 'float'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   Window_index     Stage          MAE  MAPE         RMSE  Accuracy(2000)  \\\n",
       " 0             1  Training  1281.562012  2.30  1526.656982           78.43   \n",
       " 1             2  Training  1589.933472  3.01  2000.063721           66.67   \n",
       " 2             3  Training   938.121948  1.83  1257.778198           87.25   \n",
       " 3             4  Training   818.030762  1.71  1044.745728           95.10   \n",
       " 4             5  Training   687.015930  1.55   929.322449           94.12   \n",
       " 5             6  Training   706.388794  1.75   960.278625           96.08   \n",
       " 6             7  Training  1021.307312  2.60  1329.846802           83.33   \n",
       " 7             8  Training   901.970825  2.27  1173.317383           87.25   \n",
       " 8             9  Training  1389.728882  3.16  1730.512085           73.53   \n",
       " 9            10  Training   906.062866  1.97  1125.000000           96.08   \n",
       " 10           11  Training   867.483582  1.75  1058.692261           97.06   \n",
       " 11           12  Training   677.667603  1.35   836.252258           99.02   \n",
       " 12           13  Training   591.391357  1.20   717.017273          100.00   \n",
       " 13           14  Training   664.361511  1.40   807.362061           99.02   \n",
       " 14           15  Training   795.972595  1.70  1027.729370           93.14   \n",
       " 15           15  Training   795.972595  1.70  1027.729370           93.14   \n",
       " \n",
       "     Accuracy(3000) Step4 Step6.1 Step6.2       Time Adopted_hidden_node  \n",
       " 0            99.02    80       3       0  24.031535                   1  \n",
       " 1            86.27    24       2       0   6.543177                   1  \n",
       " 2            96.08    26       0       0   7.127621                   1  \n",
       " 3            98.04    26       0       0   6.702515                   1  \n",
       " 4            98.04    26       0       0   6.590141                   1  \n",
       " 5            98.04    26       0       0   6.928819                   1  \n",
       " 6            98.04    26       0       0   7.090002                   1  \n",
       " 7           100.00    26       0       0   7.487650                   1  \n",
       " 8            91.18    26       0       0   7.718272                   1  \n",
       " 9            99.02    26       0       0   7.912834                   1  \n",
       " 10          100.00    26       0       0   8.480737                   1  \n",
       " 11          100.00    26       0       0   8.125708                   1  \n",
       " 12          100.00    26       0       0   7.945364                   1  \n",
       " 13          100.00    26       0       0   8.299749                   1  \n",
       " 14           99.02    26       0       0   8.202554                   1  \n",
       " 15           99.02    26       0       0   8.202554                   1  ,\n",
       "    Window_index        Stage          MAE  MAPE         RMSE  Accuracy(2000)  \\\n",
       " 0             1  Inferencing  2424.801344  4.71  3527.606155           60.61   \n",
       " 1             2  Inferencing  2388.958422  4.72  3065.956069           51.52   \n",
       " 2             3  Inferencing  2260.949455  4.96  3584.908316           67.42   \n",
       " 3             4  Inferencing  1058.674154  2.41  1576.766195           88.64   \n",
       " 4             5  Inferencing   971.023793  2.39  1434.637289           87.12   \n",
       " 5             6  Inferencing  1595.055220  4.11  2564.490865           77.27   \n",
       " 6             7  Inferencing  1062.069869  2.65  1400.644641           83.33   \n",
       " 7             8  Inferencing  1659.548799  3.66  2573.776677           72.73   \n",
       " 8             9  Inferencing  2052.923088  4.31  2606.387578           56.82   \n",
       " 9            10  Inferencing  1303.634025  2.73  1684.495544           80.30   \n",
       " 10           11  Inferencing   923.752307  1.86  1146.721250           93.94   \n",
       " 11           12  Inferencing   825.947562  1.67  1068.261743           91.67   \n",
       " 12           13  Inferencing   780.831352  1.64  1035.060956           93.18   \n",
       " 13           14  Inferencing  1685.247723  3.39  2688.558673           77.27   \n",
       " 14           15  Inferencing   942.898839  1.96  1341.208585           88.79   \n",
       " 15           15  Inferencing   942.898839  1.96  1341.208585           88.79   \n",
       " \n",
       "     Accuracy(3000) Step4 Step6.1 Step6.2       Time Adopted_hidden_node  \n",
       " 0            79.55    80       3       0  24.031535                   1  \n",
       " 1            68.18    24       2       0   6.543177                   1  \n",
       " 2            75.76    26       0       0   7.127621                   1  \n",
       " 3            92.42    26       0       0   6.702515                   1  \n",
       " 4            92.42    26       0       0   6.590141                   1  \n",
       " 5            81.82    26       0       0   6.928819                   1  \n",
       " 6            95.45    26       0       0   7.090002                   1  \n",
       " 7            84.85    26       0       0   7.487650                   1  \n",
       " 8            74.24    26       0       0   7.718272                   1  \n",
       " 9            91.67    26       0       0   7.912834                   1  \n",
       " 10          100.00    26       0       0   8.480737                   1  \n",
       " 11          100.00    26       0       0   8.125708                   1  \n",
       " 12           98.48    26       0       0   7.945364                   1  \n",
       " 13           79.55    26       0       0   8.299749                   1  \n",
       " 14           96.26    26       0       0   8.202554                   1  \n",
       " 15           96.26    26       0       0   8.202554                   1  )"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test_scaled, y_test, block_start, block_end,i_block+1,evaluation_table_train,evaluation_table_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
