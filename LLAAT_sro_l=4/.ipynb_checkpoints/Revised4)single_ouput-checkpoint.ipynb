{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import related package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import tensorflow package for modeling\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "## Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Min-max normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "## Plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Initializing module\n",
    "from sklearn.linear_model import LinearRegression\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "## Copy module\n",
    "import copy\n",
    "\n",
    "## Used to calculate the training time\n",
    "import time\n",
    "\n",
    "## Set the GUP environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the display\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control memory usage space for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前設備： 0\n",
      "目前設備名： GeForce GTX 1070 Ti\n"
     ]
    }
   ],
   "source": [
    "## 查詢有無可用 GPU\n",
    "torch.cuda.is_available()\n",
    "## 查詢可用 GPU 的數量\n",
    "torch.cuda.device_count()\n",
    "##目前設備\n",
    "print(\"目前設備：\",torch.cuda.current_device())\n",
    "## 目前設備名\n",
    "print(\"目前設備名：\",torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out some info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cacl(pred_value, actual_value):\n",
    "    \n",
    "#     yo, loss, tape = network.forward()\n",
    "    performance = []\n",
    "    performance.append(torch.mean(torch.abs(pred_value - actual_value)))\n",
    "    performance.append(torch.mean(torch.abs((pred_value - actual_value) / actual_value))) \n",
    "    performance.append(torch.sqrt(torch.mean((pred_value - actual_value)**2)))\n",
    "    \n",
    "    for i in range(2000,3001,1000):\n",
    "        correct_times = torch.nonzero(torch.abs(pred_value - actual_value) <= i)\n",
    "        accuracy = correct_times.shape[0]/pred_value.shape[0]\n",
    "        performance.append(accuracy)\n",
    "                       \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(name, pred_value, actual_value,block_index):\n",
    "    \n",
    "#     fig, ax = plt.subplots(2,2,figsize=(20,10), sharex=True, sharey=True)\n",
    "    fig, ax = plt.subplots(1,figsize=(20,10), sharex=True, sharey=True)\n",
    "#     ax.set_xlim(0,pred_value.shape[0])  \n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.plot(pred_value, label=\"LLAAT\")\n",
    "    ax.plot(actual_value, label=\"Actual\")\n",
    "    ax.set_title(\"Forecasted performance for l=%d\" %(1))\n",
    "    ax.legend()\n",
    "        \n",
    "    #fig.text(0.5, 0, \"Stage of training\", ha='center', fontsize=20)\n",
    "    #fig.text(0, 0.5, \"Copper price value\", va='center', rotation='vertical')\n",
    "\n",
    "    fig.suptitle(\"In the %s process in the M=%d window\"%(name, block_index))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\"In the %s process in the M=%d window.png\"%(name, block_index),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_adopted_node(network,block_index):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "#     ax.set_xticklabels([i for i in range(network.nb_node_acceptable.shape[0]+5)])\n",
    "    \n",
    "    ax.set_title(\"Total amount of adopted hidden nodes in the training process in the M=%d window\"%(block_index))\n",
    "    ax.plot(network.nb_node_acceptable,\"-o\")\n",
    "\n",
    "    ax.set_xlabel(\"Stage of training\")\n",
    "    ax.set_ylabel(\"Hidden nodes\")\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    fig.savefig(\"hidden nodes in the training process in the M=%d window\"%(block_index),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_table(evaluation_results, block_index, name, performance, nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node):\n",
    "\n",
    "    print(performance[3])\n",
    "    print(type(performance[3]))\n",
    "    \n",
    "    new_result = pd.DataFrame({\n",
    "\n",
    "        \"Window_index\":block_index,\n",
    "        \"Stage\":name,\n",
    "        \"MAE\" : performance[0].item(),\n",
    "        \"MAPE\" : \"%.2f\"%(performance[1]*100).item(),\n",
    "        \"RMSE\" : performance[2].item(),\n",
    "        \"Accuracy(2000)\" : [round(performance[3]*100,2)],\n",
    "        \"Accuracy(3000)\" : [round(performance[4]*100,2)],\n",
    "        \"Step4\":nb_step4,\n",
    "        \"Step6.1\":nb_step6_1,\n",
    "        \"Step6.2\":nb_step6_2,\n",
    "        \"Time\":time,\n",
    "        \"Adopted_hidden_node\":adopted_hidden_node\n",
    "    })\n",
    "\n",
    "    evaluation_results = evaluation_results.append(new_result, ignore_index=True)\n",
    "    \n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test, y_test, start, end, block_index, evaluation_results_train, evaluation_results_test):\n",
    "\n",
    "    ## Training_Step\n",
    "    print(\"<<Training step>>\")\n",
    "    print(\"The training time(s):\",end - start)\n",
    "    time = end - start\n",
    "    yo, loss= network.forward()\n",
    "    \n",
    "    pre_train = yo.data.cpu()\n",
    "    true_train = network.y.data.cpu()\n",
    "    \n",
    "    pred_value_train = torch.FloatTensor(sc.inverse_transform(pre_train))\n",
    "    actual_value_train = torch.FloatTensor(sc.inverse_transform(true_train))\n",
    "    accuracy_train = accuracy_cacl(pred_value_train,actual_value_train)\n",
    "\n",
    "    ## Test_step\n",
    "#     print(\"<<Testing step>>\")\n",
    "    pred_value_test = torch.FloatTensor(sc.inverse_transform(network.forecast(x_test).data.cpu()))\n",
    "    accuracy_test = accuracy_cacl(pred_value_test, y_test)\n",
    "    \n",
    "    total_time = nb_step4 + nb_step6_1 + nb_step6_2\n",
    "    print(\"<<The percentage of each step>>\")\n",
    "    print(\"Step 4: %.2f%%\"%((nb_step4/total_time)*100))\n",
    "    print(\"Step 6.1: %.2f%%\"%((nb_step6_1/total_time)*100))\n",
    "    print(\"Step 6.2: %.2f%%\"%((nb_step6_2/total_time)*100))\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"Total frequency of cramming occurrences:\",nb_step6_2)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"The amount of hidden node that be pruned:\",network.nb_node_pruned)\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    adopted_hidden_node = network.nb_node_acceptable[-1].item()\n",
    "    print(\"The amount of adopted hidden nodes:\",network.nb_node_acceptable[-1].item())\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in training step>>\")\n",
    "    print(\"The MAE for l = 1: %.2f\" %(accuracy_train[0]))\n",
    "    print(\"The MAPE for l = 1: %.2f%%\" %(accuracy_train[1]))\n",
    "    print(\"The RMSE for l = 1: %.2f\" %(accuracy_train[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.2f%%\" %(accuracy_train[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.2f%%\" %(accuracy_train[4]*100))\n",
    "#     print(\"The accuracy for l = 2: %.1f%%\" %(accuracy_train[1]*100))\n",
    "#     print(\"The accuracy for l = 3: %.1f%%\" %(accuracy_train[2]*100))\n",
    "#     print(\"The accuracy for l = 4: %.1f%%\" %(accuracy_train[3]*100))\n",
    "\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(\"<<Accuracy in inferencing step>>\")\n",
    "    print(\"The MAE for l = 1: %.1f\" %(accuracy_test[0]))\n",
    "    print(\"The MAPE for l = 1: %.1f%%\" %(accuracy_test[1]))\n",
    "    print(\"The RMSE for l = 1: %.1f\" %(accuracy_test[2]))\n",
    "    print(\"The accuracy(2000) for l = 1: %.1f%%\" %(accuracy_test[3]*100))\n",
    "    print(\"The accuracy(3000) for l = 1: %.1f%%\" %(accuracy_test[4]*100))\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    \n",
    "    evaluation_table_train = evaluation_table(evaluation_results_train, block_index, \"Training\", accuracy_train,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    evaluation_table_test = evaluation_table(evaluation_results_test, block_index, \"Inferencing\", accuracy_test,nb_step4, nb_step6_1, nb_step6_2, time,adopted_hidden_node)\n",
    "    pre_LDSS = sc.inverse_transform(network.forecast(x_test).data.cpu())\n",
    "#     pd.DataFrame(pre_LDSS).to_csv(\"pre_LDSS_%d.csv\"%(block_index), index=False)\n",
    "    \n",
    "    if block_index%5==0:\n",
    "        plot_result(\"training\",pred_value_train, actual_value_train,block_index)\n",
    "        plot_result(\"inferencing\",pred_value_test, y_test,block_index)\n",
    "        plot_adopted_node(network,block_index)\n",
    "    \n",
    "    return(evaluation_table_train, evaluation_table_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTrain(train, pastWeek=4, futureWeek=4, defaultWeek=1):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureWeek-pastWeek):\n",
    "        X = np.array(train.iloc[i:i+defaultWeek])\n",
    "        X = np.append(X,train[\"CCSP\"].iloc[i+defaultWeek:i+pastWeek])\n",
    "        X_train.append(X.reshape(X.size))\n",
    "        Y_train.append(np.array(train.iloc[i+pastWeek:i+pastWeek+futureWeek][\"CCSP\"]))\n",
    "    return np.array(X_train), np.array(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use min-max normalization to scale the data to the range from 1 to 0\n",
    "sc = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design get_data() to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(futureWeek):\n",
    "    \n",
    "    ## Read weekly copper price data\n",
    "    path = \"WeeklyFinalData.csv\"\n",
    "    data = read(path)\n",
    "    \n",
    "    date = data[\"Date\"]\n",
    "    data.drop(\"Date\", axis=1, inplace=True)\n",
    "    \n",
    "    ## Add time lag (pastWeek=4, futureWeek=1)\n",
    "    x_data, y_data = buildTrain(data, futureWeek=futureWeek)\n",
    "\n",
    "\n",
    "    return (x_data, y_data)\n",
    "\n",
    "#     return (x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_neuro, x_train_scaled, y_train_scaled):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(x_train_scaled.shape[1], nb_neuro).cuda()\n",
    "        self.linear2 = torch.nn.Linear(nb_neuro, 1).cuda()\n",
    "        \n",
    "        \n",
    "        # Stop criteria - threshold\n",
    "        self.threshold_for_error = 0.12\n",
    "        self.threshold_for_lr = 1e-4\n",
    "        \n",
    "        # Input data \n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "        \n",
    "        # Learning rate\n",
    "        self.learning_rate = 1e-3\n",
    "        \n",
    "        # Whether the network is acceptable, default as False\n",
    "        self.acceptable = False\n",
    "        \n",
    "        # Some record for experiment\n",
    "        self.nb_node_pruned = 0\n",
    "        self.nb_node_acceptable=torch.IntTensor([nb_neuro])\n",
    "        \n",
    "        self.limit = nb_neuro\n",
    "        \n",
    "    ## Forecast the test data\n",
    "    def forecast(self, x_test):\n",
    "    \n",
    "        x_test = torch.FloatTensor(x_test).cuda()\n",
    "        activation_value = self.linear1(x_test).clamp(min=0)\n",
    "        forecast_value = self.linear2(activation_value)\n",
    "       \n",
    "        return forecast_value\n",
    "\n",
    "    ## Reset the x and y data\n",
    "    def setData(self, x_train_scaled, y_train_scaled):\n",
    "        self.x = torch.FloatTensor(x_train_scaled).cuda()\n",
    "        self.y = torch.FloatTensor(y_train_scaled).cuda()\n",
    "    \n",
    "    ## Add the new data to the x and y data\n",
    "    def addData(self, new_x_train, new_y_train):\n",
    "\n",
    "        self.x = torch.cat([self.x, new_x_train.reshape(1,-1).cuda()],0)\n",
    "        self.y = torch.cat([self.y, new_y_train.reshape(-1,1).cuda()],0)\n",
    "    \n",
    "    ## forward operation\n",
    "    def forward(self, reg_strength=0):\n",
    "       \n",
    "        y1 = self.linear1(self.x).clamp(min=0)\n",
    "        yo = self.linear2(y1)\n",
    "\n",
    "        # performance measure\n",
    "        param_val= torch.sum(torch.pow(self.linear2.bias.data,2))+torch.sum(torch.pow(self.linear2.weight.data,2))+torch.sum(torch.pow(self.linear1.bias.data,2))+torch.sum(torch.pow(self.linear1.weight.data,2))\n",
    "        reg_term= reg_strength/((self.linear2.bias.data.shape[0]*(self.linear2.weight.data.shape[1]+1)) +(self.linear1.bias.data.shape[0]*(self.linear1.weight.data.shape[1]+1)))*param_val\n",
    "        loss = torch.nn.functional.mse_loss(yo,self.y)+reg_term\n",
    "        loss = loss.cuda()\n",
    "        return(yo, loss)\n",
    "\n",
    "    # backward operation\n",
    "    def backward_Adadelta(self,loss):    \n",
    "\n",
    "        optimizer = optim.Adadelta(self.parameters(), lr=self.learning_rate)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializing(network, initial_x, initial_y):\n",
    "    print(\"Initializing module\")\n",
    "    ## Find each minimum output value y\n",
    "    min_y = torch.min(initial_y, axis=0)\n",
    "    ## Subtract min_y from each y\n",
    "    res_y = initial_y-min_y.values\n",
    "    \n",
    "    ## Use linear regression to find the initial W1,b1,Wo,bo\n",
    "    reg = LinearRegression().fit(initial_x, res_y)\n",
    "    \n",
    "    ## Set up the initial parameter of the network\n",
    "    network.linear1.weight = torch.nn.Parameter(torch.FloatTensor(reg.coef_).cuda())\n",
    "    network.linear1.bias = torch.nn.Parameter(torch.FloatTensor(reg.intercept_).cuda())\n",
    "    network.linear2.weight=torch.nn.Parameter(torch.FloatTensor([[1]]).cuda())\n",
    "    network.linear2.bias = torch.nn.Parameter(torch.FloatTensor(min_y.values).cuda())\n",
    "    \n",
    "    ## Set up the acceptable of the initial network as True\n",
    "    network.acceptable =True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting(network, x_train_scaled, y_train_scaled):\n",
    "    \n",
    "    print(\"<<Selecting module>>\")\n",
    "    loss = []\n",
    "    temp_network = copy.deepcopy(network)\n",
    "    \n",
    "    ## Put each data into network to calculate the loss value\n",
    "    for i in range(x_train_scaled.shape[0]):\n",
    "        temp_network.setData(x_train_scaled[i].reshape(1,-1), y_train_scaled[i].reshape(-1,1))\n",
    "        loss.append((temp_network.forward()[1].item(),i))\n",
    "#         print(network.state_dict())\n",
    "#         print(temp_network.y)\n",
    "#         print(\"-\"*20)\n",
    "#         print(temp_network.forward()[1])\n",
    "#         print(\"-\"*20)\n",
    "#     ## Sort the data according to the loss value from smallest to largest, and save the data index in sorted_index\n",
    "    sorted_index = [sorted_data[1] for sorted_data in sorted(loss, key = lambda x:x[0])]\n",
    "    \n",
    "    \n",
    "    ## Print out some info for debug\n",
    "    print(\"The loss value of k:\",loss[sorted_index[0]])\n",
    "    print(\"The second_loss value of k:\",loss[sorted_index[1]])\n",
    "    print(\"Selecting module finish!\")\n",
    "#     print(\"Loss\",loss)\n",
    "#     print(network.state_dict())\n",
    "    \n",
    "    return sorted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def matching(network):\n",
    "\n",
    "#     times_enlarge=0\n",
    "#     times_shrink=0\n",
    "    \n",
    "#     print(\"<<Matching module>>\")\n",
    "#     print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "#     ## Set up the learning rate of the network\n",
    "#     network.learning_rate = 1e-3\n",
    "#     network.acceptable = False\n",
    "#     initial_network = copy.deepcopy(network)\n",
    "\n",
    "#     yo, loss = network.forward()\n",
    "    \n",
    "#     if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "#         print(\"Matching finished (firstly) - the network is acceptable\")\n",
    "#         network.acceptable = True\n",
    "# #         print(\"Matching firstly finished - the network is acceptable\")\n",
    "#         print(\"Number of enlarge:\",times_enlarge)\n",
    "#         print(\"Number of shrink:\",times_shrink)\n",
    "#         return(network)\n",
    "    \n",
    "#     else:\n",
    "    \n",
    "#         while True:\n",
    "\n",
    "#             yo, loss = network.forward()\n",
    "#             network_pre = copy.deepcopy(network)\n",
    "#             loss_pre = loss\n",
    "            \n",
    "#             # Backward and check the loss performance of the network with new learning rate\n",
    "#             network.backward_Adadelta(loss)\n",
    "#             yo, loss = network.forward()\n",
    "\n",
    "#             # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "#             if loss <= loss_pre and torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "       \n",
    "#                 network.acceptable = True\n",
    "#                 print(\"Matching finished - the network is acceptable\")\n",
    "#                 print(\"Number of enlarge:\",times_enlarge)\n",
    "#                 print(\"Number of shrink:\",times_shrink)\n",
    "#                 return(network)\n",
    "\n",
    "#             elif loss <= loss_pre:\n",
    "                \n",
    "#                 times_enlarge+=1\n",
    "#                 network.learning_rate *= 1.2\n",
    "\n",
    "#             else:         \n",
    "\n",
    "#                 # Identify whether the current learning rate is less than the threshold\n",
    "#                 if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "#                     # If true, set the acceptable of the network as false and return it\n",
    "#                     network.acceptable = False\n",
    "#                     print(\"Matching finished - the network is Unacceptable\")\n",
    "#                     print(\"Number of enlarge:\",times_enlarge)\n",
    "#                     print(\"Number of shrink:\",times_shrink)\n",
    "#                     return(initial_network)\n",
    "\n",
    "#                 # On the contrary, restore w and adjust the learning rate\n",
    "#                 else:\n",
    "                    \n",
    "#                     # Restore the papameter of the network\n",
    "#                     network = copy.deepcopy(network_pre)\n",
    "#                     times_shrink+=1\n",
    "#                     network.learning_rate *= 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    \n",
    "    print(\"<<Matching module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "    yo, loss = network.forward()\n",
    "    \n",
    "    if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "        network.acceptable = True\n",
    "        print(\"Matching(o) first finished - the network is acceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(10000):\n",
    "            \n",
    "            yo, loss = network.forward()\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "#             print(\"<前Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "            network.backward_Adadelta(loss)\n",
    "            yo, loss = network.forward()\n",
    "#             print(\"<後Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "            if loss <= loss_pre and torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "                # If true, multiply the learning rate by 1.2\n",
    "                network.acceptable = True\n",
    "                print(\"Matching finished - the network is acceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "            elif loss <= loss_pre:\n",
    "                \n",
    "#                 print(\"*1.2\")\n",
    "                times_enlarge+=1\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "\n",
    "            else:         \n",
    "\n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                    # If true, set the acceptable of the network as false and return it\n",
    "                    network.acceptable = False\n",
    "                    print(\"Matching finished - the network is Unacceptable\")\n",
    "                    print(\"Number of enlarge:\",times_enlarge)\n",
    "                    print(\"Number of shrink:\",times_shrink)\n",
    "                    return(initial_network)\n",
    "\n",
    "                # On the contrary, restore w and adjust the learning rate\n",
    "                else:\n",
    "#                     print(\"*0.7\")\n",
    "                    # Restore the papameter of the network\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    times_shrink+=1\n",
    "                    network.learning_rate *= 0.7\n",
    "                \n",
    "        network.acceptable = False\n",
    "        print(\"Matching的第%d回合\"%(i+1))\n",
    "        print(\"Matching finished - the network is Unacceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(initial_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching for reorganizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_for_reorganizing(network):\n",
    "\n",
    "    times_enlarge=0\n",
    "    times_shrink=0\n",
    "    \n",
    "    print(\"<<Matching module for reorganizing>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "    network.acceptable = False\n",
    "    initial_network = copy.deepcopy(network)\n",
    "    yo, loss = network.forward()\n",
    "    \n",
    "    if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "        network.acceptable = True\n",
    "        print(\"Matching(o) first finished - the network is acceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for i in range(500):\n",
    "            \n",
    "            yo, loss = network.forward()\n",
    "            network_pre = copy.deepcopy(network)\n",
    "            loss_pre = loss\n",
    "#             print(\"<前Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Backward and check the loss performance of the network with new learning rate\n",
    "            network.backward_Adadelta(loss)\n",
    "            yo, loss = network.forward()\n",
    "#             print(\"<後Loss>\",loss)\n",
    "#             print(network.state_dict())\n",
    "            # Confirm whether the loss value of the adjusted network is smaller than the current one\n",
    "            if loss <= loss_pre and torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "\n",
    "                # If true, multiply the learning rate by 1.2\n",
    "                network.acceptable = True\n",
    "                print(\"Matching finished(o) - the network is acceptable\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "                return(network)\n",
    "\n",
    "            elif loss <= loss_pre:\n",
    "                \n",
    "#                 print(\"*1.2\")\n",
    "                times_enlarge+=1\n",
    "                network.learning_rate *= 1.2\n",
    "\n",
    "\n",
    "            else:         \n",
    "\n",
    "                # Identify whether the current learning rate is less than the threshold\n",
    "                if network.learning_rate <= network.threshold_for_lr:\n",
    "\n",
    "                    # If true, set the acceptable of the network as false and return it\n",
    "                    network.acceptable = False\n",
    "                    print(\"Matching finished(o) - the network is Unacceptable\")\n",
    "                    print(\"Number of enlarge:\",times_enlarge)\n",
    "                    print(\"Number of shrink:\",times_shrink)\n",
    "                    return(initial_network)\n",
    "\n",
    "                # On the contrary, restore w and adjust the learning rate\n",
    "                else:\n",
    "#                     print(\"*0.7\")\n",
    "                    # Restore the papameter of the network\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    times_shrink+=1\n",
    "                    network.learning_rate *= 0.7\n",
    "                \n",
    "        network.acceptable = False\n",
    "        print(\"Matching的第%d回合\"%(i+1))\n",
    "        print(\"Matching finished - the network is Unacceptable\")\n",
    "        print(\"Number of enlarge:\",times_enlarge)\n",
    "        print(\"Number of shrink:\",times_shrink)\n",
    "        return(initial_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramming module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramming(network):\n",
    "    \n",
    "    torch.random.manual_seed(0)\n",
    "    print(\"<<Cramming module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    ## Find unsatisfied data:K\n",
    "    yo, loss = network.forward()\n",
    "    undesired_index = torch.nonzero(torch.abs(yo-network.y) > network.threshold_for_error+0.001, as_tuple =False)\n",
    "\n",
    "    ## Print out the undesired_index for debug\n",
    "    print(\"不滿足個數：\",undesired_index.shape[0])\n",
    "    print(\"The index of the undesired data:\",undesired_index)\n",
    "\n",
    "    \n",
    "    if undesired_index.shape[0] == 1:\n",
    "        \n",
    "        # Unsatisfied situation\n",
    "        ## Find the index of the unsatisfied data\n",
    "        k_data_num = undesired_index[0][0]\n",
    "\n",
    "        undesired_data = torch.reshape(network.x[k_data_num,:], [1,-1])\n",
    "\n",
    "        ## Remove the data that does not meet the error term\n",
    "        left_data = network.x[:k_data_num,:]\n",
    "        right_data = network.x[k_data_num+1:,:]\n",
    "        remain_tensor = torch.cat([left_data, right_data], 0)\n",
    "\n",
    "\n",
    "        ## Use the random method to find out the gamma and zeta\n",
    "        while True:\n",
    "\n",
    "            ## Find m-vector gamma: r\n",
    "            ## Use the random method to generate the gamma that can make the conditions met\n",
    "            gamma = torch.rand(size=[1,network.x.shape[1]]).cuda()\n",
    "            subtract_undesired_data = torch.sub(remain_tensor, undesired_data)\n",
    "            matmul_value = torch.mm(gamma,torch.t(subtract_undesired_data))\n",
    "\n",
    "            if torch.all(matmul_value != 0):\n",
    "                break\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## Find the tiny value: zeta\n",
    "            ## Use the random method to generate the zeta that can make the conditions met\n",
    "            zeta = torch.rand(size=[1]).cuda()\n",
    "\n",
    "            if torch.all(torch.mul(torch.add(zeta,matmul_value),torch.sub(zeta,matmul_value))<0):\n",
    "                break\n",
    "\n",
    "       \n",
    "\n",
    "        k_l = undesired_index[0][1]\n",
    "        \n",
    "        ## The weight of input layer to hidden layer I\n",
    "        w10 = gamma\n",
    "        w11 = gamma\n",
    "        w12 = gamma\n",
    "\n",
    "        W1_new = torch.cat([w10,w11,w12],0)\n",
    "        \n",
    "\n",
    "        ## The bias of input layer to hidden layer I\n",
    "        matual_value = torch.mm(gamma,torch.t(undesired_data))\n",
    "       \n",
    "        \n",
    "        b10 = torch.sub(zeta,matual_value)\n",
    "        b11 = -1*matual_value\n",
    "        b12 = torch.sub(-1*zeta,matual_value)\n",
    "\n",
    "        b1_new = torch.reshape(torch.cat([b10,b11,b12],0),[3])\n",
    "        \n",
    "#         print(\"b1_new\",b1_new)\n",
    "\n",
    "\n",
    "        ## The weight of hidden layer I to output layer\n",
    "        gap = network.y[k_data_num, k_l]-yo[k_data_num, k_l]\n",
    "#         print(\"gap:\",gap)\n",
    "\n",
    "        wo0_value = gap/zeta\n",
    "        wo1_value = (-2*gap)/zeta\n",
    "        wo2_value = gap/zeta\n",
    "\n",
    "        Wo_new = torch.reshape(torch.cat([wo0_value,wo1_value,wo2_value],0),[1,-1])\n",
    "\n",
    "        ## Add new neuroes to the network\n",
    "        network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight.data, W1_new]))\n",
    "        network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias.data, b1_new]))\n",
    "        network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight.data, Wo_new],1))\n",
    "\n",
    "\n",
    "        yo, loss = network.forward()\n",
    "        \n",
    "        ## Determine if cramming is successful and print out the corresponding information\n",
    "        if torch.all(torch.abs(yo-network.y) <= network.threshold_for_error):\n",
    "            network.acceptable = True \n",
    "            print(\"Cramming success!\")\n",
    "\n",
    "        else:\n",
    "            print(\"Cramming failed!\")\n",
    "    \n",
    "    else:\n",
    "        print(\"條件不合，不能Cramming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizing(network):\n",
    "\n",
    "    print(\"<<Regularizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    ## Record the number of executions\n",
    "    times_enlarge = 0\n",
    "    times_shrink = 0\n",
    "    ## Set up the learning rate of the network\n",
    "    network.learning_rate = 1e-3\n",
    "\n",
    "    ## Set epoch to 100\n",
    "    for i in range(100):\n",
    "\n",
    "        ## Store the parameter of the network\n",
    "        network_pre = copy.deepcopy(network)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "        loss_pre = loss\n",
    "\n",
    "#         print(\"調整前的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "        \n",
    "        ## Backward operation to obtain w'\n",
    "        network.backward_Adadelta(loss)\n",
    "        yo, loss = network.forward(1e-3)\n",
    "#         print(\"調整後的network\")\n",
    "#         print(\"<<變數>>\")\n",
    "#         print(network.state_dict())\n",
    "#         print(\"<<Loss值>>\")\n",
    "#         print(loss)\n",
    "#         print(\"差異\")\n",
    "#         print(torch.abs(yo-network.y))\n",
    "         # Confirm whether the adjusted loss value is smaller than the current one\n",
    "        if loss <= loss_pre:\n",
    "            \n",
    "            ## Identify that all forecast value has met the error term\n",
    "            if torch.all(torch.abs(yo-network.y) < network.threshold_for_error):\n",
    "                \n",
    "                ## If true, multiply the learning rate by 1.2\n",
    "#                 print(\"*1.2\")\n",
    "                network.learning_rate *= 1.2\n",
    "                times_enlarge += 1\n",
    "#                 print(\"Regularizing %d process - Enlarge\"%i)\n",
    "#                 print(\"第\\\"%d\\\"回合是成功執行regularizing\"%(i+1))\n",
    "#                 print(\"差異\")\n",
    "#                 print(torch.abs(yo-network.y))\n",
    "\n",
    "            else:\n",
    "\n",
    "                ## Else, restore w and end the process\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                print(\"Regularizing結束-因為沒有顧好預測誤差\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Unable to meet the error term\")\n",
    "                return(network)\n",
    "\n",
    "        # If the adjusted loss value is not smaller than the current one\n",
    "        else:\n",
    "\n",
    "            ## If the learning rate is greater than the threshold for learning rate\n",
    "            if network.learning_rate > network.threshold_for_lr:\n",
    "                \n",
    "                ## Restore the w and multiply the learning rate by 0.7\n",
    "                network = copy.deepcopy(network_pre)\n",
    "#                 print(\"*0.7\")\n",
    "                network.learning_rate *= 0.7\n",
    "                times_shrink += 1\n",
    "#                 print(\"把Learning rate變小\")\n",
    "#                 print(\"Regularizing %d process - Shrink\"%i)\n",
    "             ## If the learning rate is smaller than the threshold for learning rate\n",
    "            else:\n",
    "                \n",
    "                ## Restore the w\n",
    "                network = copy.deepcopy(network_pre)\n",
    "                print(\"Regularizing結束-Learning不能這麼小\")\n",
    "                print(\"Number of enlarge:\",times_enlarge)\n",
    "                print(\"Number of shrink:\",times_shrink)\n",
    "#                 print(\"Regularizing result: Less than the epsilon for the learning rate\")\n",
    "                return(network)\n",
    "\n",
    "    print(\"第\\\"%d\\\"回合Regularizing module完畢\"%(i+1))\n",
    "    print(\"Number of enlarge:\",times_enlarge)\n",
    "    print(\"Number of shrink:\",times_shrink)\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganizing module (Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganizing(network):\n",
    "    print(\"<<Reorganizing module>>\")\n",
    "    print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "    \n",
    "    limit = 4\n",
    "    if network.linear1.bias.shape[0] <= limit:\n",
    "        network = regularizing(network)\n",
    "        return(network)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        ## Set up the k = 1, and p = the number of hidden node\n",
    "        k = 1\n",
    "    #     p = network.W1.shape[1]\n",
    "        p = network.linear1.weight.data.shape[0]\n",
    "\n",
    "        while True:\n",
    "\n",
    "            ## If k > p, end of Process\n",
    "            if k > p or p<=limit:\n",
    "\n",
    "                print(\"Reorganizing result: The final number of neuro is \",p)\n",
    "                return(network)\n",
    "\n",
    "            ## Else, Process is ongoing\n",
    "            else:\n",
    "\n",
    "                ## Using the regularizing module to adjust the network\n",
    "                network = regularizing(network)\n",
    "\n",
    "                ## Store the network and w\n",
    "                network_pre = copy.deepcopy(network)\n",
    "\n",
    "                ## Set up the acceptable of the network as false\n",
    "                network.acceptable = False\n",
    "                \n",
    "            \n",
    "                ## Ignore the K hidden node\n",
    "                network.linear1.weight = torch.nn.Parameter(torch.cat([network.linear1.weight[:k-1],network.linear1.weight[k:]],0))\n",
    "                network.linear1.bias = torch.nn.Parameter(torch.cat([network.linear1.bias[:k-1],network.linear1.bias[k:]]))\n",
    "                network.linear2.weight = torch.nn.Parameter(torch.cat([network.linear2.weight[:,:k-1],network.linear2.weight[:,k:]],1))\n",
    "\n",
    "                \n",
    "                ## Using the matching module to adjust the network\n",
    "                network = matching_for_reorganizing(network)\n",
    "\n",
    "                print(\"是不是可以不要這個hidden node:\",network.acceptable)\n",
    "\n",
    "                ## If the resulting network is acceptable, this means that the k hidden node can be removed\n",
    "                if network.acceptable:\n",
    "\n",
    "                    print(\"Drop out the nero number: %d / %d\" %(k, p))\n",
    "                    network.nb_node_pruned += 1\n",
    "                    ## p--\n",
    "                    p-=1\n",
    "\n",
    "                ## Else, it means that the k hidden node cannot be removed\n",
    "                else:\n",
    "\n",
    "                    ## Restore the network and w\n",
    "                    network = copy.deepcopy(network_pre)\n",
    "                    print(\"Cannot drop out the nero number: %d / %d\" %(k, p))\n",
    "\n",
    "                    ## k++\n",
    "                    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The <<1>> Block\n",
      "Initializing module\n",
      "<<Initializing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "現在訓練到第幾筆資料: 20\n",
      "剩餘X 資料 torch.Size([87, 18])\n",
      "剩餘Y 資料 torch.Size([87, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (5.538687446460244e-07, 48)\n",
      "The second_loss value of k: (2.4864239094313234e-05, 13)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引48，y= tensor([0.7936])\n",
      "目前模型的Data狀態 torch.Size([20, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9928],\n",
      "        [0.9790],\n",
      "        [0.9973],\n",
      "        [0.9834],\n",
      "        [0.9800],\n",
      "        [0.9673],\n",
      "        [0.9438],\n",
      "        [0.8890],\n",
      "        [0.9141],\n",
      "        [0.9367],\n",
      "        [0.9159],\n",
      "        [0.8534],\n",
      "        [0.8548],\n",
      "        [0.8454],\n",
      "        [0.7929],\n",
      "        [0.8065],\n",
      "        [0.8315],\n",
      "        [0.8036],\n",
      "        [0.8492],\n",
      "        [0.7929]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0007]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 64\n",
      "Number of shrink: 36\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0007]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.0943572521209717\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 21\n",
      "剩餘X 資料 torch.Size([86, 18])\n",
      "剩餘Y 資料 torch.Size([86, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (2.4869588742149062e-05, 13)\n",
      "The second_loss value of k: (0.00012659243657253683, 18)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引13，y= tensor([0.8094])\n",
      "目前模型的Data狀態 torch.Size([21, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9928],\n",
      "        [0.9790],\n",
      "        [0.9973],\n",
      "        [0.9834],\n",
      "        [0.9800],\n",
      "        [0.9673],\n",
      "        [0.9438],\n",
      "        [0.8890],\n",
      "        [0.9141],\n",
      "        [0.9367],\n",
      "        [0.9159],\n",
      "        [0.8534],\n",
      "        [0.8548],\n",
      "        [0.8454],\n",
      "        [0.7929],\n",
      "        [0.8065],\n",
      "        [0.8315],\n",
      "        [0.8036],\n",
      "        [0.8492],\n",
      "        [0.7929],\n",
      "        [0.8144]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0007],\n",
      "        [    0.0050]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 65\n",
      "Number of shrink: 35\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0000],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0008],\n",
      "        [    0.0048]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.4332549571990967\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 22\n",
      "剩餘X 資料 torch.Size([85, 18])\n",
      "剩餘Y 資料 torch.Size([85, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00012244755635038018, 17)\n",
      "The second_loss value of k: (0.00013035132724326104, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引17，y= tensor([0.8635])\n",
      "目前模型的Data狀態 torch.Size([22, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9925],\n",
      "        [0.9788],\n",
      "        [0.9970],\n",
      "        [0.9831],\n",
      "        [0.9798],\n",
      "        [0.9671],\n",
      "        [0.9436],\n",
      "        [0.8887],\n",
      "        [0.9139],\n",
      "        [0.9364],\n",
      "        [0.9157],\n",
      "        [0.8531],\n",
      "        [0.8545],\n",
      "        [0.8452],\n",
      "        [0.7929],\n",
      "        [0.8063],\n",
      "        [0.8313],\n",
      "        [0.8034],\n",
      "        [0.8490],\n",
      "        [0.7929],\n",
      "        [0.8142],\n",
      "        [0.8746]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0000],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0008],\n",
      "        [    0.0048],\n",
      "        [    0.0111]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0004],\n",
      "        [0.0004],\n",
      "        [0.0003],\n",
      "        [0.0005],\n",
      "        [0.0005],\n",
      "        [0.0007],\n",
      "        [0.0006],\n",
      "        [0.0005],\n",
      "        [0.0007],\n",
      "        [0.0007],\n",
      "        [0.0007],\n",
      "        [0.0007],\n",
      "        [0.0009],\n",
      "        [0.0009],\n",
      "        [0.0006],\n",
      "        [0.0009],\n",
      "        [0.0011],\n",
      "        [0.0012],\n",
      "        [0.0012],\n",
      "        [0.0013],\n",
      "        [0.0035],\n",
      "        [0.0095]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 2.788686752319336\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 23\n",
      "剩餘X 資料 torch.Size([84, 18])\n",
      "剩餘Y 資料 torch.Size([84, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00014286414079833776, 12)\n",
      "The second_loss value of k: (0.00015236262697726488, 21)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([0.8043])\n",
      "目前模型的Data狀態 torch.Size([23, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9923],\n",
      "        [0.9786],\n",
      "        [0.9970],\n",
      "        [0.9829],\n",
      "        [0.9795],\n",
      "        [0.9667],\n",
      "        [0.9432],\n",
      "        [0.8884],\n",
      "        [0.9134],\n",
      "        [0.9360],\n",
      "        [0.9152],\n",
      "        [0.8526],\n",
      "        [0.8539],\n",
      "        [0.8445],\n",
      "        [0.7923],\n",
      "        [0.8056],\n",
      "        [0.8305],\n",
      "        [0.8025],\n",
      "        [0.8480],\n",
      "        [0.7923],\n",
      "        [0.8130],\n",
      "        [0.8730],\n",
      "        [0.7923]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0004],\n",
      "        [0.0004],\n",
      "        [0.0003],\n",
      "        [0.0005],\n",
      "        [0.0005],\n",
      "        [0.0007],\n",
      "        [0.0006],\n",
      "        [0.0005],\n",
      "        [0.0007],\n",
      "        [0.0007],\n",
      "        [0.0007],\n",
      "        [0.0007],\n",
      "        [0.0009],\n",
      "        [0.0009],\n",
      "        [0.0006],\n",
      "        [0.0009],\n",
      "        [0.0011],\n",
      "        [0.0012],\n",
      "        [0.0012],\n",
      "        [0.0013],\n",
      "        [0.0035],\n",
      "        [0.0095],\n",
      "        [0.0120]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0001],\n",
      "        [    0.0004],\n",
      "        [    0.0005],\n",
      "        [    0.0007],\n",
      "        [    0.0006],\n",
      "        [    0.0005],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0010],\n",
      "        [    0.0010],\n",
      "        [    0.0025],\n",
      "        [    0.0009],\n",
      "        [    0.0011],\n",
      "        [    0.0012],\n",
      "        [    0.0012],\n",
      "        [    0.0018],\n",
      "        [    0.0034],\n",
      "        [    0.0091],\n",
      "        [    0.0089]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.1660523414611816\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 24\n",
      "剩餘X 資料 torch.Size([83, 18])\n",
      "剩餘Y 資料 torch.Size([83, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0001418315659975633, 20)\n",
      "The second_loss value of k: (0.00045093995868228376, 45)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引20，y= tensor([0.9669])\n",
      "目前模型的Data狀態 torch.Size([24, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9926],\n",
      "        [0.9788],\n",
      "        [0.9972],\n",
      "        [0.9830],\n",
      "        [0.9795],\n",
      "        [0.9666],\n",
      "        [0.9432],\n",
      "        [0.8884],\n",
      "        [0.9134],\n",
      "        [0.9360],\n",
      "        [0.9152],\n",
      "        [0.8527],\n",
      "        [0.8538],\n",
      "        [0.8444],\n",
      "        [0.7954],\n",
      "        [0.8057],\n",
      "        [0.8304],\n",
      "        [0.8024],\n",
      "        [0.8480],\n",
      "        [0.7954],\n",
      "        [0.8128],\n",
      "        [0.8727],\n",
      "        [0.7954],\n",
      "        [0.9789]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0002],\n",
      "        [    0.0002],\n",
      "        [    0.0001],\n",
      "        [    0.0004],\n",
      "        [    0.0005],\n",
      "        [    0.0007],\n",
      "        [    0.0006],\n",
      "        [    0.0005],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0007],\n",
      "        [    0.0010],\n",
      "        [    0.0010],\n",
      "        [    0.0025],\n",
      "        [    0.0009],\n",
      "        [    0.0011],\n",
      "        [    0.0012],\n",
      "        [    0.0012],\n",
      "        [    0.0018],\n",
      "        [    0.0034],\n",
      "        [    0.0091],\n",
      "        [    0.0089],\n",
      "        [    0.0119]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0004],\n",
      "        [    0.0005],\n",
      "        [    0.0001],\n",
      "        [    0.0006],\n",
      "        [    0.0009],\n",
      "        [    0.0013],\n",
      "        [    0.0011],\n",
      "        [    0.0009],\n",
      "        [    0.0013],\n",
      "        [    0.0013],\n",
      "        [    0.0012],\n",
      "        [    0.0012],\n",
      "        [    0.0017],\n",
      "        [    0.0018],\n",
      "        [    0.0029],\n",
      "        [    0.0015],\n",
      "        [    0.0019],\n",
      "        [    0.0022],\n",
      "        [    0.0022],\n",
      "        [    0.0022],\n",
      "        [    0.0020],\n",
      "        [    0.0073],\n",
      "        [    0.0085],\n",
      "        [    0.0098]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.5237205028533936\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 25\n",
      "剩餘X 資料 torch.Size([82, 18])\n",
      "剩餘Y 資料 torch.Size([82, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00040199249633587897, 15)\n",
      "The second_loss value of k: (0.000435709924204275, 44)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([0.8425])\n",
      "目前模型的Data狀態 torch.Size([25, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9923],\n",
      "        [0.9786],\n",
      "        [0.9972],\n",
      "        [0.9827],\n",
      "        [0.9791],\n",
      "        [0.9661],\n",
      "        [0.9427],\n",
      "        [0.8881],\n",
      "        [0.9128],\n",
      "        [0.9354],\n",
      "        [0.9147],\n",
      "        [0.8522],\n",
      "        [0.8531],\n",
      "        [0.8436],\n",
      "        [0.7958],\n",
      "        [0.8050],\n",
      "        [0.8296],\n",
      "        [0.8015],\n",
      "        [0.8470],\n",
      "        [0.7958],\n",
      "        [0.8114],\n",
      "        [0.8708],\n",
      "        [0.7958],\n",
      "        [0.9768],\n",
      "        [0.8626]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0004],\n",
      "        [    0.0005],\n",
      "        [    0.0001],\n",
      "        [    0.0006],\n",
      "        [    0.0009],\n",
      "        [    0.0013],\n",
      "        [    0.0011],\n",
      "        [    0.0009],\n",
      "        [    0.0013],\n",
      "        [    0.0013],\n",
      "        [    0.0012],\n",
      "        [    0.0012],\n",
      "        [    0.0017],\n",
      "        [    0.0018],\n",
      "        [    0.0029],\n",
      "        [    0.0015],\n",
      "        [    0.0019],\n",
      "        [    0.0022],\n",
      "        [    0.0022],\n",
      "        [    0.0022],\n",
      "        [    0.0020],\n",
      "        [    0.0073],\n",
      "        [    0.0085],\n",
      "        [    0.0098],\n",
      "        [    0.0200]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0008],\n",
      "        [    0.0001],\n",
      "        [    0.0005],\n",
      "        [    0.0012],\n",
      "        [    0.0008],\n",
      "        [    0.0003],\n",
      "        [    0.0011],\n",
      "        [    0.0011],\n",
      "        [    0.0010],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0022],\n",
      "        [    0.0025],\n",
      "        [    0.0017],\n",
      "        [    0.0024],\n",
      "        [    0.0030],\n",
      "        [    0.0032],\n",
      "        [    0.0018],\n",
      "        [    0.0004],\n",
      "        [    0.0050],\n",
      "        [    0.0089],\n",
      "        [    0.0075],\n",
      "        [    0.0177]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 3.8519859313964844\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 26\n",
      "剩餘X 資料 torch.Size([81, 18])\n",
      "剩餘Y 資料 torch.Size([81, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00045210515963844955, 43)\n",
      "The second_loss value of k: (0.0009602215141057968, 13)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引43，y= tensor([0.8166])\n",
      "目前模型的Data狀態 torch.Size([26, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9928],\n",
      "        [0.9791],\n",
      "        [0.9981],\n",
      "        [0.9833],\n",
      "        [0.9796],\n",
      "        [0.9662],\n",
      "        [0.9430],\n",
      "        [0.8886],\n",
      "        [0.9130],\n",
      "        [0.9356],\n",
      "        [0.9149],\n",
      "        [0.8524],\n",
      "        [0.8528],\n",
      "        [0.8433],\n",
      "        [0.7954],\n",
      "        [0.8048],\n",
      "        [0.8291],\n",
      "        [0.8007],\n",
      "        [0.8460],\n",
      "        [0.7954],\n",
      "        [0.8098],\n",
      "        [0.8685],\n",
      "        [0.7954],\n",
      "        [0.9745],\n",
      "        [0.8602],\n",
      "        [0.7954]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0008],\n",
      "        [    0.0001],\n",
      "        [    0.0005],\n",
      "        [    0.0012],\n",
      "        [    0.0008],\n",
      "        [    0.0003],\n",
      "        [    0.0011],\n",
      "        [    0.0011],\n",
      "        [    0.0010],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0022],\n",
      "        [    0.0025],\n",
      "        [    0.0017],\n",
      "        [    0.0024],\n",
      "        [    0.0030],\n",
      "        [    0.0032],\n",
      "        [    0.0018],\n",
      "        [    0.0004],\n",
      "        [    0.0050],\n",
      "        [    0.0089],\n",
      "        [    0.0075],\n",
      "        [    0.0177],\n",
      "        [    0.0213]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(    0.0000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0004],\n",
      "        [    0.0003],\n",
      "        [    0.0013],\n",
      "        [    0.0001],\n",
      "        [    0.0004],\n",
      "        [    0.0013],\n",
      "        [    0.0007],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0011],\n",
      "        [    0.0009],\n",
      "        [    0.0008],\n",
      "        [    0.0019],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0016],\n",
      "        [    0.0024],\n",
      "        [    0.0030],\n",
      "        [    0.0032],\n",
      "        [    0.0064],\n",
      "        [    0.0001],\n",
      "        [    0.0040],\n",
      "        [    0.0042],\n",
      "        [    0.0063],\n",
      "        [    0.0167],\n",
      "        [    0.0166]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.205176830291748\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 27\n",
      "剩餘X 資料 torch.Size([80, 18])\n",
      "剩餘Y 資料 torch.Size([80, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0009186186944134533, 13)\n",
      "The second_loss value of k: (0.001257440890185535, 42)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引13，y= tensor([0.8145])\n",
      "目前模型的Data狀態 torch.Size([27, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9932],\n",
      "        [0.9794],\n",
      "        [0.9986],\n",
      "        [0.9835],\n",
      "        [0.9796],\n",
      "        [0.9661],\n",
      "        [0.9430],\n",
      "        [0.8888],\n",
      "        [0.9130],\n",
      "        [0.9356],\n",
      "        [0.9150],\n",
      "        [0.8526],\n",
      "        [0.8528],\n",
      "        [0.8432],\n",
      "        [0.8000],\n",
      "        [0.8050],\n",
      "        [0.8291],\n",
      "        [0.8007],\n",
      "        [0.8460],\n",
      "        [0.8000],\n",
      "        [0.8094],\n",
      "        [0.8675],\n",
      "        [0.8000],\n",
      "        [0.9733],\n",
      "        [0.8592],\n",
      "        [0.8000],\n",
      "        [0.8448]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0004],\n",
      "        [    0.0003],\n",
      "        [    0.0013],\n",
      "        [    0.0001],\n",
      "        [    0.0004],\n",
      "        [    0.0013],\n",
      "        [    0.0007],\n",
      "        [    0.0001],\n",
      "        [    0.0011],\n",
      "        [    0.0011],\n",
      "        [    0.0009],\n",
      "        [    0.0008],\n",
      "        [    0.0019],\n",
      "        [    0.0022],\n",
      "        [    0.0072],\n",
      "        [    0.0016],\n",
      "        [    0.0024],\n",
      "        [    0.0030],\n",
      "        [    0.0032],\n",
      "        [    0.0064],\n",
      "        [    0.0001],\n",
      "        [    0.0040],\n",
      "        [    0.0042],\n",
      "        [    0.0063],\n",
      "        [    0.0167],\n",
      "        [    0.0166],\n",
      "        [    0.0303]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(    0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0002],\n",
      "        [0.0002],\n",
      "        [0.0013],\n",
      "        [0.0002],\n",
      "        [0.0008],\n",
      "        [0.0021],\n",
      "        [0.0012],\n",
      "        [0.0003],\n",
      "        [0.0018],\n",
      "        [0.0017],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0030],\n",
      "        [0.0035],\n",
      "        [0.0079],\n",
      "        [0.0027],\n",
      "        [0.0038],\n",
      "        [0.0029],\n",
      "        [0.0051],\n",
      "        [0.0071],\n",
      "        [0.0028],\n",
      "        [0.0007],\n",
      "        [0.0035],\n",
      "        [0.0029],\n",
      "        [0.0132],\n",
      "        [0.0159],\n",
      "        [0.0270]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.538869857788086\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 28\n",
      "剩餘X 資料 torch.Size([79, 18])\n",
      "剩餘Y 資料 torch.Size([79, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0012080378364771605, 41)\n",
      "The second_loss value of k: (0.0012189552653580904, 40)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引41，y= tensor([0.8355])\n",
      "目前模型的Data狀態 torch.Size([28, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9925],\n",
      "        [0.9788],\n",
      "        [0.9986],\n",
      "        [0.9832],\n",
      "        [0.9792],\n",
      "        [0.9653],\n",
      "        [0.9426],\n",
      "        [0.8887],\n",
      "        [0.9123],\n",
      "        [0.9350],\n",
      "        [0.9144],\n",
      "        [0.8520],\n",
      "        [0.8518],\n",
      "        [0.8420],\n",
      "        [0.8007],\n",
      "        [0.8039],\n",
      "        [0.8277],\n",
      "        [0.8007],\n",
      "        [0.8441],\n",
      "        [0.8007],\n",
      "        [0.8066],\n",
      "        [0.8642],\n",
      "        [0.8007],\n",
      "        [0.9699],\n",
      "        [0.8557],\n",
      "        [0.8007],\n",
      "        [0.8415],\n",
      "        [0.8007]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0002],\n",
      "        [0.0002],\n",
      "        [0.0013],\n",
      "        [0.0002],\n",
      "        [0.0008],\n",
      "        [0.0021],\n",
      "        [0.0012],\n",
      "        [0.0003],\n",
      "        [0.0018],\n",
      "        [0.0017],\n",
      "        [0.0015],\n",
      "        [0.0014],\n",
      "        [0.0030],\n",
      "        [0.0035],\n",
      "        [0.0079],\n",
      "        [0.0027],\n",
      "        [0.0038],\n",
      "        [0.0029],\n",
      "        [0.0051],\n",
      "        [0.0071],\n",
      "        [0.0028],\n",
      "        [0.0007],\n",
      "        [0.0035],\n",
      "        [0.0029],\n",
      "        [0.0132],\n",
      "        [0.0159],\n",
      "        [0.0270],\n",
      "        [0.0348]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(    0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0019],\n",
      "        [    0.0001],\n",
      "        [    0.0005],\n",
      "        [    0.0021],\n",
      "        [    0.0011],\n",
      "        [    0.0002],\n",
      "        [    0.0016],\n",
      "        [    0.0015],\n",
      "        [    0.0012],\n",
      "        [    0.0011],\n",
      "        [    0.0030],\n",
      "        [    0.0036],\n",
      "        [    0.0139],\n",
      "        [    0.0003],\n",
      "        [    0.0038],\n",
      "        [    0.0032],\n",
      "        [    0.0053],\n",
      "        [    0.0132],\n",
      "        [    0.0026],\n",
      "        [    0.0005],\n",
      "        [    0.0025],\n",
      "        [    0.0015],\n",
      "        [    0.0119],\n",
      "        [    0.0098],\n",
      "        [    0.0258],\n",
      "        [    0.0287]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 4.914279460906982\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 29\n",
      "剩餘X 資料 torch.Size([78, 18])\n",
      "剩餘Y 資料 torch.Size([78, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0008317596511915326, 40)\n",
      "The second_loss value of k: (0.001104047172702849, 13)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引40，y= tensor([0.8356])\n",
      "目前模型的Data狀態 torch.Size([29, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9928],\n",
      "        [0.9791],\n",
      "        [0.9992],\n",
      "        [0.9835],\n",
      "        [0.9795],\n",
      "        [0.9652],\n",
      "        [0.9427],\n",
      "        [0.8891],\n",
      "        [0.9125],\n",
      "        [0.9352],\n",
      "        [0.9147],\n",
      "        [0.8523],\n",
      "        [0.8518],\n",
      "        [0.8419],\n",
      "        [0.8068],\n",
      "        [0.8068],\n",
      "        [0.8277],\n",
      "        [0.8068],\n",
      "        [0.8439],\n",
      "        [0.8068],\n",
      "        [0.8068],\n",
      "        [0.8630],\n",
      "        [0.8068],\n",
      "        [0.9685],\n",
      "        [0.8544],\n",
      "        [0.8068],\n",
      "        [0.8403],\n",
      "        [0.8068],\n",
      "        [0.8068]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0000],\n",
      "        [    0.0019],\n",
      "        [    0.0001],\n",
      "        [    0.0005],\n",
      "        [    0.0021],\n",
      "        [    0.0011],\n",
      "        [    0.0002],\n",
      "        [    0.0016],\n",
      "        [    0.0015],\n",
      "        [    0.0012],\n",
      "        [    0.0011],\n",
      "        [    0.0030],\n",
      "        [    0.0036],\n",
      "        [    0.0139],\n",
      "        [    0.0003],\n",
      "        [    0.0038],\n",
      "        [    0.0032],\n",
      "        [    0.0053],\n",
      "        [    0.0132],\n",
      "        [    0.0026],\n",
      "        [    0.0005],\n",
      "        [    0.0025],\n",
      "        [    0.0015],\n",
      "        [    0.0119],\n",
      "        [    0.0098],\n",
      "        [    0.0258],\n",
      "        [    0.0287],\n",
      "        [    0.0288]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0024],\n",
      "        [    0.0004],\n",
      "        [    0.0003],\n",
      "        [    0.0022],\n",
      "        [    0.0009],\n",
      "        [    0.0007],\n",
      "        [    0.0015],\n",
      "        [    0.0013],\n",
      "        [    0.0010],\n",
      "        [    0.0008],\n",
      "        [    0.0030],\n",
      "        [    0.0037],\n",
      "        [    0.0175],\n",
      "        [    0.0038],\n",
      "        [    0.0039],\n",
      "        [    0.0067],\n",
      "        [    0.0057],\n",
      "        [    0.0167],\n",
      "        [    0.0009],\n",
      "        [    0.0019],\n",
      "        [    0.0061],\n",
      "        [    0.0000],\n",
      "        [    0.0104],\n",
      "        [    0.0063],\n",
      "        [    0.0244],\n",
      "        [    0.0251],\n",
      "        [    0.0253]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.249586820602417\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 30\n",
      "剩餘X 資料 torch.Size([77, 18])\n",
      "剩餘Y 資料 torch.Size([77, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0008811933803372085, 13)\n",
      "The second_loss value of k: (0.002038827631622553, 34)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引13，y= tensor([0.8400])\n",
      "目前模型的Data狀態 torch.Size([30, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9928],\n",
      "        [0.9791],\n",
      "        [0.9996],\n",
      "        [0.9837],\n",
      "        [0.9797],\n",
      "        [0.9652],\n",
      "        [0.9429],\n",
      "        [0.8896],\n",
      "        [0.9126],\n",
      "        [0.9354],\n",
      "        [0.9149],\n",
      "        [0.8525],\n",
      "        [0.8518],\n",
      "        [0.8417],\n",
      "        [0.8103],\n",
      "        [0.8103],\n",
      "        [0.8276],\n",
      "        [0.8103],\n",
      "        [0.8435],\n",
      "        [0.8103],\n",
      "        [0.8103],\n",
      "        [0.8616],\n",
      "        [0.8103],\n",
      "        [0.9670],\n",
      "        [0.8529],\n",
      "        [0.8103],\n",
      "        [0.8388],\n",
      "        [0.8103],\n",
      "        [0.8103],\n",
      "        [0.8103]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0024],\n",
      "        [    0.0004],\n",
      "        [    0.0003],\n",
      "        [    0.0022],\n",
      "        [    0.0009],\n",
      "        [    0.0007],\n",
      "        [    0.0015],\n",
      "        [    0.0013],\n",
      "        [    0.0010],\n",
      "        [    0.0008],\n",
      "        [    0.0030],\n",
      "        [    0.0037],\n",
      "        [    0.0175],\n",
      "        [    0.0038],\n",
      "        [    0.0039],\n",
      "        [    0.0067],\n",
      "        [    0.0057],\n",
      "        [    0.0167],\n",
      "        [    0.0009],\n",
      "        [    0.0019],\n",
      "        [    0.0061],\n",
      "        [    0.0000],\n",
      "        [    0.0104],\n",
      "        [    0.0063],\n",
      "        [    0.0244],\n",
      "        [    0.0251],\n",
      "        [    0.0253],\n",
      "        [    0.0297]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0006],\n",
      "        [    0.0005],\n",
      "        [    0.0021],\n",
      "        [    0.0001],\n",
      "        [    0.0008],\n",
      "        [    0.0028],\n",
      "        [    0.0014],\n",
      "        [    0.0004],\n",
      "        [    0.0020],\n",
      "        [    0.0016],\n",
      "        [    0.0013],\n",
      "        [    0.0011],\n",
      "        [    0.0035],\n",
      "        [    0.0043],\n",
      "        [    0.0205],\n",
      "        [    0.0068],\n",
      "        [    0.0044],\n",
      "        [    0.0097],\n",
      "        [    0.0065],\n",
      "        [    0.0197],\n",
      "        [    0.0039],\n",
      "        [    0.0034],\n",
      "        [    0.0091],\n",
      "        [    0.0015],\n",
      "        [    0.0088],\n",
      "        [    0.0033],\n",
      "        [    0.0228],\n",
      "        [    0.0221],\n",
      "        [    0.0223],\n",
      "        [    0.0267]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.603264093399048\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 31\n",
      "剩餘X 資料 torch.Size([76, 18])\n",
      "剩餘Y 資料 torch.Size([76, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.001976368250325322, 33)\n",
      "The second_loss value of k: (0.002332691103219986, 37)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引33，y= tensor([0.9594])\n",
      "目前模型的Data狀態 torch.Size([31, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9921],\n",
      "        [0.9785],\n",
      "        [0.9994],\n",
      "        [0.9833],\n",
      "        [0.9792],\n",
      "        [0.9645],\n",
      "        [0.9424],\n",
      "        [0.8894],\n",
      "        [0.9121],\n",
      "        [0.9350],\n",
      "        [0.9146],\n",
      "        [0.8522],\n",
      "        [0.8513],\n",
      "        [0.8411],\n",
      "        [0.8134],\n",
      "        [0.8134],\n",
      "        [0.8271],\n",
      "        [0.8134],\n",
      "        [0.8427],\n",
      "        [0.8134],\n",
      "        [0.8134],\n",
      "        [0.8602],\n",
      "        [0.8134],\n",
      "        [0.9654],\n",
      "        [0.8513],\n",
      "        [0.8134],\n",
      "        [0.8372],\n",
      "        [0.8134],\n",
      "        [0.8134],\n",
      "        [0.8134],\n",
      "        [1.0038]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0006],\n",
      "        [    0.0005],\n",
      "        [    0.0021],\n",
      "        [    0.0001],\n",
      "        [    0.0008],\n",
      "        [    0.0028],\n",
      "        [    0.0014],\n",
      "        [    0.0004],\n",
      "        [    0.0020],\n",
      "        [    0.0016],\n",
      "        [    0.0013],\n",
      "        [    0.0011],\n",
      "        [    0.0035],\n",
      "        [    0.0043],\n",
      "        [    0.0205],\n",
      "        [    0.0068],\n",
      "        [    0.0044],\n",
      "        [    0.0097],\n",
      "        [    0.0065],\n",
      "        [    0.0197],\n",
      "        [    0.0039],\n",
      "        [    0.0034],\n",
      "        [    0.0091],\n",
      "        [    0.0015],\n",
      "        [    0.0088],\n",
      "        [    0.0033],\n",
      "        [    0.0228],\n",
      "        [    0.0221],\n",
      "        [    0.0223],\n",
      "        [    0.0267],\n",
      "        [    0.0445]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0012],\n",
      "        [0.0010],\n",
      "        [0.0016],\n",
      "        [0.0010],\n",
      "        [0.0018],\n",
      "        [0.0039],\n",
      "        [0.0024],\n",
      "        [0.0002],\n",
      "        [0.0027],\n",
      "        [0.0021],\n",
      "        [0.0018],\n",
      "        [0.0014],\n",
      "        [0.0043],\n",
      "        [0.0052],\n",
      "        [0.0204],\n",
      "        [0.0068],\n",
      "        [0.0059],\n",
      "        [0.0097],\n",
      "        [0.0078],\n",
      "        [0.0197],\n",
      "        [0.0039],\n",
      "        [0.0059],\n",
      "        [0.0090],\n",
      "        [0.0042],\n",
      "        [0.0062],\n",
      "        [0.0033],\n",
      "        [0.0204],\n",
      "        [0.0222],\n",
      "        [0.0223],\n",
      "        [0.0267],\n",
      "        [0.0414]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 5.957314491271973\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 32\n",
      "剩餘X 資料 torch.Size([75, 18])\n",
      "剩餘Y 資料 torch.Size([75, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.002336803823709488, 36)\n",
      "The second_loss value of k: (0.002779091475531459, 43)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引36，y= tensor([0.8617])\n",
      "目前模型的Data狀態 torch.Size([32, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9915],\n",
      "        [0.9780],\n",
      "        [0.9988],\n",
      "        [0.9824],\n",
      "        [0.9782],\n",
      "        [0.9634],\n",
      "        [0.9414],\n",
      "        [0.8887],\n",
      "        [0.9114],\n",
      "        [0.9345],\n",
      "        [0.9141],\n",
      "        [0.8519],\n",
      "        [0.8505],\n",
      "        [0.8402],\n",
      "        [0.8133],\n",
      "        [0.8133],\n",
      "        [0.8256],\n",
      "        [0.8133],\n",
      "        [0.8414],\n",
      "        [0.8133],\n",
      "        [0.8133],\n",
      "        [0.8576],\n",
      "        [0.8133],\n",
      "        [0.9627],\n",
      "        [0.8488],\n",
      "        [0.8133],\n",
      "        [0.8348],\n",
      "        [0.8133],\n",
      "        [0.8133],\n",
      "        [0.8133],\n",
      "        [1.0007],\n",
      "        [0.8133]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0012],\n",
      "        [0.0010],\n",
      "        [0.0016],\n",
      "        [0.0010],\n",
      "        [0.0018],\n",
      "        [0.0039],\n",
      "        [0.0024],\n",
      "        [0.0002],\n",
      "        [0.0027],\n",
      "        [0.0021],\n",
      "        [0.0018],\n",
      "        [0.0014],\n",
      "        [0.0043],\n",
      "        [0.0052],\n",
      "        [0.0204],\n",
      "        [0.0068],\n",
      "        [0.0059],\n",
      "        [0.0097],\n",
      "        [0.0078],\n",
      "        [0.0197],\n",
      "        [0.0039],\n",
      "        [0.0059],\n",
      "        [0.0090],\n",
      "        [0.0042],\n",
      "        [0.0062],\n",
      "        [0.0033],\n",
      "        [0.0204],\n",
      "        [0.0222],\n",
      "        [0.0223],\n",
      "        [0.0267],\n",
      "        [0.0414],\n",
      "        [0.0483]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0008],\n",
      "        [    0.0006],\n",
      "        [    0.0018],\n",
      "        [    0.0009],\n",
      "        [    0.0019],\n",
      "        [    0.0039],\n",
      "        [    0.0024],\n",
      "        [    0.0000],\n",
      "        [    0.0024],\n",
      "        [    0.0017],\n",
      "        [    0.0012],\n",
      "        [    0.0007],\n",
      "        [    0.0039],\n",
      "        [    0.0049],\n",
      "        [    0.0249],\n",
      "        [    0.0112],\n",
      "        [    0.0060],\n",
      "        [    0.0141],\n",
      "        [    0.0075],\n",
      "        [    0.0241],\n",
      "        [    0.0083],\n",
      "        [    0.0064],\n",
      "        [    0.0135],\n",
      "        [    0.0050],\n",
      "        [    0.0057],\n",
      "        [    0.0011],\n",
      "        [    0.0200],\n",
      "        [    0.0177],\n",
      "        [    0.0179],\n",
      "        [    0.0223],\n",
      "        [    0.0398],\n",
      "        [    0.0439]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.322644472122192\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 33\n",
      "剩餘X 資料 torch.Size([74, 18])\n",
      "剩餘Y 資料 torch.Size([74, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0032024101819843054, 36)\n",
      "The second_loss value of k: (0.0032671180088073015, 42)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引36，y= tensor([0.8743])\n",
      "目前模型的Data狀態 torch.Size([33, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9919],\n",
      "        [0.9784],\n",
      "        [0.9991],\n",
      "        [0.9824],\n",
      "        [0.9781],\n",
      "        [0.9634],\n",
      "        [0.9413],\n",
      "        [0.8890],\n",
      "        [0.9117],\n",
      "        [0.9350],\n",
      "        [0.9147],\n",
      "        [0.8527],\n",
      "        [0.8509],\n",
      "        [0.8405],\n",
      "        [0.8178],\n",
      "        [0.8178],\n",
      "        [0.8255],\n",
      "        [0.8178],\n",
      "        [0.8417],\n",
      "        [0.8178],\n",
      "        [0.8178],\n",
      "        [0.8571],\n",
      "        [0.8178],\n",
      "        [0.9619],\n",
      "        [0.8482],\n",
      "        [0.8178],\n",
      "        [0.8344],\n",
      "        [0.8178],\n",
      "        [0.8178],\n",
      "        [0.8178],\n",
      "        [0.9992],\n",
      "        [0.8178],\n",
      "        [0.8178]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0008],\n",
      "        [    0.0006],\n",
      "        [    0.0018],\n",
      "        [    0.0009],\n",
      "        [    0.0019],\n",
      "        [    0.0039],\n",
      "        [    0.0024],\n",
      "        [    0.0000],\n",
      "        [    0.0024],\n",
      "        [    0.0017],\n",
      "        [    0.0012],\n",
      "        [    0.0007],\n",
      "        [    0.0039],\n",
      "        [    0.0049],\n",
      "        [    0.0249],\n",
      "        [    0.0112],\n",
      "        [    0.0060],\n",
      "        [    0.0141],\n",
      "        [    0.0075],\n",
      "        [    0.0241],\n",
      "        [    0.0083],\n",
      "        [    0.0064],\n",
      "        [    0.0135],\n",
      "        [    0.0050],\n",
      "        [    0.0057],\n",
      "        [    0.0011],\n",
      "        [    0.0200],\n",
      "        [    0.0177],\n",
      "        [    0.0179],\n",
      "        [    0.0223],\n",
      "        [    0.0398],\n",
      "        [    0.0439],\n",
      "        [    0.0566]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 75\n",
      "Number of shrink: 25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0016],\n",
      "        [0.0014],\n",
      "        [0.0008],\n",
      "        [0.0022],\n",
      "        [0.0033],\n",
      "        [0.0052],\n",
      "        [0.0038],\n",
      "        [0.0011],\n",
      "        [0.0033],\n",
      "        [0.0025],\n",
      "        [0.0019],\n",
      "        [0.0012],\n",
      "        [0.0046],\n",
      "        [0.0057],\n",
      "        [0.0295],\n",
      "        [0.0159],\n",
      "        [0.0071],\n",
      "        [0.0188],\n",
      "        [0.0081],\n",
      "        [0.0288],\n",
      "        [0.0130],\n",
      "        [0.0077],\n",
      "        [0.0181],\n",
      "        [0.0066],\n",
      "        [0.0045],\n",
      "        [0.0058],\n",
      "        [0.0188],\n",
      "        [0.0131],\n",
      "        [0.0132],\n",
      "        [0.0176],\n",
      "        [0.0374],\n",
      "        [0.0392],\n",
      "        [0.0519]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 6.671383857727051\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 34\n",
      "剩餘X 資料 torch.Size([73, 18])\n",
      "剩餘Y 資料 torch.Size([73, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.003710033604875207, 35)\n",
      "The second_loss value of k: (0.0038202719297260046, 41)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引35，y= tensor([0.8833])\n",
      "目前模型的Data狀態 torch.Size([34, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9911],\n",
      "        [0.9776],\n",
      "        [0.9980],\n",
      "        [0.9812],\n",
      "        [0.9767],\n",
      "        [0.9621],\n",
      "        [0.9400],\n",
      "        [0.8879],\n",
      "        [0.9108],\n",
      "        [0.9342],\n",
      "        [0.9140],\n",
      "        [0.8522],\n",
      "        [0.8501],\n",
      "        [0.8397],\n",
      "        [0.8224],\n",
      "        [0.8224],\n",
      "        [0.8244],\n",
      "        [0.8224],\n",
      "        [0.8411],\n",
      "        [0.8224],\n",
      "        [0.8224],\n",
      "        [0.8559],\n",
      "        [0.8224],\n",
      "        [0.9603],\n",
      "        [0.8470],\n",
      "        [0.8224],\n",
      "        [0.8332],\n",
      "        [0.8224],\n",
      "        [0.8224],\n",
      "        [0.8224],\n",
      "        [0.9968],\n",
      "        [0.8224],\n",
      "        [0.8224],\n",
      "        [0.8224]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0016],\n",
      "        [0.0014],\n",
      "        [0.0008],\n",
      "        [0.0022],\n",
      "        [0.0033],\n",
      "        [0.0052],\n",
      "        [0.0038],\n",
      "        [0.0011],\n",
      "        [0.0033],\n",
      "        [0.0025],\n",
      "        [0.0019],\n",
      "        [0.0012],\n",
      "        [0.0046],\n",
      "        [0.0057],\n",
      "        [0.0295],\n",
      "        [0.0159],\n",
      "        [0.0071],\n",
      "        [0.0188],\n",
      "        [0.0081],\n",
      "        [0.0288],\n",
      "        [0.0130],\n",
      "        [0.0077],\n",
      "        [0.0181],\n",
      "        [0.0066],\n",
      "        [0.0045],\n",
      "        [0.0058],\n",
      "        [0.0188],\n",
      "        [0.0131],\n",
      "        [0.0132],\n",
      "        [0.0176],\n",
      "        [0.0374],\n",
      "        [0.0392],\n",
      "        [0.0519],\n",
      "        [0.0609]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0016],\n",
      "        [0.0015],\n",
      "        [0.0005],\n",
      "        [0.0026],\n",
      "        [0.0039],\n",
      "        [0.0057],\n",
      "        [0.0043],\n",
      "        [0.0014],\n",
      "        [0.0036],\n",
      "        [0.0026],\n",
      "        [0.0019],\n",
      "        [0.0011],\n",
      "        [0.0048],\n",
      "        [0.0059],\n",
      "        [0.0345],\n",
      "        [0.0209],\n",
      "        [0.0041],\n",
      "        [0.0238],\n",
      "        [0.0081],\n",
      "        [0.0338],\n",
      "        [0.0180],\n",
      "        [0.0082],\n",
      "        [0.0231],\n",
      "        [0.0074],\n",
      "        [0.0039],\n",
      "        [0.0107],\n",
      "        [0.0183],\n",
      "        [0.0081],\n",
      "        [0.0082],\n",
      "        [0.0126],\n",
      "        [0.0358],\n",
      "        [0.0343],\n",
      "        [0.0469],\n",
      "        [0.0559]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.000786781311035\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 35\n",
      "剩餘X 資料 torch.Size([72, 18])\n",
      "剩餘Y 資料 torch.Size([72, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004462383221834898, 40)\n",
      "The second_loss value of k: (0.004733263980597258, 42)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引40，y= tensor([0.7606])\n",
      "目前模型的Data狀態 torch.Size([35, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9912],\n",
      "        [0.9776],\n",
      "        [0.9977],\n",
      "        [0.9807],\n",
      "        [0.9762],\n",
      "        [0.9617],\n",
      "        [0.9395],\n",
      "        [0.8875],\n",
      "        [0.9105],\n",
      "        [0.9341],\n",
      "        [0.9140],\n",
      "        [0.8522],\n",
      "        [0.8500],\n",
      "        [0.8395],\n",
      "        [0.8274],\n",
      "        [0.8274],\n",
      "        [0.8274],\n",
      "        [0.8274],\n",
      "        [0.8411],\n",
      "        [0.8274],\n",
      "        [0.8274],\n",
      "        [0.8553],\n",
      "        [0.8274],\n",
      "        [0.9595],\n",
      "        [0.8465],\n",
      "        [0.8274],\n",
      "        [0.8327],\n",
      "        [0.8274],\n",
      "        [0.8274],\n",
      "        [0.8274],\n",
      "        [0.9952],\n",
      "        [0.8274],\n",
      "        [0.8274],\n",
      "        [0.8274],\n",
      "        [0.8274]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0016],\n",
      "        [0.0015],\n",
      "        [0.0005],\n",
      "        [0.0026],\n",
      "        [0.0039],\n",
      "        [0.0057],\n",
      "        [0.0043],\n",
      "        [0.0014],\n",
      "        [0.0036],\n",
      "        [0.0026],\n",
      "        [0.0019],\n",
      "        [0.0011],\n",
      "        [0.0048],\n",
      "        [0.0059],\n",
      "        [0.0345],\n",
      "        [0.0209],\n",
      "        [0.0041],\n",
      "        [0.0238],\n",
      "        [0.0081],\n",
      "        [0.0338],\n",
      "        [0.0180],\n",
      "        [0.0082],\n",
      "        [0.0231],\n",
      "        [0.0074],\n",
      "        [0.0039],\n",
      "        [0.0107],\n",
      "        [0.0183],\n",
      "        [0.0081],\n",
      "        [0.0082],\n",
      "        [0.0126],\n",
      "        [0.0358],\n",
      "        [0.0343],\n",
      "        [0.0469],\n",
      "        [0.0559],\n",
      "        [0.0668]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0003],\n",
      "        [0.0001],\n",
      "        [0.0023],\n",
      "        [0.0010],\n",
      "        [0.0022],\n",
      "        [0.0041],\n",
      "        [0.0026],\n",
      "        [0.0006],\n",
      "        [0.0017],\n",
      "        [0.0005],\n",
      "        [0.0001],\n",
      "        [0.0009],\n",
      "        [0.0031],\n",
      "        [0.0044],\n",
      "        [0.0297],\n",
      "        [0.0160],\n",
      "        [0.0068],\n",
      "        [0.0189],\n",
      "        [0.0076],\n",
      "        [0.0289],\n",
      "        [0.0131],\n",
      "        [0.0085],\n",
      "        [0.0183],\n",
      "        [0.0075],\n",
      "        [0.0036],\n",
      "        [0.0059],\n",
      "        [0.0180],\n",
      "        [0.0129],\n",
      "        [0.0131],\n",
      "        [0.0175],\n",
      "        [0.0353],\n",
      "        [0.0391],\n",
      "        [0.0518],\n",
      "        [0.0608],\n",
      "        [0.0620]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.345968961715698\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 36\n",
      "剩餘X 資料 torch.Size([71, 18])\n",
      "剩餘Y 資料 torch.Size([71, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004091409966349602, 41)\n",
      "The second_loss value of k: (0.005816101096570492, 40)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引41，y= tensor([0.7586])\n",
      "目前模型的Data狀態 torch.Size([36, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9925],\n",
      "        [0.9792],\n",
      "        [0.9996],\n",
      "        [0.9824],\n",
      "        [0.9778],\n",
      "        [0.9632],\n",
      "        [0.9412],\n",
      "        [0.8896],\n",
      "        [0.9124],\n",
      "        [0.9362],\n",
      "        [0.9160],\n",
      "        [0.8543],\n",
      "        [0.8516],\n",
      "        [0.8410],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8247],\n",
      "        [0.8226],\n",
      "        [0.8416],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8550],\n",
      "        [0.8226],\n",
      "        [0.9595],\n",
      "        [0.8461],\n",
      "        [0.8226],\n",
      "        [0.8324],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.9947],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8226],\n",
      "        [0.8226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0003],\n",
      "        [0.0001],\n",
      "        [0.0023],\n",
      "        [0.0010],\n",
      "        [0.0022],\n",
      "        [0.0041],\n",
      "        [0.0026],\n",
      "        [0.0006],\n",
      "        [0.0017],\n",
      "        [0.0005],\n",
      "        [0.0001],\n",
      "        [0.0009],\n",
      "        [0.0031],\n",
      "        [0.0044],\n",
      "        [0.0297],\n",
      "        [0.0160],\n",
      "        [0.0068],\n",
      "        [0.0189],\n",
      "        [0.0076],\n",
      "        [0.0289],\n",
      "        [0.0131],\n",
      "        [0.0085],\n",
      "        [0.0183],\n",
      "        [0.0075],\n",
      "        [0.0036],\n",
      "        [0.0059],\n",
      "        [0.0180],\n",
      "        [0.0129],\n",
      "        [0.0131],\n",
      "        [0.0175],\n",
      "        [0.0353],\n",
      "        [0.0391],\n",
      "        [0.0518],\n",
      "        [0.0608],\n",
      "        [0.0620],\n",
      "        [0.0640]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0011],\n",
      "        [    0.0005],\n",
      "        [    0.0017],\n",
      "        [    0.0016],\n",
      "        [    0.0028],\n",
      "        [    0.0047],\n",
      "        [    0.0031],\n",
      "        [    0.0003],\n",
      "        [    0.0019],\n",
      "        [    0.0006],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0034],\n",
      "        [    0.0048],\n",
      "        [    0.0254],\n",
      "        [    0.0117],\n",
      "        [    0.0076],\n",
      "        [    0.0146],\n",
      "        [    0.0085],\n",
      "        [    0.0247],\n",
      "        [    0.0088],\n",
      "        [    0.0099],\n",
      "        [    0.0140],\n",
      "        [    0.0089],\n",
      "        [    0.0021],\n",
      "        [    0.0016],\n",
      "        [    0.0164],\n",
      "        [    0.0172],\n",
      "        [    0.0174],\n",
      "        [    0.0217],\n",
      "        [    0.0331],\n",
      "        [    0.0434],\n",
      "        [    0.0561],\n",
      "        [    0.0650],\n",
      "        [    0.0577],\n",
      "        [    0.0597]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 7.681040525436401\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 37\n",
      "剩餘X 資料 torch.Size([70, 18])\n",
      "剩餘Y 資料 torch.Size([70, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005182184278964996, 40)\n",
      "The second_loss value of k: (0.005204769782721996, 38)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引40，y= tensor([0.7463])\n",
      "目前模型的Data狀態 torch.Size([37, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9916],\n",
      "        [0.9786],\n",
      "        [0.9990],\n",
      "        [0.9817],\n",
      "        [0.9772],\n",
      "        [0.9626],\n",
      "        [0.9407],\n",
      "        [0.8893],\n",
      "        [0.9122],\n",
      "        [0.9361],\n",
      "        [0.9160],\n",
      "        [0.8543],\n",
      "        [0.8514],\n",
      "        [0.8406],\n",
      "        [0.8183],\n",
      "        [0.8183],\n",
      "        [0.8239],\n",
      "        [0.8183],\n",
      "        [0.8407],\n",
      "        [0.8183],\n",
      "        [0.8183],\n",
      "        [0.8536],\n",
      "        [0.8183],\n",
      "        [0.9581],\n",
      "        [0.8446],\n",
      "        [0.8183],\n",
      "        [0.8309],\n",
      "        [0.8183],\n",
      "        [0.8183],\n",
      "        [0.8183],\n",
      "        [0.9925],\n",
      "        [0.8183],\n",
      "        [0.8183],\n",
      "        [0.8183],\n",
      "        [0.8183],\n",
      "        [0.8183],\n",
      "        [0.8183]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0011],\n",
      "        [    0.0005],\n",
      "        [    0.0017],\n",
      "        [    0.0016],\n",
      "        [    0.0028],\n",
      "        [    0.0047],\n",
      "        [    0.0031],\n",
      "        [    0.0003],\n",
      "        [    0.0019],\n",
      "        [    0.0006],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0034],\n",
      "        [    0.0048],\n",
      "        [    0.0254],\n",
      "        [    0.0117],\n",
      "        [    0.0076],\n",
      "        [    0.0146],\n",
      "        [    0.0085],\n",
      "        [    0.0247],\n",
      "        [    0.0088],\n",
      "        [    0.0099],\n",
      "        [    0.0140],\n",
      "        [    0.0089],\n",
      "        [    0.0021],\n",
      "        [    0.0016],\n",
      "        [    0.0164],\n",
      "        [    0.0172],\n",
      "        [    0.0174],\n",
      "        [    0.0217],\n",
      "        [    0.0331],\n",
      "        [    0.0434],\n",
      "        [    0.0561],\n",
      "        [    0.0650],\n",
      "        [    0.0577],\n",
      "        [    0.0597],\n",
      "        [    0.0720]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0007],\n",
      "        [0.0002],\n",
      "        [0.0025],\n",
      "        [0.0009],\n",
      "        [0.0021],\n",
      "        [0.0040],\n",
      "        [0.0023],\n",
      "        [0.0014],\n",
      "        [0.0008],\n",
      "        [0.0007],\n",
      "        [0.0013],\n",
      "        [0.0022],\n",
      "        [0.0023],\n",
      "        [0.0039],\n",
      "        [0.0210],\n",
      "        [0.0074],\n",
      "        [0.0071],\n",
      "        [0.0102],\n",
      "        [0.0082],\n",
      "        [0.0203],\n",
      "        [0.0045],\n",
      "        [0.0100],\n",
      "        [0.0096],\n",
      "        [0.0088],\n",
      "        [0.0019],\n",
      "        [0.0028],\n",
      "        [0.0162],\n",
      "        [0.0216],\n",
      "        [0.0218],\n",
      "        [0.0261],\n",
      "        [0.0324],\n",
      "        [0.0478],\n",
      "        [0.0605],\n",
      "        [0.0694],\n",
      "        [0.0533],\n",
      "        [0.0553],\n",
      "        [0.0676]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.03150987625122\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 38\n",
      "剩餘X 資料 torch.Size([69, 18])\n",
      "剩餘Y 資料 torch.Size([69, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004590132273733616, 38)\n",
      "The second_loss value of k: (0.004675440955907106, 39)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引38，y= tensor([0.7461])\n",
      "目前模型的Data狀態 torch.Size([38, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9920],\n",
      "        [0.9793],\n",
      "        [0.9997],\n",
      "        [0.9825],\n",
      "        [0.9780],\n",
      "        [0.9634],\n",
      "        [0.9415],\n",
      "        [0.8904],\n",
      "        [0.9133],\n",
      "        [0.9373],\n",
      "        [0.9172],\n",
      "        [0.8556],\n",
      "        [0.8525],\n",
      "        [0.8415],\n",
      "        [0.8139],\n",
      "        [0.8139],\n",
      "        [0.8244],\n",
      "        [0.8139],\n",
      "        [0.8410],\n",
      "        [0.8139],\n",
      "        [0.8139],\n",
      "        [0.8535],\n",
      "        [0.8139],\n",
      "        [0.9581],\n",
      "        [0.8444],\n",
      "        [0.8139],\n",
      "        [0.8307],\n",
      "        [0.8139],\n",
      "        [0.8139],\n",
      "        [0.8139],\n",
      "        [0.9918],\n",
      "        [0.8139],\n",
      "        [0.8139],\n",
      "        [0.8139],\n",
      "        [0.8139],\n",
      "        [0.8139],\n",
      "        [0.8139],\n",
      "        [0.8139]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0007],\n",
      "        [0.0002],\n",
      "        [0.0025],\n",
      "        [0.0009],\n",
      "        [0.0021],\n",
      "        [0.0040],\n",
      "        [0.0023],\n",
      "        [0.0014],\n",
      "        [0.0008],\n",
      "        [0.0007],\n",
      "        [0.0013],\n",
      "        [0.0022],\n",
      "        [0.0023],\n",
      "        [0.0039],\n",
      "        [0.0210],\n",
      "        [0.0074],\n",
      "        [0.0071],\n",
      "        [0.0102],\n",
      "        [0.0082],\n",
      "        [0.0203],\n",
      "        [0.0045],\n",
      "        [0.0100],\n",
      "        [0.0096],\n",
      "        [0.0088],\n",
      "        [0.0019],\n",
      "        [0.0028],\n",
      "        [0.0162],\n",
      "        [0.0216],\n",
      "        [0.0218],\n",
      "        [0.0261],\n",
      "        [0.0324],\n",
      "        [0.0478],\n",
      "        [0.0605],\n",
      "        [0.0694],\n",
      "        [0.0533],\n",
      "        [0.0553],\n",
      "        [0.0676],\n",
      "        [0.0678]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0015],\n",
      "        [0.0003],\n",
      "        [0.0019],\n",
      "        [0.0015],\n",
      "        [0.0027],\n",
      "        [0.0045],\n",
      "        [0.0028],\n",
      "        [0.0011],\n",
      "        [0.0010],\n",
      "        [0.0006],\n",
      "        [0.0012],\n",
      "        [0.0022],\n",
      "        [0.0024],\n",
      "        [0.0042],\n",
      "        [0.0170],\n",
      "        [0.0033],\n",
      "        [0.0077],\n",
      "        [0.0062],\n",
      "        [0.0088],\n",
      "        [0.0163],\n",
      "        [0.0004],\n",
      "        [0.0109],\n",
      "        [0.0056],\n",
      "        [0.0096],\n",
      "        [0.0010],\n",
      "        [0.0068],\n",
      "        [0.0152],\n",
      "        [0.0256],\n",
      "        [0.0258],\n",
      "        [0.0301],\n",
      "        [0.0306],\n",
      "        [0.0518],\n",
      "        [0.0645],\n",
      "        [0.0734],\n",
      "        [0.0493],\n",
      "        [0.0513],\n",
      "        [0.0636],\n",
      "        [0.0637]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.38388729095459\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 39\n",
      "剩餘X 資料 torch.Size([68, 18])\n",
      "剩餘Y 資料 torch.Size([68, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004143156111240387, 38)\n",
      "The second_loss value of k: (0.005534589756280184, 49)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引38，y= tensor([0.7455])\n",
      "目前模型的Data狀態 torch.Size([39, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9912],\n",
      "        [0.9787],\n",
      "        [0.9991],\n",
      "        [0.9818],\n",
      "        [0.9773],\n",
      "        [0.9628],\n",
      "        [0.9410],\n",
      "        [0.8901],\n",
      "        [0.9131],\n",
      "        [0.9373],\n",
      "        [0.9171],\n",
      "        [0.8556],\n",
      "        [0.8523],\n",
      "        [0.8413],\n",
      "        [0.8099],\n",
      "        [0.8099],\n",
      "        [0.8238],\n",
      "        [0.8099],\n",
      "        [0.8404],\n",
      "        [0.8099],\n",
      "        [0.8099],\n",
      "        [0.8526],\n",
      "        [0.8099],\n",
      "        [0.9573],\n",
      "        [0.8436],\n",
      "        [0.8099],\n",
      "        [0.8297],\n",
      "        [0.8099],\n",
      "        [0.8099],\n",
      "        [0.8099],\n",
      "        [0.9900],\n",
      "        [0.8099],\n",
      "        [0.8099],\n",
      "        [0.8099],\n",
      "        [0.8099],\n",
      "        [0.8099],\n",
      "        [0.8099],\n",
      "        [0.8099],\n",
      "        [0.8099]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0015],\n",
      "        [0.0003],\n",
      "        [0.0019],\n",
      "        [0.0015],\n",
      "        [0.0027],\n",
      "        [0.0045],\n",
      "        [0.0028],\n",
      "        [0.0011],\n",
      "        [0.0010],\n",
      "        [0.0006],\n",
      "        [0.0012],\n",
      "        [0.0022],\n",
      "        [0.0024],\n",
      "        [0.0042],\n",
      "        [0.0170],\n",
      "        [0.0033],\n",
      "        [0.0077],\n",
      "        [0.0062],\n",
      "        [0.0088],\n",
      "        [0.0163],\n",
      "        [0.0004],\n",
      "        [0.0109],\n",
      "        [0.0056],\n",
      "        [0.0096],\n",
      "        [0.0010],\n",
      "        [0.0068],\n",
      "        [0.0152],\n",
      "        [0.0256],\n",
      "        [0.0258],\n",
      "        [0.0301],\n",
      "        [0.0306],\n",
      "        [0.0518],\n",
      "        [0.0645],\n",
      "        [0.0734],\n",
      "        [0.0493],\n",
      "        [0.0513],\n",
      "        [0.0636],\n",
      "        [0.0637],\n",
      "        [0.0644]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0013],\n",
      "        [    0.0001],\n",
      "        [    0.0022],\n",
      "        [    0.0012],\n",
      "        [    0.0023],\n",
      "        [    0.0040],\n",
      "        [    0.0023],\n",
      "        [    0.0018],\n",
      "        [    0.0003],\n",
      "        [    0.0015],\n",
      "        [    0.0021],\n",
      "        [    0.0031],\n",
      "        [    0.0016],\n",
      "        [    0.0035],\n",
      "        [    0.0135],\n",
      "        [    0.0002],\n",
      "        [    0.0073],\n",
      "        [    0.0027],\n",
      "        [    0.0085],\n",
      "        [    0.0128],\n",
      "        [    0.0031],\n",
      "        [    0.0108],\n",
      "        [    0.0021],\n",
      "        [    0.0094],\n",
      "        [    0.0011],\n",
      "        [    0.0103],\n",
      "        [    0.0152],\n",
      "        [    0.0291],\n",
      "        [    0.0293],\n",
      "        [    0.0337],\n",
      "        [    0.0299],\n",
      "        [    0.0553],\n",
      "        [    0.0680],\n",
      "        [    0.0769],\n",
      "        [    0.0458],\n",
      "        [    0.0478],\n",
      "        [    0.0601],\n",
      "        [    0.0602],\n",
      "        [    0.0609]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 8.759517908096313\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 40\n",
      "剩餘X 資料 torch.Size([67, 18])\n",
      "剩餘Y 資料 torch.Size([67, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005023956764489412, 48)\n",
      "The second_loss value of k: (0.005203213542699814, 49)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引48，y= tensor([0.7355])\n",
      "目前模型的Data狀態 torch.Size([40, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9914],\n",
      "        [0.9791],\n",
      "        [0.9995],\n",
      "        [0.9822],\n",
      "        [0.9778],\n",
      "        [0.9633],\n",
      "        [0.9415],\n",
      "        [0.8907],\n",
      "        [0.9138],\n",
      "        [0.9381],\n",
      "        [0.9180],\n",
      "        [0.8565],\n",
      "        [0.8531],\n",
      "        [0.8420],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.8242],\n",
      "        [0.8064],\n",
      "        [0.8407],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.8528],\n",
      "        [0.8064],\n",
      "        [0.9576],\n",
      "        [0.8436],\n",
      "        [0.8064],\n",
      "        [0.8297],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.9893],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.8064],\n",
      "        [0.8064]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0013],\n",
      "        [    0.0001],\n",
      "        [    0.0022],\n",
      "        [    0.0012],\n",
      "        [    0.0023],\n",
      "        [    0.0040],\n",
      "        [    0.0023],\n",
      "        [    0.0018],\n",
      "        [    0.0003],\n",
      "        [    0.0015],\n",
      "        [    0.0021],\n",
      "        [    0.0031],\n",
      "        [    0.0016],\n",
      "        [    0.0035],\n",
      "        [    0.0135],\n",
      "        [    0.0002],\n",
      "        [    0.0073],\n",
      "        [    0.0027],\n",
      "        [    0.0085],\n",
      "        [    0.0128],\n",
      "        [    0.0031],\n",
      "        [    0.0108],\n",
      "        [    0.0021],\n",
      "        [    0.0094],\n",
      "        [    0.0011],\n",
      "        [    0.0103],\n",
      "        [    0.0152],\n",
      "        [    0.0291],\n",
      "        [    0.0293],\n",
      "        [    0.0337],\n",
      "        [    0.0299],\n",
      "        [    0.0553],\n",
      "        [    0.0680],\n",
      "        [    0.0769],\n",
      "        [    0.0458],\n",
      "        [    0.0478],\n",
      "        [    0.0601],\n",
      "        [    0.0602],\n",
      "        [    0.0609],\n",
      "        [    0.0709]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0015],\n",
      "        [0.0001],\n",
      "        [0.0023],\n",
      "        [0.0011],\n",
      "        [0.0022],\n",
      "        [0.0039],\n",
      "        [0.0021],\n",
      "        [0.0021],\n",
      "        [0.0001],\n",
      "        [0.0020],\n",
      "        [0.0026],\n",
      "        [0.0037],\n",
      "        [0.0012],\n",
      "        [0.0031],\n",
      "        [0.0096],\n",
      "        [0.0020],\n",
      "        [0.0073],\n",
      "        [0.0012],\n",
      "        [0.0085],\n",
      "        [0.0088],\n",
      "        [0.0070],\n",
      "        [0.0109],\n",
      "        [0.0018],\n",
      "        [0.0094],\n",
      "        [0.0009],\n",
      "        [0.0142],\n",
      "        [0.0149],\n",
      "        [0.0330],\n",
      "        [0.0332],\n",
      "        [0.0376],\n",
      "        [0.0290],\n",
      "        [0.0592],\n",
      "        [0.0719],\n",
      "        [0.0809],\n",
      "        [0.0418],\n",
      "        [0.0438],\n",
      "        [0.0561],\n",
      "        [0.0563],\n",
      "        [0.0569],\n",
      "        [0.0670]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.120823621749878\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 41\n",
      "剩餘X 資料 torch.Size([66, 18])\n",
      "剩餘Y 資料 torch.Size([66, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004652369301766157, 48)\n",
      "The second_loss value of k: (0.006506715901196003, 38)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引48，y= tensor([0.7342])\n",
      "目前模型的Data狀態 torch.Size([41, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9913],\n",
      "        [0.9792],\n",
      "        [0.9995],\n",
      "        [0.9822],\n",
      "        [0.9778],\n",
      "        [0.9634],\n",
      "        [0.9417],\n",
      "        [0.8910],\n",
      "        [0.9142],\n",
      "        [0.9386],\n",
      "        [0.9185],\n",
      "        [0.8570],\n",
      "        [0.8536],\n",
      "        [0.8423],\n",
      "        [0.8024],\n",
      "        [0.8046],\n",
      "        [0.8243],\n",
      "        [0.8024],\n",
      "        [0.8407],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.8526],\n",
      "        [0.8024],\n",
      "        [0.9575],\n",
      "        [0.8435],\n",
      "        [0.8024],\n",
      "        [0.8294],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.9884],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.8024],\n",
      "        [0.8024]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0015],\n",
      "        [0.0001],\n",
      "        [0.0023],\n",
      "        [0.0011],\n",
      "        [0.0022],\n",
      "        [0.0039],\n",
      "        [0.0021],\n",
      "        [0.0021],\n",
      "        [0.0001],\n",
      "        [0.0020],\n",
      "        [0.0026],\n",
      "        [0.0037],\n",
      "        [0.0012],\n",
      "        [0.0031],\n",
      "        [0.0096],\n",
      "        [0.0020],\n",
      "        [0.0073],\n",
      "        [0.0012],\n",
      "        [0.0085],\n",
      "        [0.0088],\n",
      "        [0.0070],\n",
      "        [0.0109],\n",
      "        [0.0018],\n",
      "        [0.0094],\n",
      "        [0.0009],\n",
      "        [0.0142],\n",
      "        [0.0149],\n",
      "        [0.0330],\n",
      "        [0.0332],\n",
      "        [0.0376],\n",
      "        [0.0290],\n",
      "        [0.0592],\n",
      "        [0.0719],\n",
      "        [0.0809],\n",
      "        [0.0418],\n",
      "        [0.0438],\n",
      "        [0.0561],\n",
      "        [0.0563],\n",
      "        [0.0569],\n",
      "        [0.0670],\n",
      "        [0.0682]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0022],\n",
      "        [0.0004],\n",
      "        [0.0016],\n",
      "        [0.0018],\n",
      "        [0.0028],\n",
      "        [0.0044],\n",
      "        [0.0027],\n",
      "        [0.0017],\n",
      "        [0.0002],\n",
      "        [0.0018],\n",
      "        [0.0024],\n",
      "        [0.0036],\n",
      "        [0.0013],\n",
      "        [0.0034],\n",
      "        [0.0059],\n",
      "        [0.0023],\n",
      "        [0.0078],\n",
      "        [0.0048],\n",
      "        [0.0089],\n",
      "        [0.0052],\n",
      "        [0.0106],\n",
      "        [0.0115],\n",
      "        [0.0055],\n",
      "        [0.0099],\n",
      "        [0.0004],\n",
      "        [0.0178],\n",
      "        [0.0143],\n",
      "        [0.0367],\n",
      "        [0.0368],\n",
      "        [0.0412],\n",
      "        [0.0276],\n",
      "        [0.0628],\n",
      "        [0.0755],\n",
      "        [0.0845],\n",
      "        [0.0382],\n",
      "        [0.0402],\n",
      "        [0.0525],\n",
      "        [0.0527],\n",
      "        [0.0533],\n",
      "        [0.0633],\n",
      "        [0.0646]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.45596194267273\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 42\n",
      "剩餘X 資料 torch.Size([65, 18])\n",
      "剩餘Y 資料 torch.Size([65, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005934383720159531, 38)\n",
      "The second_loss value of k: (0.006731981877237558, 47)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引38，y= tensor([0.7218])\n",
      "目前模型的Data狀態 torch.Size([42, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9905],\n",
      "        [0.9786],\n",
      "        [0.9989],\n",
      "        [0.9816],\n",
      "        [0.9772],\n",
      "        [0.9629],\n",
      "        [0.9411],\n",
      "        [0.8906],\n",
      "        [0.9139],\n",
      "        [0.9385],\n",
      "        [0.9183],\n",
      "        [0.8569],\n",
      "        [0.8534],\n",
      "        [0.8421],\n",
      "        [0.7988],\n",
      "        [0.8043],\n",
      "        [0.8238],\n",
      "        [0.7988],\n",
      "        [0.8403],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.8521],\n",
      "        [0.7988],\n",
      "        [0.9570],\n",
      "        [0.8429],\n",
      "        [0.7988],\n",
      "        [0.8287],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.9870],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.7988],\n",
      "        [0.7988]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0022],\n",
      "        [0.0004],\n",
      "        [0.0016],\n",
      "        [0.0018],\n",
      "        [0.0028],\n",
      "        [0.0044],\n",
      "        [0.0027],\n",
      "        [0.0017],\n",
      "        [0.0002],\n",
      "        [0.0018],\n",
      "        [0.0024],\n",
      "        [0.0036],\n",
      "        [0.0013],\n",
      "        [0.0034],\n",
      "        [0.0059],\n",
      "        [0.0023],\n",
      "        [0.0078],\n",
      "        [0.0048],\n",
      "        [0.0089],\n",
      "        [0.0052],\n",
      "        [0.0106],\n",
      "        [0.0115],\n",
      "        [0.0055],\n",
      "        [0.0099],\n",
      "        [0.0004],\n",
      "        [0.0178],\n",
      "        [0.0143],\n",
      "        [0.0367],\n",
      "        [0.0368],\n",
      "        [0.0412],\n",
      "        [0.0276],\n",
      "        [0.0628],\n",
      "        [0.0755],\n",
      "        [0.0845],\n",
      "        [0.0382],\n",
      "        [0.0402],\n",
      "        [0.0525],\n",
      "        [0.0527],\n",
      "        [0.0533],\n",
      "        [0.0633],\n",
      "        [0.0646],\n",
      "        [0.0770]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0020],\n",
      "        [    0.0001],\n",
      "        [    0.0021],\n",
      "        [    0.0012],\n",
      "        [    0.0022],\n",
      "        [    0.0037],\n",
      "        [    0.0019],\n",
      "        [    0.0026],\n",
      "        [    0.0008],\n",
      "        [    0.0029],\n",
      "        [    0.0035],\n",
      "        [    0.0047],\n",
      "        [    0.0002],\n",
      "        [    0.0023],\n",
      "        [    0.0009],\n",
      "        [    0.0013],\n",
      "        [    0.0069],\n",
      "        [    0.0078],\n",
      "        [    0.0082],\n",
      "        [    0.0002],\n",
      "        [    0.0126],\n",
      "        [    0.0108],\n",
      "        [    0.0105],\n",
      "        [    0.0092],\n",
      "        [    0.0010],\n",
      "        [    0.0228],\n",
      "        [    0.0148],\n",
      "        [    0.0417],\n",
      "        [    0.0418],\n",
      "        [    0.0462],\n",
      "        [    0.0275],\n",
      "        [    0.0678],\n",
      "        [    0.0805],\n",
      "        [    0.0895],\n",
      "        [    0.0332],\n",
      "        [    0.0352],\n",
      "        [    0.0475],\n",
      "        [    0.0477],\n",
      "        [    0.0483],\n",
      "        [    0.0583],\n",
      "        [    0.0596],\n",
      "        [    0.0720]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 9.791181325912476\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 43\n",
      "剩餘X 資料 torch.Size([64, 18])\n",
      "剩餘Y 資料 torch.Size([64, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005936348810791969, 46)\n",
      "The second_loss value of k: (0.006041406188160181, 51)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引46，y= tensor([0.7168])\n",
      "目前模型的Data狀態 torch.Size([43, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9908],\n",
      "        [0.9791],\n",
      "        [0.9994],\n",
      "        [0.9822],\n",
      "        [0.9779],\n",
      "        [0.9636],\n",
      "        [0.9419],\n",
      "        [0.8915],\n",
      "        [0.9149],\n",
      "        [0.9395],\n",
      "        [0.9194],\n",
      "        [0.8580],\n",
      "        [0.8546],\n",
      "        [0.8431],\n",
      "        [0.7938],\n",
      "        [0.8052],\n",
      "        [0.8246],\n",
      "        [0.7958],\n",
      "        [0.8410],\n",
      "        [0.7938],\n",
      "        [0.7969],\n",
      "        [0.8528],\n",
      "        [0.7938],\n",
      "        [0.9578],\n",
      "        [0.8436],\n",
      "        [0.7938],\n",
      "        [0.8293],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.9869],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938],\n",
      "        [0.7938]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0020],\n",
      "        [    0.0001],\n",
      "        [    0.0021],\n",
      "        [    0.0012],\n",
      "        [    0.0022],\n",
      "        [    0.0037],\n",
      "        [    0.0019],\n",
      "        [    0.0026],\n",
      "        [    0.0008],\n",
      "        [    0.0029],\n",
      "        [    0.0035],\n",
      "        [    0.0047],\n",
      "        [    0.0002],\n",
      "        [    0.0023],\n",
      "        [    0.0009],\n",
      "        [    0.0013],\n",
      "        [    0.0069],\n",
      "        [    0.0078],\n",
      "        [    0.0082],\n",
      "        [    0.0002],\n",
      "        [    0.0126],\n",
      "        [    0.0108],\n",
      "        [    0.0105],\n",
      "        [    0.0092],\n",
      "        [    0.0010],\n",
      "        [    0.0228],\n",
      "        [    0.0148],\n",
      "        [    0.0417],\n",
      "        [    0.0418],\n",
      "        [    0.0462],\n",
      "        [    0.0275],\n",
      "        [    0.0678],\n",
      "        [    0.0805],\n",
      "        [    0.0895],\n",
      "        [    0.0332],\n",
      "        [    0.0352],\n",
      "        [    0.0475],\n",
      "        [    0.0477],\n",
      "        [    0.0483],\n",
      "        [    0.0583],\n",
      "        [    0.0596],\n",
      "        [    0.0720],\n",
      "        [    0.0770]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0022],\n",
      "        [    0.0000],\n",
      "        [    0.0019],\n",
      "        [    0.0013],\n",
      "        [    0.0022],\n",
      "        [    0.0037],\n",
      "        [    0.0018],\n",
      "        [    0.0028],\n",
      "        [    0.0012],\n",
      "        [    0.0033],\n",
      "        [    0.0039],\n",
      "        [    0.0052],\n",
      "        [    0.0003],\n",
      "        [    0.0018],\n",
      "        [    0.0023],\n",
      "        [    0.0009],\n",
      "        [    0.0066],\n",
      "        [    0.0074],\n",
      "        [    0.0079],\n",
      "        [    0.0040],\n",
      "        [    0.0123],\n",
      "        [    0.0104],\n",
      "        [    0.0147],\n",
      "        [    0.0088],\n",
      "        [    0.0014],\n",
      "        [    0.0271],\n",
      "        [    0.0151],\n",
      "        [    0.0459],\n",
      "        [    0.0461],\n",
      "        [    0.0505],\n",
      "        [    0.0269],\n",
      "        [    0.0721],\n",
      "        [    0.0848],\n",
      "        [    0.0937],\n",
      "        [    0.0290],\n",
      "        [    0.0310],\n",
      "        [    0.0433],\n",
      "        [    0.0434],\n",
      "        [    0.0441],\n",
      "        [    0.0541],\n",
      "        [    0.0553],\n",
      "        [    0.0678],\n",
      "        [    0.0728]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.14760708808899\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 44\n",
      "剩餘X 資料 torch.Size([63, 18])\n",
      "剩餘Y 資料 torch.Size([63, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005401484668254852, 50)\n",
      "The second_loss value of k: (0.006057464983314276, 46)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引50，y= tensor([0.7161])\n",
      "目前模型的Data狀態 torch.Size([44, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9905],\n",
      "        [0.9790],\n",
      "        [0.9992],\n",
      "        [0.9820],\n",
      "        [0.9778],\n",
      "        [0.9636],\n",
      "        [0.9419],\n",
      "        [0.8917],\n",
      "        [0.9153],\n",
      "        [0.9399],\n",
      "        [0.9198],\n",
      "        [0.8585],\n",
      "        [0.8551],\n",
      "        [0.8436],\n",
      "        [0.7906],\n",
      "        [0.8057],\n",
      "        [0.8249],\n",
      "        [0.7962],\n",
      "        [0.8413],\n",
      "        [0.7896],\n",
      "        [0.7971],\n",
      "        [0.8532],\n",
      "        [0.7896],\n",
      "        [0.9582],\n",
      "        [0.8440],\n",
      "        [0.7896],\n",
      "        [0.8296],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.9863],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896],\n",
      "        [0.7896]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0022],\n",
      "        [    0.0000],\n",
      "        [    0.0019],\n",
      "        [    0.0013],\n",
      "        [    0.0022],\n",
      "        [    0.0037],\n",
      "        [    0.0018],\n",
      "        [    0.0028],\n",
      "        [    0.0012],\n",
      "        [    0.0033],\n",
      "        [    0.0039],\n",
      "        [    0.0052],\n",
      "        [    0.0003],\n",
      "        [    0.0018],\n",
      "        [    0.0023],\n",
      "        [    0.0009],\n",
      "        [    0.0066],\n",
      "        [    0.0074],\n",
      "        [    0.0079],\n",
      "        [    0.0040],\n",
      "        [    0.0123],\n",
      "        [    0.0104],\n",
      "        [    0.0147],\n",
      "        [    0.0088],\n",
      "        [    0.0014],\n",
      "        [    0.0271],\n",
      "        [    0.0151],\n",
      "        [    0.0459],\n",
      "        [    0.0461],\n",
      "        [    0.0505],\n",
      "        [    0.0269],\n",
      "        [    0.0721],\n",
      "        [    0.0848],\n",
      "        [    0.0937],\n",
      "        [    0.0290],\n",
      "        [    0.0310],\n",
      "        [    0.0433],\n",
      "        [    0.0434],\n",
      "        [    0.0441],\n",
      "        [    0.0541],\n",
      "        [    0.0553],\n",
      "        [    0.0678],\n",
      "        [    0.0728],\n",
      "        [    0.0735]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0021],\n",
      "        [0.0002],\n",
      "        [0.0022],\n",
      "        [0.0010],\n",
      "        [0.0019],\n",
      "        [0.0033],\n",
      "        [0.0014],\n",
      "        [0.0033],\n",
      "        [0.0018],\n",
      "        [0.0040],\n",
      "        [0.0046],\n",
      "        [0.0059],\n",
      "        [0.0011],\n",
      "        [0.0011],\n",
      "        [0.0015],\n",
      "        [0.0002],\n",
      "        [0.0060],\n",
      "        [0.0067],\n",
      "        [0.0073],\n",
      "        [0.0079],\n",
      "        [0.0118],\n",
      "        [0.0097],\n",
      "        [0.0185],\n",
      "        [0.0081],\n",
      "        [0.0021],\n",
      "        [0.0309],\n",
      "        [0.0156],\n",
      "        [0.0497],\n",
      "        [0.0499],\n",
      "        [0.0543],\n",
      "        [0.0266],\n",
      "        [0.0759],\n",
      "        [0.0886],\n",
      "        [0.0976],\n",
      "        [0.0252],\n",
      "        [0.0272],\n",
      "        [0.0395],\n",
      "        [0.0396],\n",
      "        [0.0402],\n",
      "        [0.0503],\n",
      "        [0.0515],\n",
      "        [0.0640],\n",
      "        [0.0690],\n",
      "        [0.0697]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.46346664428711\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 45\n",
      "剩餘X 資料 torch.Size([62, 18])\n",
      "剩餘Y 資料 torch.Size([62, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005476202815771103, 46)\n",
      "The second_loss value of k: (0.006059060804545879, 19)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引46，y= tensor([0.7118])\n",
      "目前模型的Data狀態 torch.Size([45, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9906],\n",
      "        [0.9793],\n",
      "        [0.9994],\n",
      "        [0.9823],\n",
      "        [0.9781],\n",
      "        [0.9640],\n",
      "        [0.9424],\n",
      "        [0.8922],\n",
      "        [0.9159],\n",
      "        [0.9406],\n",
      "        [0.9205],\n",
      "        [0.8593],\n",
      "        [0.8559],\n",
      "        [0.8444],\n",
      "        [0.7913],\n",
      "        [0.8063],\n",
      "        [0.8255],\n",
      "        [0.7969],\n",
      "        [0.8419],\n",
      "        [0.7858],\n",
      "        [0.7977],\n",
      "        [0.8538],\n",
      "        [0.7858],\n",
      "        [0.9588],\n",
      "        [0.8446],\n",
      "        [0.7858],\n",
      "        [0.8301],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.9860],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858],\n",
      "        [0.7858]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0021],\n",
      "        [0.0002],\n",
      "        [0.0022],\n",
      "        [0.0010],\n",
      "        [0.0019],\n",
      "        [0.0033],\n",
      "        [0.0014],\n",
      "        [0.0033],\n",
      "        [0.0018],\n",
      "        [0.0040],\n",
      "        [0.0046],\n",
      "        [0.0059],\n",
      "        [0.0011],\n",
      "        [0.0011],\n",
      "        [0.0015],\n",
      "        [0.0002],\n",
      "        [0.0060],\n",
      "        [0.0067],\n",
      "        [0.0073],\n",
      "        [0.0079],\n",
      "        [0.0118],\n",
      "        [0.0097],\n",
      "        [0.0185],\n",
      "        [0.0081],\n",
      "        [0.0021],\n",
      "        [0.0309],\n",
      "        [0.0156],\n",
      "        [0.0497],\n",
      "        [0.0499],\n",
      "        [0.0543],\n",
      "        [0.0266],\n",
      "        [0.0759],\n",
      "        [0.0886],\n",
      "        [0.0976],\n",
      "        [0.0252],\n",
      "        [0.0272],\n",
      "        [0.0395],\n",
      "        [0.0396],\n",
      "        [0.0402],\n",
      "        [0.0503],\n",
      "        [0.0515],\n",
      "        [0.0640],\n",
      "        [0.0690],\n",
      "        [0.0697],\n",
      "        [0.0740]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0005],\n",
      "        [0.0014],\n",
      "        [0.0018],\n",
      "        [0.0026],\n",
      "        [0.0039],\n",
      "        [0.0021],\n",
      "        [0.0027],\n",
      "        [0.0014],\n",
      "        [0.0036],\n",
      "        [0.0042],\n",
      "        [0.0056],\n",
      "        [0.0009],\n",
      "        [0.0014],\n",
      "        [0.0018],\n",
      "        [0.0005],\n",
      "        [0.0064],\n",
      "        [0.0071],\n",
      "        [0.0077],\n",
      "        [0.0116],\n",
      "        [0.0121],\n",
      "        [0.0100],\n",
      "        [0.0223],\n",
      "        [0.0084],\n",
      "        [0.0018],\n",
      "        [0.0347],\n",
      "        [0.0153],\n",
      "        [0.0535],\n",
      "        [0.0536],\n",
      "        [0.0580],\n",
      "        [0.0254],\n",
      "        [0.0797],\n",
      "        [0.0923],\n",
      "        [0.1013],\n",
      "        [0.0214],\n",
      "        [0.0234],\n",
      "        [0.0357],\n",
      "        [0.0359],\n",
      "        [0.0365],\n",
      "        [0.0465],\n",
      "        [0.0478],\n",
      "        [0.0602],\n",
      "        [0.0652],\n",
      "        [0.0659],\n",
      "        [0.0702]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 10.84159541130066\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 46\n",
      "剩餘X 資料 torch.Size([61, 18])\n",
      "剩餘Y 資料 torch.Size([61, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005488321650773287, 19)\n",
      "The second_loss value of k: (0.005509643815457821, 49)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引19，y= tensor([0.7079])\n",
      "目前模型的Data狀態 torch.Size([46, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9786],\n",
      "        [0.9986],\n",
      "        [0.9816],\n",
      "        [0.9774],\n",
      "        [0.9634],\n",
      "        [0.9417],\n",
      "        [0.8917],\n",
      "        [0.9155],\n",
      "        [0.9402],\n",
      "        [0.9201],\n",
      "        [0.8589],\n",
      "        [0.8556],\n",
      "        [0.8441],\n",
      "        [0.7910],\n",
      "        [0.8060],\n",
      "        [0.8251],\n",
      "        [0.7966],\n",
      "        [0.8415],\n",
      "        [0.7820],\n",
      "        [0.7973],\n",
      "        [0.8535],\n",
      "        [0.7820],\n",
      "        [0.9585],\n",
      "        [0.8443],\n",
      "        [0.7820],\n",
      "        [0.8297],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.9848],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820],\n",
      "        [0.7820]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0005],\n",
      "        [0.0014],\n",
      "        [0.0018],\n",
      "        [0.0026],\n",
      "        [0.0039],\n",
      "        [0.0021],\n",
      "        [0.0027],\n",
      "        [0.0014],\n",
      "        [0.0036],\n",
      "        [0.0042],\n",
      "        [0.0056],\n",
      "        [0.0009],\n",
      "        [0.0014],\n",
      "        [0.0018],\n",
      "        [0.0005],\n",
      "        [0.0064],\n",
      "        [0.0071],\n",
      "        [0.0077],\n",
      "        [0.0116],\n",
      "        [0.0121],\n",
      "        [0.0100],\n",
      "        [0.0223],\n",
      "        [0.0084],\n",
      "        [0.0018],\n",
      "        [0.0347],\n",
      "        [0.0153],\n",
      "        [0.0535],\n",
      "        [0.0536],\n",
      "        [0.0580],\n",
      "        [0.0254],\n",
      "        [0.0797],\n",
      "        [0.0923],\n",
      "        [0.1013],\n",
      "        [0.0214],\n",
      "        [0.0234],\n",
      "        [0.0357],\n",
      "        [0.0359],\n",
      "        [0.0365],\n",
      "        [0.0465],\n",
      "        [0.0478],\n",
      "        [0.0602],\n",
      "        [0.0652],\n",
      "        [0.0659],\n",
      "        [0.0702],\n",
      "        [0.0741]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0002],\n",
      "        [    0.0016],\n",
      "        [    0.0015],\n",
      "        [    0.0023],\n",
      "        [    0.0036],\n",
      "        [    0.0018],\n",
      "        [    0.0031],\n",
      "        [    0.0019],\n",
      "        [    0.0041],\n",
      "        [    0.0047],\n",
      "        [    0.0061],\n",
      "        [    0.0015],\n",
      "        [    0.0008],\n",
      "        [    0.0013],\n",
      "        [    0.0000],\n",
      "        [    0.0060],\n",
      "        [    0.0066],\n",
      "        [    0.0073],\n",
      "        [    0.0151],\n",
      "        [    0.0117],\n",
      "        [    0.0096],\n",
      "        [    0.0258],\n",
      "        [    0.0080],\n",
      "        [    0.0023],\n",
      "        [    0.0381],\n",
      "        [    0.0157],\n",
      "        [    0.0570],\n",
      "        [    0.0571],\n",
      "        [    0.0615],\n",
      "        [    0.0251],\n",
      "        [    0.0832],\n",
      "        [    0.0958],\n",
      "        [    0.1048],\n",
      "        [    0.0179],\n",
      "        [    0.0199],\n",
      "        [    0.0322],\n",
      "        [    0.0324],\n",
      "        [    0.0330],\n",
      "        [    0.0430],\n",
      "        [    0.0443],\n",
      "        [    0.0567],\n",
      "        [    0.0617],\n",
      "        [    0.0624],\n",
      "        [    0.0668],\n",
      "        [    0.0706]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.164685726165771\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 47\n",
      "剩餘X 資料 torch.Size([60, 18])\n",
      "剩餘Y 資料 torch.Size([60, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005003099795430899, 48)\n",
      "The second_loss value of k: (0.005308675579726696, 47)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引48，y= tensor([0.7078])\n",
      "目前模型的Data狀態 torch.Size([47, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9899],\n",
      "        [0.9788],\n",
      "        [0.9988],\n",
      "        [0.9818],\n",
      "        [0.9777],\n",
      "        [0.9637],\n",
      "        [0.9420],\n",
      "        [0.8921],\n",
      "        [0.9160],\n",
      "        [0.9408],\n",
      "        [0.9206],\n",
      "        [0.8595],\n",
      "        [0.8562],\n",
      "        [0.8447],\n",
      "        [0.7916],\n",
      "        [0.8065],\n",
      "        [0.8255],\n",
      "        [0.7970],\n",
      "        [0.8419],\n",
      "        [0.7785],\n",
      "        [0.7977],\n",
      "        [0.8540],\n",
      "        [0.7785],\n",
      "        [0.9590],\n",
      "        [0.8448],\n",
      "        [0.7785],\n",
      "        [0.8302],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.9845],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785],\n",
      "        [0.7785]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0002],\n",
      "        [    0.0016],\n",
      "        [    0.0015],\n",
      "        [    0.0023],\n",
      "        [    0.0036],\n",
      "        [    0.0018],\n",
      "        [    0.0031],\n",
      "        [    0.0019],\n",
      "        [    0.0041],\n",
      "        [    0.0047],\n",
      "        [    0.0061],\n",
      "        [    0.0015],\n",
      "        [    0.0008],\n",
      "        [    0.0013],\n",
      "        [    0.0000],\n",
      "        [    0.0060],\n",
      "        [    0.0066],\n",
      "        [    0.0073],\n",
      "        [    0.0151],\n",
      "        [    0.0117],\n",
      "        [    0.0096],\n",
      "        [    0.0258],\n",
      "        [    0.0080],\n",
      "        [    0.0023],\n",
      "        [    0.0381],\n",
      "        [    0.0157],\n",
      "        [    0.0570],\n",
      "        [    0.0571],\n",
      "        [    0.0615],\n",
      "        [    0.0251],\n",
      "        [    0.0832],\n",
      "        [    0.0958],\n",
      "        [    0.1048],\n",
      "        [    0.0179],\n",
      "        [    0.0199],\n",
      "        [    0.0322],\n",
      "        [    0.0324],\n",
      "        [    0.0330],\n",
      "        [    0.0430],\n",
      "        [    0.0443],\n",
      "        [    0.0567],\n",
      "        [    0.0617],\n",
      "        [    0.0624],\n",
      "        [    0.0668],\n",
      "        [    0.0706],\n",
      "        [    0.0707]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0015],\n",
      "        [0.0016],\n",
      "        [0.0024],\n",
      "        [0.0036],\n",
      "        [0.0018],\n",
      "        [0.0031],\n",
      "        [0.0020],\n",
      "        [0.0043],\n",
      "        [0.0049],\n",
      "        [0.0063],\n",
      "        [0.0017],\n",
      "        [0.0005],\n",
      "        [0.0011],\n",
      "        [0.0001],\n",
      "        [0.0060],\n",
      "        [0.0064],\n",
      "        [0.0071],\n",
      "        [0.0183],\n",
      "        [0.0115],\n",
      "        [0.0094],\n",
      "        [0.0290],\n",
      "        [0.0078],\n",
      "        [0.0025],\n",
      "        [0.0414],\n",
      "        [0.0159],\n",
      "        [0.0602],\n",
      "        [0.0604],\n",
      "        [0.0647],\n",
      "        [0.0245],\n",
      "        [0.0864],\n",
      "        [0.0991],\n",
      "        [0.1080],\n",
      "        [0.0147],\n",
      "        [0.0167],\n",
      "        [0.0290],\n",
      "        [0.0291],\n",
      "        [0.0298],\n",
      "        [0.0398],\n",
      "        [0.0411],\n",
      "        [0.0535],\n",
      "        [0.0585],\n",
      "        [0.0592],\n",
      "        [0.0635],\n",
      "        [0.0674],\n",
      "        [0.0675]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.533915519714355\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 48\n",
      "剩餘X 資料 torch.Size([59, 18])\n",
      "剩餘Y 資料 torch.Size([59, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004850905854254961, 47)\n",
      "The second_loss value of k: (0.004938601981848478, 48)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引47，y= tensor([0.7056])\n",
      "目前模型的Data狀態 torch.Size([48, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9788],\n",
      "        [0.9987],\n",
      "        [0.9817],\n",
      "        [0.9776],\n",
      "        [0.9637],\n",
      "        [0.9420],\n",
      "        [0.8921],\n",
      "        [0.9161],\n",
      "        [0.9410],\n",
      "        [0.9208],\n",
      "        [0.8597],\n",
      "        [0.8565],\n",
      "        [0.8449],\n",
      "        [0.7918],\n",
      "        [0.8067],\n",
      "        [0.8256],\n",
      "        [0.7972],\n",
      "        [0.8421],\n",
      "        [0.7753],\n",
      "        [0.7979],\n",
      "        [0.8542],\n",
      "        [0.7753],\n",
      "        [0.9592],\n",
      "        [0.8450],\n",
      "        [0.7753],\n",
      "        [0.8303],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.9839],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753],\n",
      "        [0.7753]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0015],\n",
      "        [0.0016],\n",
      "        [0.0024],\n",
      "        [0.0036],\n",
      "        [0.0018],\n",
      "        [0.0031],\n",
      "        [0.0020],\n",
      "        [0.0043],\n",
      "        [0.0049],\n",
      "        [0.0063],\n",
      "        [0.0017],\n",
      "        [0.0005],\n",
      "        [0.0011],\n",
      "        [0.0001],\n",
      "        [0.0060],\n",
      "        [0.0064],\n",
      "        [0.0071],\n",
      "        [0.0183],\n",
      "        [0.0115],\n",
      "        [0.0094],\n",
      "        [0.0290],\n",
      "        [0.0078],\n",
      "        [0.0025],\n",
      "        [0.0414],\n",
      "        [0.0159],\n",
      "        [0.0602],\n",
      "        [0.0604],\n",
      "        [0.0647],\n",
      "        [0.0245],\n",
      "        [0.0864],\n",
      "        [0.0991],\n",
      "        [0.1080],\n",
      "        [0.0147],\n",
      "        [0.0167],\n",
      "        [0.0290],\n",
      "        [0.0291],\n",
      "        [0.0298],\n",
      "        [0.0398],\n",
      "        [0.0411],\n",
      "        [0.0535],\n",
      "        [0.0585],\n",
      "        [0.0592],\n",
      "        [0.0635],\n",
      "        [0.0674],\n",
      "        [0.0675],\n",
      "        [0.0696]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0036],\n",
      "        [0.0008],\n",
      "        [0.0008],\n",
      "        [0.0022],\n",
      "        [0.0030],\n",
      "        [0.0042],\n",
      "        [0.0024],\n",
      "        [0.0026],\n",
      "        [0.0016],\n",
      "        [0.0040],\n",
      "        [0.0045],\n",
      "        [0.0060],\n",
      "        [0.0014],\n",
      "        [0.0008],\n",
      "        [0.0014],\n",
      "        [0.0002],\n",
      "        [0.0064],\n",
      "        [0.0068],\n",
      "        [0.0075],\n",
      "        [0.0214],\n",
      "        [0.0119],\n",
      "        [0.0096],\n",
      "        [0.0321],\n",
      "        [0.0081],\n",
      "        [0.0022],\n",
      "        [0.0444],\n",
      "        [0.0155],\n",
      "        [0.0633],\n",
      "        [0.0634],\n",
      "        [0.0678],\n",
      "        [0.0234],\n",
      "        [0.0894],\n",
      "        [0.1021],\n",
      "        [0.1111],\n",
      "        [0.0116],\n",
      "        [0.0136],\n",
      "        [0.0259],\n",
      "        [0.0261],\n",
      "        [0.0267],\n",
      "        [0.0367],\n",
      "        [0.0380],\n",
      "        [0.0504],\n",
      "        [0.0554],\n",
      "        [0.0561],\n",
      "        [0.0605],\n",
      "        [0.0643],\n",
      "        [0.0644],\n",
      "        [0.0666]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 11.867332220077515\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 49\n",
      "剩餘X 資料 torch.Size([58, 18])\n",
      "剩餘Y 資料 torch.Size([58, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004515320062637329, 47)\n",
      "The second_loss value of k: (0.004674617666751146, 34)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引47，y= tensor([0.7050])\n",
      "目前模型的Data狀態 torch.Size([49, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9891],\n",
      "        [0.9783],\n",
      "        [0.9981],\n",
      "        [0.9811],\n",
      "        [0.9770],\n",
      "        [0.9632],\n",
      "        [0.9414],\n",
      "        [0.8916],\n",
      "        [0.9157],\n",
      "        [0.9406],\n",
      "        [0.9204],\n",
      "        [0.8593],\n",
      "        [0.8562],\n",
      "        [0.8446],\n",
      "        [0.7915],\n",
      "        [0.8063],\n",
      "        [0.8251],\n",
      "        [0.7968],\n",
      "        [0.8417],\n",
      "        [0.7722],\n",
      "        [0.7976],\n",
      "        [0.8539],\n",
      "        [0.7722],\n",
      "        [0.9588],\n",
      "        [0.8447],\n",
      "        [0.7722],\n",
      "        [0.8300],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.9828],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722],\n",
      "        [0.7722]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0036],\n",
      "        [0.0008],\n",
      "        [0.0008],\n",
      "        [0.0022],\n",
      "        [0.0030],\n",
      "        [0.0042],\n",
      "        [0.0024],\n",
      "        [0.0026],\n",
      "        [0.0016],\n",
      "        [0.0040],\n",
      "        [0.0045],\n",
      "        [0.0060],\n",
      "        [0.0014],\n",
      "        [0.0008],\n",
      "        [0.0014],\n",
      "        [0.0002],\n",
      "        [0.0064],\n",
      "        [0.0068],\n",
      "        [0.0075],\n",
      "        [0.0214],\n",
      "        [0.0119],\n",
      "        [0.0096],\n",
      "        [0.0321],\n",
      "        [0.0081],\n",
      "        [0.0022],\n",
      "        [0.0444],\n",
      "        [0.0155],\n",
      "        [0.0633],\n",
      "        [0.0634],\n",
      "        [0.0678],\n",
      "        [0.0234],\n",
      "        [0.0894],\n",
      "        [0.1021],\n",
      "        [0.1111],\n",
      "        [0.0116],\n",
      "        [0.0136],\n",
      "        [0.0259],\n",
      "        [0.0261],\n",
      "        [0.0267],\n",
      "        [0.0367],\n",
      "        [0.0380],\n",
      "        [0.0504],\n",
      "        [0.0554],\n",
      "        [0.0561],\n",
      "        [0.0605],\n",
      "        [0.0643],\n",
      "        [0.0644],\n",
      "        [0.0666],\n",
      "        [0.0672]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0034],\n",
      "        [0.0004],\n",
      "        [0.0011],\n",
      "        [0.0019],\n",
      "        [0.0027],\n",
      "        [0.0038],\n",
      "        [0.0020],\n",
      "        [0.0030],\n",
      "        [0.0020],\n",
      "        [0.0044],\n",
      "        [0.0049],\n",
      "        [0.0064],\n",
      "        [0.0019],\n",
      "        [0.0003],\n",
      "        [0.0009],\n",
      "        [0.0002],\n",
      "        [0.0061],\n",
      "        [0.0064],\n",
      "        [0.0071],\n",
      "        [0.0242],\n",
      "        [0.0115],\n",
      "        [0.0092],\n",
      "        [0.0348],\n",
      "        [0.0077],\n",
      "        [0.0026],\n",
      "        [0.0472],\n",
      "        [0.0159],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0706],\n",
      "        [0.0232],\n",
      "        [0.0922],\n",
      "        [0.1049],\n",
      "        [0.1139],\n",
      "        [0.0088],\n",
      "        [0.0108],\n",
      "        [0.0231],\n",
      "        [0.0233],\n",
      "        [0.0239],\n",
      "        [0.0340],\n",
      "        [0.0352],\n",
      "        [0.0477],\n",
      "        [0.0527],\n",
      "        [0.0534],\n",
      "        [0.0577],\n",
      "        [0.0615],\n",
      "        [0.0617],\n",
      "        [0.0638],\n",
      "        [0.0644]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.242841243743896\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 50\n",
      "剩餘X 資料 torch.Size([57, 18])\n",
      "剩餘Y 資料 torch.Size([57, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004304217174649239, 34)\n",
      "The second_loss value of k: (0.004366113804280758, 45)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引34，y= tensor([0.7038])\n",
      "目前模型的Data狀態 torch.Size([50, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9894],\n",
      "        [0.9786],\n",
      "        [0.9984],\n",
      "        [0.9814],\n",
      "        [0.9774],\n",
      "        [0.9635],\n",
      "        [0.9417],\n",
      "        [0.8919],\n",
      "        [0.9161],\n",
      "        [0.9411],\n",
      "        [0.9208],\n",
      "        [0.8598],\n",
      "        [0.8567],\n",
      "        [0.8451],\n",
      "        [0.7919],\n",
      "        [0.8067],\n",
      "        [0.8254],\n",
      "        [0.7972],\n",
      "        [0.8421],\n",
      "        [0.7694],\n",
      "        [0.7980],\n",
      "        [0.8543],\n",
      "        [0.7694],\n",
      "        [0.9592],\n",
      "        [0.8452],\n",
      "        [0.7694],\n",
      "        [0.8304],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.9826],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694],\n",
      "        [0.7694]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0034],\n",
      "        [0.0004],\n",
      "        [0.0011],\n",
      "        [0.0019],\n",
      "        [0.0027],\n",
      "        [0.0038],\n",
      "        [0.0020],\n",
      "        [0.0030],\n",
      "        [0.0020],\n",
      "        [0.0044],\n",
      "        [0.0049],\n",
      "        [0.0064],\n",
      "        [0.0019],\n",
      "        [0.0003],\n",
      "        [0.0009],\n",
      "        [0.0002],\n",
      "        [0.0061],\n",
      "        [0.0064],\n",
      "        [0.0071],\n",
      "        [0.0242],\n",
      "        [0.0115],\n",
      "        [0.0092],\n",
      "        [0.0348],\n",
      "        [0.0077],\n",
      "        [0.0026],\n",
      "        [0.0472],\n",
      "        [0.0159],\n",
      "        [0.0660],\n",
      "        [0.0662],\n",
      "        [0.0706],\n",
      "        [0.0232],\n",
      "        [0.0922],\n",
      "        [0.1049],\n",
      "        [0.1139],\n",
      "        [0.0088],\n",
      "        [0.0108],\n",
      "        [0.0231],\n",
      "        [0.0233],\n",
      "        [0.0239],\n",
      "        [0.0340],\n",
      "        [0.0352],\n",
      "        [0.0477],\n",
      "        [0.0527],\n",
      "        [0.0534],\n",
      "        [0.0577],\n",
      "        [0.0615],\n",
      "        [0.0617],\n",
      "        [0.0638],\n",
      "        [0.0644],\n",
      "        [0.0656]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "第\"100\"回合Regularizing module完畢\n",
      "Number of enlarge: 76\n",
      "Number of shrink: 24\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0024],\n",
      "        [0.0007],\n",
      "        [0.0021],\n",
      "        [0.0008],\n",
      "        [0.0015],\n",
      "        [0.0025],\n",
      "        [0.0007],\n",
      "        [0.0044],\n",
      "        [0.0035],\n",
      "        [0.0059],\n",
      "        [0.0063],\n",
      "        [0.0079],\n",
      "        [0.0034],\n",
      "        [0.0013],\n",
      "        [0.0007],\n",
      "        [0.0017],\n",
      "        [0.0046],\n",
      "        [0.0048],\n",
      "        [0.0056],\n",
      "        [0.0281],\n",
      "        [0.0097],\n",
      "        [0.0075],\n",
      "        [0.0340],\n",
      "        [0.0060],\n",
      "        [0.0044],\n",
      "        [0.0512],\n",
      "        [0.0176],\n",
      "        [0.0700],\n",
      "        [0.0702],\n",
      "        [0.0746],\n",
      "        [0.0240],\n",
      "        [0.0962],\n",
      "        [0.1089],\n",
      "        [0.1178],\n",
      "        [0.0049],\n",
      "        [0.0069],\n",
      "        [0.0192],\n",
      "        [0.0193],\n",
      "        [0.0200],\n",
      "        [0.0300],\n",
      "        [0.0312],\n",
      "        [0.0437],\n",
      "        [0.0487],\n",
      "        [0.0494],\n",
      "        [0.0537],\n",
      "        [0.0576],\n",
      "        [0.0577],\n",
      "        [0.0598],\n",
      "        [0.0605],\n",
      "        [0.0616]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.587513208389282\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 51\n",
      "剩餘X 資料 torch.Size([56, 18])\n",
      "剩餘Y 資料 torch.Size([56, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00385777885094285, 44)\n",
      "The second_loss value of k: (0.004963791463524103, 46)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引44，y= tensor([0.7034])\n",
      "目前模型的Data狀態 torch.Size([51, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9903],\n",
      "        [0.9797],\n",
      "        [0.9994],\n",
      "        [0.9826],\n",
      "        [0.9786],\n",
      "        [0.9648],\n",
      "        [0.9431],\n",
      "        [0.8933],\n",
      "        [0.9176],\n",
      "        [0.9425],\n",
      "        [0.9222],\n",
      "        [0.8612],\n",
      "        [0.8582],\n",
      "        [0.8467],\n",
      "        [0.7936],\n",
      "        [0.8082],\n",
      "        [0.8269],\n",
      "        [0.7988],\n",
      "        [0.8436],\n",
      "        [0.7655],\n",
      "        [0.7997],\n",
      "        [0.8560],\n",
      "        [0.7703],\n",
      "        [0.9609],\n",
      "        [0.8469],\n",
      "        [0.7655],\n",
      "        [0.8321],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.9833],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655],\n",
      "        [0.7655]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0024],\n",
      "        [0.0007],\n",
      "        [0.0021],\n",
      "        [0.0008],\n",
      "        [0.0015],\n",
      "        [0.0025],\n",
      "        [0.0007],\n",
      "        [0.0044],\n",
      "        [0.0035],\n",
      "        [0.0059],\n",
      "        [0.0063],\n",
      "        [0.0079],\n",
      "        [0.0034],\n",
      "        [0.0013],\n",
      "        [0.0007],\n",
      "        [0.0017],\n",
      "        [0.0046],\n",
      "        [0.0048],\n",
      "        [0.0056],\n",
      "        [0.0281],\n",
      "        [0.0097],\n",
      "        [0.0075],\n",
      "        [0.0340],\n",
      "        [0.0060],\n",
      "        [0.0044],\n",
      "        [0.0512],\n",
      "        [0.0176],\n",
      "        [0.0700],\n",
      "        [0.0702],\n",
      "        [0.0746],\n",
      "        [0.0240],\n",
      "        [0.0962],\n",
      "        [0.1089],\n",
      "        [0.1178],\n",
      "        [0.0049],\n",
      "        [0.0069],\n",
      "        [0.0192],\n",
      "        [0.0193],\n",
      "        [0.0200],\n",
      "        [0.0300],\n",
      "        [0.0312],\n",
      "        [0.0437],\n",
      "        [0.0487],\n",
      "        [0.0494],\n",
      "        [0.0537],\n",
      "        [0.0576],\n",
      "        [0.0577],\n",
      "        [0.0598],\n",
      "        [0.0605],\n",
      "        [0.0616],\n",
      "        [0.0621]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 33\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0029],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0029],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0060],\n",
      "        [0.0075],\n",
      "        [0.0031],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0060],\n",
      "        [0.0303],\n",
      "        [0.0101],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0064],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0721],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0028],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0279],\n",
      "        [0.0291],\n",
      "        [0.0416],\n",
      "        [0.0466],\n",
      "        [0.0473],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0556],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0600]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.747568130493164\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 52\n",
      "剩餘X 資料 torch.Size([55, 18])\n",
      "剩餘Y 資料 torch.Size([55, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.004667717032134533, 45)\n",
      "The second_loss value of k: (0.005173100624233484, 44)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引45，y= tensor([0.6950])\n",
      "目前模型的Data狀態 torch.Size([52, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9822],\n",
      "        [0.9782],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9422],\n",
      "        [0.9219],\n",
      "        [0.8609],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7984],\n",
      "        [0.8432],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8556],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9828],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0029],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0029],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0060],\n",
      "        [0.0075],\n",
      "        [0.0031],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0060],\n",
      "        [0.0303],\n",
      "        [0.0101],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0064],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0721],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0028],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0279],\n",
      "        [0.0291],\n",
      "        [0.0416],\n",
      "        [0.0466],\n",
      "        [0.0473],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0556],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0600],\n",
      "        [0.0683]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 7\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0029],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.850995540618896\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 53\n",
      "剩餘X 資料 torch.Size([54, 18])\n",
      "剩餘Y 資料 torch.Size([54, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.005169088486582041, 44)\n",
      "The second_loss value of k: (0.006363172084093094, 45)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引44，y= tensor([0.6914])\n",
      "目前模型的Data狀態 torch.Size([53, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0029],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 12.930769205093384\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 54\n",
      "剩餘X 資料 torch.Size([53, 18])\n",
      "剩餘Y 資料 torch.Size([53, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.006362734362483025, 44)\n",
      "The second_loss value of k: (0.006952828262001276, 12)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引44，y= tensor([0.6835])\n",
      "目前模型的Data狀態 torch.Size([54, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.011138916015625\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 55\n",
      "剩餘X 資料 torch.Size([52, 18])\n",
      "剩餘Y 資料 torch.Size([52, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.006952828262001276, 12)\n",
      "The second_loss value of k: (0.007035775575786829, 51)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引12，y= tensor([0.8200])\n",
      "目前模型的Data狀態 torch.Size([55, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.075700998306274\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 56\n",
      "剩餘X 資料 torch.Size([51, 18])\n",
      "剩餘Y 資料 torch.Size([51, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.007035775575786829, 50)\n",
      "The second_loss value of k: (0.00742205698043108, 43)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引50，y= tensor([0.6794])\n",
      "目前模型的Data狀態 torch.Size([56, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.152063131332397\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 57\n",
      "剩餘X 資料 torch.Size([50, 18])\n",
      "剩餘Y 資料 torch.Size([50, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00742205698043108, 43)\n",
      "The second_loss value of k: (0.00882281269878149, 15)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引43，y= tensor([0.6772])\n",
      "目前模型的Data狀態 torch.Size([57, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.216610670089722\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 58\n",
      "剩餘X 資料 torch.Size([49, 18])\n",
      "剩餘Y 資料 torch.Size([49, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.00882281269878149, 15)\n",
      "The second_loss value of k: (0.010058406740427017, 35)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引15，y= tensor([0.9682])\n",
      "目前模型的Data狀態 torch.Size([58, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.289063692092896\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 59\n",
      "剩餘X 資料 torch.Size([48, 18])\n",
      "剩餘Y 資料 torch.Size([48, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010058406740427017, 34)\n",
      "The second_loss value of k: (0.010455083101987839, 41)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引34，y= tensor([0.6630])\n",
      "目前模型的Data狀態 torch.Size([59, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.353495836257935\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 60\n",
      "剩餘X 資料 torch.Size([47, 18])\n",
      "剩餘Y 資料 torch.Size([47, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010455083101987839, 40)\n",
      "The second_loss value of k: (0.010729198344051838, 41)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引40，y= tensor([0.6611])\n",
      "目前模型的Data狀態 torch.Size([60, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.425511837005615\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 61\n",
      "剩餘X 資料 torch.Size([46, 18])\n",
      "剩餘Y 資料 torch.Size([46, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010729198344051838, 40)\n",
      "The second_loss value of k: (0.010851257480680943, 44)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引40，y= tensor([0.6597])\n",
      "目前模型的Data狀態 torch.Size([61, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.491042852401733\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 62\n",
      "剩餘X 資料 torch.Size([45, 18])\n",
      "剩餘Y 資料 torch.Size([45, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010851257480680943, 43)\n",
      "The second_loss value of k: (0.010883929207921028, 44)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引43，y= tensor([0.6591])\n",
      "目前模型的Data狀態 torch.Size([62, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.553025007247925\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 63\n",
      "剩餘X 資料 torch.Size([44, 18])\n",
      "剩餘Y 資料 torch.Size([44, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.010883929207921028, 43)\n",
      "The second_loss value of k: (0.01099043432623148, 33)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引43，y= tensor([0.6590])\n",
      "目前模型的Data狀態 torch.Size([63, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.614174842834473\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 64\n",
      "剩餘X 資料 torch.Size([43, 18])\n",
      "剩餘Y 資料 torch.Size([43, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.01099043432623148, 33)\n",
      "The second_loss value of k: (0.01166573353111744, 38)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引33，y= tensor([0.6585])\n",
      "目前模型的Data狀態 torch.Size([64, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043],\n",
      "        [0.1048]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043],\n",
      "        [0.1048]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.676671266555786\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 65\n",
      "剩餘X 資料 torch.Size([42, 18])\n",
      "剩餘Y 資料 torch.Size([42, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.01166573353111744, 37)\n",
      "The second_loss value of k: (0.013014085590839386, 32)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引37，y= tensor([0.6553])\n",
      "目前模型的Data狀態 torch.Size([65, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043],\n",
      "        [0.1048],\n",
      "        [0.1080]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043],\n",
      "        [0.1048],\n",
      "        [0.1080]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.73447322845459\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 66\n",
      "剩餘X 資料 torch.Size([41, 18])\n",
      "剩餘Y 資料 torch.Size([41, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.013014085590839386, 32)\n",
      "The second_loss value of k: (0.01342842634767294, 39)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引32，y= tensor([0.6492])\n",
      "目前模型的Data狀態 torch.Size([66, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043],\n",
      "        [0.1048],\n",
      "        [0.1080],\n",
      "        [0.1141]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043],\n",
      "        [0.1048],\n",
      "        [0.1080],\n",
      "        [0.1141]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.790310621261597\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 67\n",
      "剩餘X 資料 torch.Size([40, 18])\n",
      "剩餘Y 資料 torch.Size([40, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.01342842634767294, 38)\n",
      "The second_loss value of k: (0.014920186251401901, 39)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引38，y= tensor([0.6474])\n",
      "目前模型的Data狀態 torch.Size([67, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043],\n",
      "        [0.1048],\n",
      "        [0.1080],\n",
      "        [0.1141],\n",
      "        [0.1159]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 0\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043],\n",
      "        [0.1048],\n",
      "        [0.1080],\n",
      "        [0.1141],\n",
      "        [0.1159]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 13.850022077560425\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 68\n",
      "剩餘X 資料 torch.Size([39, 18])\n",
      "剩餘Y 資料 torch.Size([39, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.014920186251401901, 38)\n",
      "The second_loss value of k: (0.016380038112401962, 37)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引38，y= tensor([0.6412])\n",
      "目前模型的Data狀態 torch.Size([68, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9898],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9821],\n",
      "        [0.9781],\n",
      "        [0.9644],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9172],\n",
      "        [0.9421],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7932],\n",
      "        [0.8078],\n",
      "        [0.8265],\n",
      "        [0.7983],\n",
      "        [0.8431],\n",
      "        [0.7633],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9605],\n",
      "        [0.8465],\n",
      "        [0.7633],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9827],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9034],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8742],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043],\n",
      "        [0.1048],\n",
      "        [0.1080],\n",
      "        [0.1141],\n",
      "        [0.1159],\n",
      "        [0.1221]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第10000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 6614\n",
      "Number of shrink: 3386\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0030],\n",
      "        [0.0002],\n",
      "        [0.0017],\n",
      "        [0.0012],\n",
      "        [0.0019],\n",
      "        [0.0030],\n",
      "        [0.0011],\n",
      "        [0.0040],\n",
      "        [0.0031],\n",
      "        [0.0055],\n",
      "        [0.0059],\n",
      "        [0.0075],\n",
      "        [0.0030],\n",
      "        [0.0009],\n",
      "        [0.0003],\n",
      "        [0.0013],\n",
      "        [0.0051],\n",
      "        [0.0053],\n",
      "        [0.0061],\n",
      "        [0.0303],\n",
      "        [0.0102],\n",
      "        [0.0080],\n",
      "        [0.0345],\n",
      "        [0.0065],\n",
      "        [0.0039],\n",
      "        [0.0533],\n",
      "        [0.0172],\n",
      "        [0.0722],\n",
      "        [0.0723],\n",
      "        [0.0767],\n",
      "        [0.0234],\n",
      "        [0.0983],\n",
      "        [0.1110],\n",
      "        [0.1200],\n",
      "        [0.0027],\n",
      "        [0.0047],\n",
      "        [0.0170],\n",
      "        [0.0172],\n",
      "        [0.0178],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0415],\n",
      "        [0.0466],\n",
      "        [0.0472],\n",
      "        [0.0516],\n",
      "        [0.0554],\n",
      "        [0.0555],\n",
      "        [0.0577],\n",
      "        [0.0583],\n",
      "        [0.0595],\n",
      "        [0.0599],\n",
      "        [0.0683],\n",
      "        [0.0719],\n",
      "        [0.0798],\n",
      "        [0.0834],\n",
      "        [0.0839],\n",
      "        [0.0862],\n",
      "        [0.0939],\n",
      "        [0.1003],\n",
      "        [0.1023],\n",
      "        [0.1036],\n",
      "        [0.1042],\n",
      "        [0.1043],\n",
      "        [0.1048],\n",
      "        [0.1080],\n",
      "        [0.1141],\n",
      "        [0.1159],\n",
      "        [0.1221]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.12\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[67,  0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 43.18805718421936\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 69\n",
      "剩餘X 資料 torch.Size([38, 18])\n",
      "剩餘Y 資料 torch.Size([38, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.016379062086343765, 37)\n",
      "The second_loss value of k: (0.016854653134942055, 35)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引37，y= tensor([0.6353])\n",
      "目前模型的Data狀態 torch.Size([69, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9899],\n",
      "        [0.9791],\n",
      "        [0.9989],\n",
      "        [0.9823],\n",
      "        [0.9782],\n",
      "        [0.9645],\n",
      "        [0.9428],\n",
      "        [0.8930],\n",
      "        [0.9174],\n",
      "        [0.9420],\n",
      "        [0.9218],\n",
      "        [0.8607],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7931],\n",
      "        [0.8077],\n",
      "        [0.8263],\n",
      "        [0.7985],\n",
      "        [0.8433],\n",
      "        [0.7636],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9603],\n",
      "        [0.8464],\n",
      "        [0.7634],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7632],\n",
      "        [0.9828],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9033],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8743],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.6420],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.1280]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 8\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.1280]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.12\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[68,  0]], device='cuda:0')\n",
      "Cramming failed!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 26\n",
      "Number of shrink: 20\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 670\n",
      "Number of shrink: 330\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 675\n",
      "Number of shrink: 325\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 670\n",
      "Number of shrink: 330\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 666\n",
      "Number of shrink: 334\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 7\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 7\n",
      "Reorganizing result: The final number of neuro is  7\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 7],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 61.06678605079651\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 70\n",
      "剩餘X 資料 torch.Size([37, 18])\n",
      "剩餘Y 資料 torch.Size([37, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.016854653134942055, 35)\n",
      "The second_loss value of k: (0.01918931119143963, 16)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引35，y= tensor([0.6335])\n",
      "目前模型的Data狀態 torch.Size([70, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9899],\n",
      "        [0.9791],\n",
      "        [0.9989],\n",
      "        [0.9823],\n",
      "        [0.9782],\n",
      "        [0.9645],\n",
      "        [0.9428],\n",
      "        [0.8930],\n",
      "        [0.9174],\n",
      "        [0.9420],\n",
      "        [0.9218],\n",
      "        [0.8607],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7931],\n",
      "        [0.8077],\n",
      "        [0.8263],\n",
      "        [0.7985],\n",
      "        [0.8433],\n",
      "        [0.7636],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9603],\n",
      "        [0.8464],\n",
      "        [0.7634],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7632],\n",
      "        [0.9828],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9033],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8743],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.6420],\n",
      "        [0.6353],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.1298]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 6\n",
      "Number of shrink: 10\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.1298]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.12\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[69,  0]], device='cuda:0')\n",
      "Cramming failed!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0029],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 28\n",
      "Number of shrink: 21\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 670\n",
      "Number of shrink: 330\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 241\n",
      "Number of shrink: 130\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 670\n",
      "Number of shrink: 330\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 666\n",
      "Number of shrink: 334\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 666\n",
      "Number of shrink: 334\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 10\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 10\n",
      "Reorganizing result: The final number of neuro is  10\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0029],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  7, 10],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 85.8648784160614\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 71\n",
      "剩餘X 資料 torch.Size([36, 18])\n",
      "剩餘Y 資料 torch.Size([36, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.019185082986950874, 16)\n",
      "The second_loss value of k: (0.019525982439517975, 35)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引16，y= tensor([0.9018])\n",
      "目前模型的Data狀態 torch.Size([71, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9899],\n",
      "        [0.9791],\n",
      "        [0.9989],\n",
      "        [0.9823],\n",
      "        [0.9782],\n",
      "        [0.9645],\n",
      "        [0.9427],\n",
      "        [0.8930],\n",
      "        [0.9174],\n",
      "        [0.9420],\n",
      "        [0.9218],\n",
      "        [0.8607],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7931],\n",
      "        [0.8077],\n",
      "        [0.8263],\n",
      "        [0.7985],\n",
      "        [0.8433],\n",
      "        [0.7636],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9603],\n",
      "        [0.8464],\n",
      "        [0.7634],\n",
      "        [0.8316],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7632],\n",
      "        [0.9828],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9033],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8743],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.6420],\n",
      "        [0.6353],\n",
      "        [0.6335],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0029],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.1385]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0001],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0029],\n",
      "        [    0.0010],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0030],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0012],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0301],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0722],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.1385]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.12\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[70,  0]], device='cuda:0')\n",
      "Cramming failed!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0028],\n",
      "        [    0.0002],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0012],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0721],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 12\n",
      "Number of shrink: 13\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 668\n",
      "Number of shrink: 332\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 668\n",
      "Number of shrink: 332\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 669\n",
      "Number of shrink: 331\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 13\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 13\n",
      "Reorganizing result: The final number of neuro is  13\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0028],\n",
      "        [    0.0002],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0012],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0721],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  7, 10, 13],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 121.76084399223328\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 72\n",
      "剩餘X 資料 torch.Size([35, 18])\n",
      "剩餘Y 資料 torch.Size([35, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.019525982439517975, 34)\n",
      "The second_loss value of k: (0.020146269351243973, 32)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引34，y= tensor([0.6236])\n",
      "目前模型的Data狀態 torch.Size([72, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9899],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9823],\n",
      "        [0.9782],\n",
      "        [0.9645],\n",
      "        [0.9426],\n",
      "        [0.8930],\n",
      "        [0.9174],\n",
      "        [0.9420],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8579],\n",
      "        [0.8463],\n",
      "        [0.7931],\n",
      "        [0.8077],\n",
      "        [0.8263],\n",
      "        [0.7985],\n",
      "        [0.8433],\n",
      "        [0.7636],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9603],\n",
      "        [0.8464],\n",
      "        [0.7634],\n",
      "        [0.8316],\n",
      "        [0.7634],\n",
      "        [0.7633],\n",
      "        [0.7632],\n",
      "        [0.9828],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9033],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8743],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.6420],\n",
      "        [0.6353],\n",
      "        [0.6335],\n",
      "        [0.9009],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0028],\n",
      "        [    0.0002],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0012],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0721],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.1397]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0028],\n",
      "        [    0.0002],\n",
      "        [    0.0017],\n",
      "        [    0.0010],\n",
      "        [    0.0019],\n",
      "        [    0.0028],\n",
      "        [    0.0012],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0054],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0721],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.1397]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.12\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[71,  0]], device='cuda:0')\n",
      "Cramming failed!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0002],\n",
      "        [    0.0017],\n",
      "        [    0.0011],\n",
      "        [    0.0018],\n",
      "        [    0.0028],\n",
      "        [    0.0012],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0053],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0721],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 10\n",
      "Number of shrink: 12\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 669\n",
      "Number of shrink: 331\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 669\n",
      "Number of shrink: 331\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 669\n",
      "Number of shrink: 331\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 666\n",
      "Number of shrink: 334\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 16\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 16\n",
      "Reorganizing result: The final number of neuro is  16\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0002],\n",
      "        [    0.0017],\n",
      "        [    0.0011],\n",
      "        [    0.0018],\n",
      "        [    0.0028],\n",
      "        [    0.0012],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0053],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0721],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  7, 10, 13, 16],\n",
      "       dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 166.01449418067932\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 73\n",
      "剩餘X 資料 torch.Size([34, 18])\n",
      "剩餘Y 資料 torch.Size([34, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.020146269351243973, 32)\n",
      "The second_loss value of k: (0.0222039632499218, 33)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引32，y= tensor([0.6213])\n",
      "目前模型的Data狀態 torch.Size([73, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9899],\n",
      "        [0.9792],\n",
      "        [0.9989],\n",
      "        [0.9823],\n",
      "        [0.9782],\n",
      "        [0.9645],\n",
      "        [0.9426],\n",
      "        [0.8930],\n",
      "        [0.9174],\n",
      "        [0.9420],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7931],\n",
      "        [0.8077],\n",
      "        [0.8263],\n",
      "        [0.7985],\n",
      "        [0.8433],\n",
      "        [0.7636],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7698],\n",
      "        [0.9603],\n",
      "        [0.8465],\n",
      "        [0.7634],\n",
      "        [0.8316],\n",
      "        [0.7634],\n",
      "        [0.7633],\n",
      "        [0.7632],\n",
      "        [0.9828],\n",
      "        [0.7633],\n",
      "        [0.7634],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9033],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8743],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.6420],\n",
      "        [0.6353],\n",
      "        [0.6335],\n",
      "        [0.9009],\n",
      "        [0.6236],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0002],\n",
      "        [    0.0017],\n",
      "        [    0.0011],\n",
      "        [    0.0018],\n",
      "        [    0.0028],\n",
      "        [    0.0012],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0053],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0721],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0000],\n",
      "        [    0.1419]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0029],\n",
      "        [    0.0002],\n",
      "        [    0.0017],\n",
      "        [    0.0011],\n",
      "        [    0.0018],\n",
      "        [    0.0028],\n",
      "        [    0.0012],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0053],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0002],\n",
      "        [    0.0011],\n",
      "        [    0.0052],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0345],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0171],\n",
      "        [    0.0721],\n",
      "        [    0.0723],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0983],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0834],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0000],\n",
      "        [    0.1419]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.12\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[72,  0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0002],\n",
      "        [    0.0019],\n",
      "        [    0.0011],\n",
      "        [    0.0018],\n",
      "        [    0.0031],\n",
      "        [    0.0014],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0056],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0054],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0346],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0170],\n",
      "        [    0.0724],\n",
      "        [    0.0726],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0981],\n",
      "        [    0.1110],\n",
      "        [    0.1199],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0835],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0000],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 8\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 662\n",
      "Number of shrink: 338\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 662\n",
      "Number of shrink: 338\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 19\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 4\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 19\n",
      "Reorganizing result: The final number of neuro is  19\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0002],\n",
      "        [    0.0019],\n",
      "        [    0.0011],\n",
      "        [    0.0018],\n",
      "        [    0.0031],\n",
      "        [    0.0014],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0056],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0054],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0346],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0170],\n",
      "        [    0.0724],\n",
      "        [    0.0726],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0981],\n",
      "        [    0.1110],\n",
      "        [    0.1199],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0835],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0000],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  7, 10, 13, 16,\n",
      "        19], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 219.0535478591919\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 74\n",
      "剩餘X 資料 torch.Size([33, 18])\n",
      "剩餘Y 資料 torch.Size([33, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.0222039632499218, 32)\n",
      "The second_loss value of k: (0.024645745754241943, 30)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引32，y= tensor([0.6143])\n",
      "目前模型的Data狀態 torch.Size([74, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9896],\n",
      "        [0.9792],\n",
      "        [0.9992],\n",
      "        [0.9823],\n",
      "        [0.9782],\n",
      "        [0.9642],\n",
      "        [0.9424],\n",
      "        [0.8930],\n",
      "        [0.9174],\n",
      "        [0.9423],\n",
      "        [0.9218],\n",
      "        [0.8608],\n",
      "        [0.8578],\n",
      "        [0.8463],\n",
      "        [0.7934],\n",
      "        [0.8077],\n",
      "        [0.8261],\n",
      "        [0.7985],\n",
      "        [0.8433],\n",
      "        [0.7636],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7697],\n",
      "        [0.9603],\n",
      "        [0.8465],\n",
      "        [0.7634],\n",
      "        [0.8315],\n",
      "        [0.7631],\n",
      "        [0.7631],\n",
      "        [0.7632],\n",
      "        [0.9828],\n",
      "        [0.7636],\n",
      "        [0.7634],\n",
      "        [0.7634],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9035],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8743],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.6420],\n",
      "        [0.6353],\n",
      "        [0.6335],\n",
      "        [0.9009],\n",
      "        [0.6236],\n",
      "        [0.6214],\n",
      "        [0.7633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0002],\n",
      "        [    0.0019],\n",
      "        [    0.0011],\n",
      "        [    0.0018],\n",
      "        [    0.0031],\n",
      "        [    0.0014],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0056],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0054],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0346],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0170],\n",
      "        [    0.0724],\n",
      "        [    0.0726],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0981],\n",
      "        [    0.1110],\n",
      "        [    0.1199],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0835],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.1490]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0002],\n",
      "        [    0.0019],\n",
      "        [    0.0011],\n",
      "        [    0.0018],\n",
      "        [    0.0031],\n",
      "        [    0.0014],\n",
      "        [    0.0040],\n",
      "        [    0.0033],\n",
      "        [    0.0056],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0009],\n",
      "        [    0.0005],\n",
      "        [    0.0011],\n",
      "        [    0.0054],\n",
      "        [    0.0052],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0346],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0170],\n",
      "        [    0.0724],\n",
      "        [    0.0726],\n",
      "        [    0.0768],\n",
      "        [    0.0234],\n",
      "        [    0.0981],\n",
      "        [    0.1110],\n",
      "        [    0.1199],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0178],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0554],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0835],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0939],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1048],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0009],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.1490]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.12\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[73,  0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0002],\n",
      "        [    0.0020],\n",
      "        [    0.0009],\n",
      "        [    0.0017],\n",
      "        [    0.0031],\n",
      "        [    0.0015],\n",
      "        [    0.0042],\n",
      "        [    0.0033],\n",
      "        [    0.0057],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0007],\n",
      "        [    0.0004],\n",
      "        [    0.0012],\n",
      "        [    0.0053],\n",
      "        [    0.0051],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0346],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0531],\n",
      "        [    0.0170],\n",
      "        [    0.0723],\n",
      "        [    0.0726],\n",
      "        [    0.0769],\n",
      "        [    0.0235],\n",
      "        [    0.0982],\n",
      "        [    0.1109],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0177],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0555],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0835],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0938],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1049],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 3\n",
      "Number of shrink: 8\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 668\n",
      "Number of shrink: 332\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 666\n",
      "Number of shrink: 334\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 662\n",
      "Number of shrink: 338\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 666\n",
      "Number of shrink: 334\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 22\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-因為沒有顧好預測誤差\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 5\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 22\n",
      "Reorganizing result: The final number of neuro is  22\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0002],\n",
      "        [    0.0020],\n",
      "        [    0.0009],\n",
      "        [    0.0017],\n",
      "        [    0.0031],\n",
      "        [    0.0015],\n",
      "        [    0.0042],\n",
      "        [    0.0033],\n",
      "        [    0.0057],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0007],\n",
      "        [    0.0004],\n",
      "        [    0.0012],\n",
      "        [    0.0053],\n",
      "        [    0.0051],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0346],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0531],\n",
      "        [    0.0170],\n",
      "        [    0.0723],\n",
      "        [    0.0726],\n",
      "        [    0.0769],\n",
      "        [    0.0235],\n",
      "        [    0.0982],\n",
      "        [    0.1109],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0177],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0555],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0835],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0938],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1049],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  7, 10, 13, 16,\n",
      "        19, 22], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 280.6756455898285\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 75\n",
      "剩餘X 資料 torch.Size([32, 18])\n",
      "剩餘Y 資料 torch.Size([32, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.024655327200889587, 30)\n",
      "The second_loss value of k: (0.03223571553826332, 29)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引30，y= tensor([0.9203])\n",
      "目前模型的Data狀態 torch.Size([75, 1])\n",
      "<<預測值>>\n",
      "tensor([[0.9896],\n",
      "        [0.9792],\n",
      "        [0.9993],\n",
      "        [0.9824],\n",
      "        [0.9783],\n",
      "        [0.9642],\n",
      "        [0.9423],\n",
      "        [0.8931],\n",
      "        [0.9174],\n",
      "        [0.9424],\n",
      "        [0.9218],\n",
      "        [0.8607],\n",
      "        [0.8578],\n",
      "        [0.8462],\n",
      "        [0.7933],\n",
      "        [0.8078],\n",
      "        [0.8262],\n",
      "        [0.7985],\n",
      "        [0.8433],\n",
      "        [0.7636],\n",
      "        [0.7993],\n",
      "        [0.8555],\n",
      "        [0.7697],\n",
      "        [0.9603],\n",
      "        [0.8464],\n",
      "        [0.7635],\n",
      "        [0.8314],\n",
      "        [0.7632],\n",
      "        [0.7631],\n",
      "        [0.7632],\n",
      "        [0.9829],\n",
      "        [0.7635],\n",
      "        [0.7634],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7635],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.9035],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.8743],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7634],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.6420],\n",
      "        [0.6353],\n",
      "        [0.6335],\n",
      "        [0.9010],\n",
      "        [0.6236],\n",
      "        [0.6214],\n",
      "        [0.6144],\n",
      "        [0.7632]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0002],\n",
      "        [    0.0020],\n",
      "        [    0.0009],\n",
      "        [    0.0017],\n",
      "        [    0.0031],\n",
      "        [    0.0015],\n",
      "        [    0.0042],\n",
      "        [    0.0033],\n",
      "        [    0.0057],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0007],\n",
      "        [    0.0004],\n",
      "        [    0.0012],\n",
      "        [    0.0053],\n",
      "        [    0.0051],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0346],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0531],\n",
      "        [    0.0170],\n",
      "        [    0.0723],\n",
      "        [    0.0726],\n",
      "        [    0.0769],\n",
      "        [    0.0235],\n",
      "        [    0.0982],\n",
      "        [    0.1109],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0177],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0555],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0835],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0938],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1049],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.1571]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0002],\n",
      "        [    0.0020],\n",
      "        [    0.0009],\n",
      "        [    0.0017],\n",
      "        [    0.0031],\n",
      "        [    0.0015],\n",
      "        [    0.0042],\n",
      "        [    0.0033],\n",
      "        [    0.0057],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0007],\n",
      "        [    0.0004],\n",
      "        [    0.0012],\n",
      "        [    0.0053],\n",
      "        [    0.0051],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0346],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0531],\n",
      "        [    0.0170],\n",
      "        [    0.0723],\n",
      "        [    0.0726],\n",
      "        [    0.0769],\n",
      "        [    0.0235],\n",
      "        [    0.0982],\n",
      "        [    0.1109],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0177],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0555],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0835],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0938],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1049],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.1571]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.12\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[74,  0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0031],\n",
      "        [    0.0002],\n",
      "        [    0.0020],\n",
      "        [    0.0011],\n",
      "        [    0.0017],\n",
      "        [    0.0032],\n",
      "        [    0.0014],\n",
      "        [    0.0042],\n",
      "        [    0.0033],\n",
      "        [    0.0057],\n",
      "        [    0.0059],\n",
      "        [    0.0074],\n",
      "        [    0.0031],\n",
      "        [    0.0007],\n",
      "        [    0.0004],\n",
      "        [    0.0012],\n",
      "        [    0.0053],\n",
      "        [    0.0051],\n",
      "        [    0.0059],\n",
      "        [    0.0300],\n",
      "        [    0.0101],\n",
      "        [    0.0080],\n",
      "        [    0.0346],\n",
      "        [    0.0066],\n",
      "        [    0.0039],\n",
      "        [    0.0532],\n",
      "        [    0.0170],\n",
      "        [    0.0723],\n",
      "        [    0.0726],\n",
      "        [    0.0769],\n",
      "        [    0.0235],\n",
      "        [    0.0982],\n",
      "        [    0.1110],\n",
      "        [    0.1200],\n",
      "        [    0.0027],\n",
      "        [    0.0047],\n",
      "        [    0.0170],\n",
      "        [    0.0172],\n",
      "        [    0.0177],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0415],\n",
      "        [    0.0466],\n",
      "        [    0.0472],\n",
      "        [    0.0516],\n",
      "        [    0.0555],\n",
      "        [    0.0555],\n",
      "        [    0.0577],\n",
      "        [    0.0583],\n",
      "        [    0.0595],\n",
      "        [    0.0599],\n",
      "        [    0.0683],\n",
      "        [    0.0719],\n",
      "        [    0.0798],\n",
      "        [    0.0835],\n",
      "        [    0.0839],\n",
      "        [    0.0862],\n",
      "        [    0.0938],\n",
      "        [    0.1003],\n",
      "        [    0.1023],\n",
      "        [    0.1036],\n",
      "        [    0.1042],\n",
      "        [    0.1043],\n",
      "        [    0.1049],\n",
      "        [    0.1080],\n",
      "        [    0.1141],\n",
      "        [    0.1159],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0008],\n",
      "        [    0.0000],\n",
      "        [    0.0001],\n",
      "        [    0.0001],\n",
      "        [    0.0001]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 2 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 668\n",
      "Number of shrink: 332\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 3 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 4 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 5 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 6 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 7 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 8 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 9 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 10 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 11 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 12 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 665\n",
      "Number of shrink: 335\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 13 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 14 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 15 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 16 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 17 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 18 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 667\n",
      "Number of shrink: 333\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 19 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 20 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 664\n",
      "Number of shrink: 336\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 21 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 22 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 662\n",
      "Number of shrink: 338\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 23 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 663\n",
      "Number of shrink: 337\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 24 / 25\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching的第1000回合\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 662\n",
      "Number of shrink: 338\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 25 / 25\n",
      "Reorganizing result: The final number of neuro is  25\n",
      "<<Reorganizing後看一下差異>>\n",
      "tensor([[0.0453],\n",
      "        [0.0490],\n",
      "        [0.0540],\n",
      "        [0.0517],\n",
      "        [0.0507],\n",
      "        [0.0460],\n",
      "        [0.0497],\n",
      "        [0.0550],\n",
      "        [0.0558],\n",
      "        [0.0561],\n",
      "        [0.0545],\n",
      "        [0.0594],\n",
      "        [0.0518],\n",
      "        [0.0477],\n",
      "        [0.0470],\n",
      "        [0.0467],\n",
      "        [0.0426],\n",
      "        [0.0053],\n",
      "        [0.0106],\n",
      "        [0.0165],\n",
      "        [0.0117],\n",
      "        [0.0113],\n",
      "        [0.0360],\n",
      "        [0.0075],\n",
      "        [0.0042],\n",
      "        [0.0533],\n",
      "        [0.0175],\n",
      "        [0.0215],\n",
      "        [0.0273],\n",
      "        [0.0782],\n",
      "        [0.0222],\n",
      "        [0.0534],\n",
      "        [0.0657],\n",
      "        [0.1178],\n",
      "        [0.0007],\n",
      "        [0.0335],\n",
      "        [0.0114],\n",
      "        [0.0122],\n",
      "        [0.0127],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0040],\n",
      "        [0.0466],\n",
      "        [0.0380],\n",
      "        [0.0516],\n",
      "        [0.1044],\n",
      "        [0.0479],\n",
      "        [0.0553],\n",
      "        [0.0507],\n",
      "        [0.0562],\n",
      "        [0.0575],\n",
      "        [0.0305],\n",
      "        [0.0694],\n",
      "        [0.0431],\n",
      "        [0.0816],\n",
      "        [0.0815],\n",
      "        [0.0494],\n",
      "        [0.0955],\n",
      "        [0.0643],\n",
      "        [0.1022],\n",
      "        [0.0669],\n",
      "        [0.0691],\n",
      "        [0.0698],\n",
      "        [0.0997],\n",
      "        [0.0719],\n",
      "        [0.1088],\n",
      "        [0.1135],\n",
      "        [0.0095],\n",
      "        [0.0351],\n",
      "        [0.0386],\n",
      "        [0.0163],\n",
      "        [0.0006],\n",
      "        [0.0132],\n",
      "        [0.0367],\n",
      "        [0.0014]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "看一下 hidden node\n",
      "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  7, 10, 13, 16,\n",
      "        19, 22, 25], dtype=torch.int32)\n",
      "使用裝置 cuda:0\n",
      "累計時間(s) 351.22559690475464\n",
      "------------------------------------------------------------------------------------------\n",
      "現在訓練到第幾筆資料: 76\n",
      "剩餘X 資料 torch.Size([31, 18])\n",
      "剩餘Y 資料 torch.Size([31, 1])\n",
      "<<Selecting module>>\n",
      "The loss value of k: (0.032515957951545715, 29)\n",
      "The second_loss value of k: (0.034716833382844925, 11)\n",
      "Selecting module finish!\n",
      "現在要進去模型的數據，索引29，y= tensor([0.9552])\n",
      "目前模型的Data狀態 torch.Size([76, 1])\n",
      "<<預測值>>\n",
      "tensor([[1.0381],\n",
      "        [1.0280],\n",
      "        [1.0512],\n",
      "        [1.0351],\n",
      "        [1.0307],\n",
      "        [1.0134],\n",
      "        [0.9935],\n",
      "        [0.9439],\n",
      "        [0.9699],\n",
      "        [0.9927],\n",
      "        [0.9704],\n",
      "        [0.9127],\n",
      "        [0.9065],\n",
      "        [0.8932],\n",
      "        [0.8398],\n",
      "        [0.8532],\n",
      "        [0.8741],\n",
      "        [0.7984],\n",
      "        [0.8386],\n",
      "        [0.8101],\n",
      "        [0.7978],\n",
      "        [0.8522],\n",
      "        [0.7682],\n",
      "        [0.9594],\n",
      "        [0.8467],\n",
      "        [0.7633],\n",
      "        [0.8319],\n",
      "        [0.8140],\n",
      "        [0.8084],\n",
      "        [0.7618],\n",
      "        [0.9816],\n",
      "        [0.8082],\n",
      "        [0.8087],\n",
      "        [0.7655],\n",
      "        [0.7613],\n",
      "        [0.7251],\n",
      "        [0.7577],\n",
      "        [0.7583],\n",
      "        [0.7582],\n",
      "        [0.7633],\n",
      "        [0.7633],\n",
      "        [0.7258],\n",
      "        [0.7633],\n",
      "        [0.7541],\n",
      "        [0.7633],\n",
      "        [0.8123],\n",
      "        [0.7557],\n",
      "        [0.7609],\n",
      "        [0.7557],\n",
      "        [0.7600],\n",
      "        [0.7608],\n",
      "        [0.7255],\n",
      "        [0.7608],\n",
      "        [0.7266],\n",
      "        [0.9016],\n",
      "        [0.7609],\n",
      "        [0.7266],\n",
      "        [0.8727],\n",
      "        [0.7273],\n",
      "        [0.7633],\n",
      "        [0.7266],\n",
      "        [0.7283],\n",
      "        [0.7288],\n",
      "        [0.7582],\n",
      "        [0.7272],\n",
      "        [0.7580],\n",
      "        [0.7609],\n",
      "        [0.6317],\n",
      "        [0.6003],\n",
      "        [0.5949],\n",
      "        [0.9182],\n",
      "        [0.6230],\n",
      "        [0.6081],\n",
      "        [0.5777],\n",
      "        [0.9217],\n",
      "        [0.7746]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "<<差異>>\n",
      "tensor([[0.0453],\n",
      "        [0.0490],\n",
      "        [0.0540],\n",
      "        [0.0517],\n",
      "        [0.0507],\n",
      "        [0.0460],\n",
      "        [0.0497],\n",
      "        [0.0550],\n",
      "        [0.0558],\n",
      "        [0.0561],\n",
      "        [0.0545],\n",
      "        [0.0594],\n",
      "        [0.0518],\n",
      "        [0.0477],\n",
      "        [0.0470],\n",
      "        [0.0467],\n",
      "        [0.0426],\n",
      "        [0.0053],\n",
      "        [0.0106],\n",
      "        [0.0165],\n",
      "        [0.0117],\n",
      "        [0.0113],\n",
      "        [0.0360],\n",
      "        [0.0075],\n",
      "        [0.0042],\n",
      "        [0.0533],\n",
      "        [0.0175],\n",
      "        [0.0215],\n",
      "        [0.0273],\n",
      "        [0.0782],\n",
      "        [0.0222],\n",
      "        [0.0534],\n",
      "        [0.0657],\n",
      "        [0.1178],\n",
      "        [0.0007],\n",
      "        [0.0335],\n",
      "        [0.0114],\n",
      "        [0.0122],\n",
      "        [0.0127],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0040],\n",
      "        [0.0466],\n",
      "        [0.0380],\n",
      "        [0.0516],\n",
      "        [0.1044],\n",
      "        [0.0479],\n",
      "        [0.0553],\n",
      "        [0.0507],\n",
      "        [0.0562],\n",
      "        [0.0575],\n",
      "        [0.0305],\n",
      "        [0.0694],\n",
      "        [0.0431],\n",
      "        [0.0816],\n",
      "        [0.0815],\n",
      "        [0.0494],\n",
      "        [0.0955],\n",
      "        [0.0643],\n",
      "        [0.1022],\n",
      "        [0.0669],\n",
      "        [0.0691],\n",
      "        [0.0698],\n",
      "        [0.0997],\n",
      "        [0.0719],\n",
      "        [0.1088],\n",
      "        [0.1135],\n",
      "        [0.0095],\n",
      "        [0.0351],\n",
      "        [0.0386],\n",
      "        [0.0163],\n",
      "        [0.0006],\n",
      "        [0.0132],\n",
      "        [0.0367],\n",
      "        [0.0014],\n",
      "        [0.1806]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "Loss值\n",
      "tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "<<Matching module>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished - the network is Unacceptable\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching後看一下差異>>\n",
      "tensor([[0.0453],\n",
      "        [0.0490],\n",
      "        [0.0540],\n",
      "        [0.0517],\n",
      "        [0.0507],\n",
      "        [0.0460],\n",
      "        [0.0497],\n",
      "        [0.0550],\n",
      "        [0.0558],\n",
      "        [0.0561],\n",
      "        [0.0545],\n",
      "        [0.0594],\n",
      "        [0.0518],\n",
      "        [0.0477],\n",
      "        [0.0470],\n",
      "        [0.0467],\n",
      "        [0.0426],\n",
      "        [0.0053],\n",
      "        [0.0106],\n",
      "        [0.0165],\n",
      "        [0.0117],\n",
      "        [0.0113],\n",
      "        [0.0360],\n",
      "        [0.0075],\n",
      "        [0.0042],\n",
      "        [0.0533],\n",
      "        [0.0175],\n",
      "        [0.0215],\n",
      "        [0.0273],\n",
      "        [0.0782],\n",
      "        [0.0222],\n",
      "        [0.0534],\n",
      "        [0.0657],\n",
      "        [0.1178],\n",
      "        [0.0007],\n",
      "        [0.0335],\n",
      "        [0.0114],\n",
      "        [0.0122],\n",
      "        [0.0127],\n",
      "        [0.0278],\n",
      "        [0.0291],\n",
      "        [0.0040],\n",
      "        [0.0466],\n",
      "        [0.0380],\n",
      "        [0.0516],\n",
      "        [0.1044],\n",
      "        [0.0479],\n",
      "        [0.0553],\n",
      "        [0.0507],\n",
      "        [0.0562],\n",
      "        [0.0575],\n",
      "        [0.0305],\n",
      "        [0.0694],\n",
      "        [0.0431],\n",
      "        [0.0816],\n",
      "        [0.0815],\n",
      "        [0.0494],\n",
      "        [0.0955],\n",
      "        [0.0643],\n",
      "        [0.1022],\n",
      "        [0.0669],\n",
      "        [0.0691],\n",
      "        [0.0698],\n",
      "        [0.0997],\n",
      "        [0.0719],\n",
      "        [0.1088],\n",
      "        [0.1135],\n",
      "        [0.0095],\n",
      "        [0.0351],\n",
      "        [0.0386],\n",
      "        [0.0163],\n",
      "        [0.0006],\n",
      "        [0.0132],\n",
      "        [0.0367],\n",
      "        [0.0014],\n",
      "        [0.1806]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: [0.11750881]\n",
      "<<Cramming module>>\n",
      "threshold_for_error: 0.12\n",
      "不滿足個數： 1\n",
      "The index of the undesired data: tensor([[75,  0]], device='cuda:0')\n",
      "Cramming success!\n",
      "<<Cramming後看一下差異>>\n",
      "tensor([[    0.0453],\n",
      "        [    0.0490],\n",
      "        [    0.0542],\n",
      "        [    0.0519],\n",
      "        [    0.0505],\n",
      "        [    0.0462],\n",
      "        [    0.0499],\n",
      "        [    0.0548],\n",
      "        [    0.0558],\n",
      "        [    0.0560],\n",
      "        [    0.0545],\n",
      "        [    0.0594],\n",
      "        [    0.0517],\n",
      "        [    0.0478],\n",
      "        [    0.0470],\n",
      "        [    0.0467],\n",
      "        [    0.0426],\n",
      "        [    0.0053],\n",
      "        [    0.0106],\n",
      "        [    0.0165],\n",
      "        [    0.0117],\n",
      "        [    0.0113],\n",
      "        [    0.0360],\n",
      "        [    0.0075],\n",
      "        [    0.0042],\n",
      "        [    0.0533],\n",
      "        [    0.0175],\n",
      "        [    0.0215],\n",
      "        [    0.0273],\n",
      "        [    0.0782],\n",
      "        [    0.0222],\n",
      "        [    0.0534],\n",
      "        [    0.0657],\n",
      "        [    0.1178],\n",
      "        [    0.0007],\n",
      "        [    0.0335],\n",
      "        [    0.0114],\n",
      "        [    0.0122],\n",
      "        [    0.0127],\n",
      "        [    0.0278],\n",
      "        [    0.0291],\n",
      "        [    0.0040],\n",
      "        [    0.0466],\n",
      "        [    0.0380],\n",
      "        [    0.0516],\n",
      "        [    0.1044],\n",
      "        [    0.0479],\n",
      "        [    0.0553],\n",
      "        [    0.0507],\n",
      "        [    0.0562],\n",
      "        [    0.0575],\n",
      "        [    0.0305],\n",
      "        [    0.0694],\n",
      "        [    0.0431],\n",
      "        [    0.0816],\n",
      "        [    0.0815],\n",
      "        [    0.0494],\n",
      "        [    0.0955],\n",
      "        [    0.0643],\n",
      "        [    0.1022],\n",
      "        [    0.0669],\n",
      "        [    0.0691],\n",
      "        [    0.0698],\n",
      "        [    0.0997],\n",
      "        [    0.0719],\n",
      "        [    0.1088],\n",
      "        [    0.1135],\n",
      "        [    0.0095],\n",
      "        [    0.0351],\n",
      "        [    0.0386],\n",
      "        [    0.0163],\n",
      "        [    0.0006],\n",
      "        [    0.0132],\n",
      "        [    0.0367],\n",
      "        [    0.0014],\n",
      "        [    0.0000]], device='cuda:0', grad_fn=<AbsBackward>)\n",
      "threshold_for_error: 0.12\n",
      "<<Reorganizing module>>\n",
      "threshold_for_error: 0.12\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n",
      "Matching finished(o) - the network is Unacceptable\n",
      "Number of enlarge: 1\n",
      "Number of shrink: 7\n",
      "是不是可以不要這個hidden node: False\n",
      "Cannot drop out the nero number: 1 / 28\n",
      "<<Regularizing module>>\n",
      "threshold_for_error: 0.12\n",
      "Regularizing結束-Learning不能這麼小\n",
      "Number of enlarge: 0\n",
      "Number of shrink: 7\n",
      "<<Matching module for reorganizing>>\n",
      "threshold_for_error: 0.12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8fe61d14e5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mnb_step4\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreorganizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<<Reorganizing後看一下差異>>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0myo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-d90f45550235>\u001b[0m in \u001b[0;36mreorganizing\u001b[0;34m(network)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m## Using the matching module to adjust the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatching_for_reorganizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"是不是可以不要這個hidden node:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macceptable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-4b238e4f3257>\u001b[0m in \u001b[0;36mmatching_for_reorganizing\u001b[0;34m(network)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m#                     print(\"*0.7\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0;31m# Restore the papameter of the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0mtimes_shrink\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_quantized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqscheme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_tensor_affine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'torch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluation_table_train = pd.DataFrame(columns=[\"Window_index\",\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "evaluation_table_test = pd.DataFrame(columns=[\"Window_index\",\"Stage\",\"MAE\",\"MAPE\",\"RMSE\",\"Accuracy(2000)\",\"Accuracy(3000)\",\"Step4\",\"Step6.1\",\"Step6.2\",\"Time\",\"Adopted_hidden_node\"])\n",
    "    \n",
    "x_data, y_data= get_data(4)\n",
    "x_data = sc.fit_transform(x_data)\n",
    "y_data = sc.fit_transform(y_data[:,3].reshape(-1,1))\n",
    "threshold_for_error = 3000/(sc.data_max_-sc.data_min_)\n",
    "\n",
    "data = range(x_data.shape[0])\n",
    "# window_size => the length of training block\n",
    "window_size = 106\n",
    "# step_window => step size of each window\n",
    "step_window = 26\n",
    "# the split data\n",
    "splits = []\n",
    "\n",
    "## Moving window mechnism\n",
    "for i in range(window_size, len(data), step_window):\n",
    "    train = np.array(data[i-window_size:i])\n",
    "    test = np.array(data[i-window_size:i+step_window])\n",
    "#     test = np.array(data[i:i+step_window])\n",
    "    splits.append(('TRAIN:', train, 'TEST:', test))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i_block in range(len(splits)):\n",
    "# for i_block in range(-2,0,1):\n",
    "# for i_block in range(2):\n",
    "    block_start = time.time()\n",
    "    ## Record the number of each step\n",
    "    nb_step4 = 0\n",
    "    nb_step6_1 = 0\n",
    "    nb_step6_2 = 0\n",
    "    \n",
    "    print(\"The <<%d>> Block\" %(i_block+1))\n",
    "#     print(\"The <<%d>> Block\" %(len(splits)+i_block+1))\n",
    "#     print(\"The training block\\n\", y_data[splits[i_block][1]])\n",
    "#     print(\"The testing block\\n\", y_data[splits[i_block][3]])\n",
    "    \n",
    "    x_train = x_data[splits[i_block][1]]\n",
    "    x_test = x_data[splits[i_block][3]]\n",
    "    y_train = y_data[splits[i_block][1]]\n",
    "    y_test = y_data[splits[i_block][3]]\n",
    "    \n",
    "    x_train_scaled = torch.FloatTensor(x_train)\n",
    "    x_test_scaled = torch.FloatTensor(x_test)\n",
    "    y_train_scaled = torch.FloatTensor(y_train)\n",
    "    y_test = sc.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "#     if i_block == -2:\n",
    "    if i_block == 0:\n",
    "        \n",
    "        initial_x = torch.FloatTensor(x_train_scaled[10:29])\n",
    "        initial_y = torch.FloatTensor(y_train_scaled[10:29])\n",
    "\n",
    "        x_train_scaled = torch.FloatTensor(np.concatenate([x_train_scaled[:10],x_train_scaled[29:]], axis=0))\n",
    "        y_train_scaled = torch.FloatTensor(np.concatenate([y_train_scaled[:10],y_train_scaled[29:]], axis=0))\n",
    "#         print(initial_x.shape[0])\n",
    "        \n",
    "        network = Network(1,initial_x,initial_y)\n",
    "        \n",
    "        network.nb_node_acceptable = torch.IntTensor([1 for _ in range(initial_x.shape[0])])\n",
    "        network.threshold_for_error = round(threshold_for_error[0],2)\n",
    "        \n",
    "        initializing(network, initial_x, initial_y)\n",
    "        \n",
    "        print(\"<<Initializing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(network.y-yo))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        remainder = int(window_size*0.9624) - initial_x.shape[0]\n",
    "    \n",
    "    else:\n",
    "#         print(\"新的Code待驗證\")\n",
    "#         print(network.state_dict())\n",
    "        sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "        restart_index = int(x_train_scaled.shape[0]*0.9624)-step_window\n",
    "        print(\"其他區塊剛開始選的資料索引：\",sorted_index[:restart_index])\n",
    "        init_x = x_train_scaled[sorted_index[:int(x_train_scaled.shape[0]*0.9624)-step_window]].reshape(-1,x_train_scaled.shape[1])\n",
    "        init_y = y_train_scaled[sorted_index[:int(x_train_scaled.shape[0]*0.9624)-step_window]].reshape(-1,1)\n",
    "#         print(\"取得的x\",init_x.shape)\n",
    "#         print(\"取得的y\",init_y.shape)\n",
    "#         print(\"前\")\n",
    "#         print(network.y.shape)\n",
    "        network.setData(init_x, init_y)\n",
    "#         print(\"後\")\n",
    "#         print(network.y.shape)\n",
    "        network.nb_node_acceptable = torch.IntTensor([network.linear1.bias.data.shape[0] for _ in range(init_x.shape[0])])\n",
    "        network.nb_node_pruned = 0\n",
    "        \n",
    "        print(\"<<其他區塊剛開始時看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(network.y-yo))\n",
    "        \n",
    "        remainder = int(window_size*0.9624) - init_x.shape[0]\n",
    "        x_train_scaled = np.delete(x_train_scaled, sorted_index[:restart_index], 0)\n",
    "        y_train_scaled = np.delete(y_train_scaled, sorted_index[:restart_index], 0)\n",
    "        \n",
    "#         print(\"X 資料\",x_train_scaled.shape)\n",
    "#         print(\"Y 資料\",y_train_scaled.shape)\n",
    "#     network.limit = network.linear1.bias.data.shape[0]\n",
    "#     print(\"Limit for node pruned:\",network.limit)\n",
    "    \n",
    "#     for i in range(int(x_train_scaled.shape[0]*0.9624)):\n",
    "#     for i in range(2):\n",
    "    for i in range(remainder):\n",
    "#         if i_block == -2:\n",
    "        if i_block == 0:\n",
    "            print(\"現在訓練到第幾筆資料: %d\"%(i+x_train_scaled.shape[1]+2))\n",
    "        \n",
    "        else:\n",
    "            print(\"現在訓練到第幾筆資料: %d\"%(restart_index+i+1))\n",
    "        \n",
    "        print(\"剩餘X 資料\",x_train_scaled.shape)\n",
    "        print(\"剩餘Y 資料\",y_train_scaled.shape)\n",
    "        \n",
    "        sorted_index = selecting(network, x_train_scaled, y_train_scaled)\n",
    "        \n",
    "\n",
    "        ## Add new data for training\n",
    "        \n",
    "        print(\"現在要進去模型的數據，索引%d，y=\"%(sorted_index[0]),y_train_scaled[sorted_index[0]].data)        \n",
    "        network.addData(x_train_scaled[sorted_index[0]], y_train_scaled[sorted_index[0]])\n",
    "        print(\"目前模型的Data狀態\",network.y.shape)\n",
    "        x_train_scaled = np.delete(x_train_scaled, sorted_index[0], 0)\n",
    "        y_train_scaled = np.delete(y_train_scaled, sorted_index[0], 0)\n",
    "        \n",
    "        yo,loss = network.forward()\n",
    "        print(\"<<預測值>>\")\n",
    "        print(yo)\n",
    "        print(\"<<差異>>\")\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        print(\"Loss值\")\n",
    "        print(loss)\n",
    "\n",
    "        pre_network = copy.deepcopy(network)\n",
    "        \n",
    "        if not torch.all(torch.abs(network.y-yo)<=network.threshold_for_error):\n",
    "\n",
    "            network.acceptable = False\n",
    "            network = matching(network)\n",
    "            \n",
    "            print(\"<<Matching後看一下差異>>\")\n",
    "            yo,loss = network.forward()\n",
    "            print(torch.abs(yo-network.y))\n",
    "            print(\"threshold_for_error:\",threshold_for_error)\n",
    "            \n",
    "            if network.acceptable == False:\n",
    "                \n",
    "                network = copy.deepcopy(pre_network)\n",
    "                cramming(network)\n",
    "\n",
    "                if network.acceptable == False:\n",
    "                    sys.exit(0)  \n",
    "                \n",
    "                print(\"<<Cramming後看一下差異>>\")\n",
    "                yo,loss = network.forward()\n",
    "                print(torch.abs(yo-network.y))\n",
    "                print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "                nb_step6_2 += 1\n",
    "\n",
    "            else:\n",
    "                nb_step6_1 += 1\n",
    "\n",
    "        else:\n",
    "            nb_step4 += 1\n",
    "\n",
    "        network = reorganizing(network)\n",
    "        print(\"<<Reorganizing後看一下差異>>\")\n",
    "        yo,loss = network.forward()\n",
    "        print(torch.abs(yo-network.y))\n",
    "        print(\"threshold_for_error:\",network.threshold_for_error)\n",
    "        \n",
    "        network.nb_node_acceptable = torch.cat([network.nb_node_acceptable, torch.IntTensor([network.linear1.bias.data.shape[0]])],0)\n",
    "        print(\"看一下 hidden node\")\n",
    "        print(network.nb_node_acceptable)\n",
    "       \n",
    "        print(\"使用裝置\",(list(network.parameters())[0].device))\n",
    "        print(\"累計時間(s)\",time.time()-start)\n",
    "#         print(network.state_dict())\n",
    "        print(\"-\"*90)\n",
    "\n",
    "    \n",
    "    block_end = time.time()\n",
    "    print(\"到第 %d 個區塊累積花費時間(s)\"%(i_block+1),block_end-block_start)\n",
    "#     print(\"到第 %d 個區塊累積花費時間(s)\"%(len(splits)+i_block+1),block_end-block_start)\n",
    "    print(\"<<The performance of %d block>>\"%(i_block+1))\n",
    "#     print(\"<<The performance of %d block>>\"%(len(splits)+i_block+1))\n",
    "    \n",
    "    evaluation_table_train, evaluation_table_test = validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test_scaled, y_test, block_start, block_end,i_block+1,evaluation_table_train,evaluation_table_test)\n",
    "\n",
    "    evaluation_table_train.to_csv(\"evaluation_table_train.csv\",index=False)\n",
    "    evaluation_table_test.to_csv(\"evaluation_table_inferencing.csv\",index=False)\n",
    "#     validation(network, nb_step4, nb_step6_1, nb_step6_2, x_test_scaled, y_test, block_start, block_end,(len(splits)+i_block+1))\n",
    "end = time.time()\n",
    "print(\"總計時間(s)\", end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
